{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 010 - Sklearn DuckDB SQL Classification (CatBoost + XGBoost)\n",
    "\n",
    "This notebook demonstrates **complete DuckDB SQL preprocessing** for classification with CatBoost (primary) and XGBoost (fallback).\n",
    "\n",
    "## Key Features\n",
    "\n",
    "| Aspect | Implementation |\n",
    "|--------|---------------|\n",
    "| **Primary Model** | CatBoost (best for categorical features, native handling) |\n",
    "| **Fallback Model** | XGBoost (sklearn-native, for YellowBrick testing) |\n",
    "| **JSON extraction** | `json_extract_string()` in DuckDB SQL |\n",
    "| **Timestamp parsing** | `date_part()` in DuckDB SQL |\n",
    "| **Feature scaling** | None needed (tree-based models) |\n",
    "\n",
    "## Model Comparison\n",
    "\n",
    "| Aspect | CatBoost | XGBoost |\n",
    "|--------|----------|---------|\n",
    "| **Categorical handling** | ✅ Native (strings) | Requires label encoding |\n",
    "| **SQL Query** | Keeps strings | `DENSE_RANK() - 1` |\n",
    "| **Imbalanced data** | `auto_class_weights` | `scale_pos_weight` |\n",
    "| **YellowBrick** | ❌ Incompatible | ✅ sklearn-native |\n",
    "\n",
    "## SQL Queries by Model Type\n",
    "\n",
    "**CatBoost (Primary)** - Keeps categorical strings:\n",
    "```sql\n",
    "SELECT amount, currency, json_extract_string(device_info, '$.browser') AS browser, ...\n",
    "FROM delta_scan('s3://...')\n",
    "```\n",
    "\n",
    "**XGBoost (Fallback)** - Label encodes categoricals:\n",
    "```sql\n",
    "SELECT amount, DENSE_RANK() OVER (ORDER BY currency) - 1 AS currency, ...\n",
    "FROM delta_scan('s3://...')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ed00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn import metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from catboost import CatBoostClassifier  # Primary model - best for categorical features\n",
    "from xgboost import XGBClassifier  # Fallback model - sklearn-native for YellowBrick testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ffd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_HOST = \"localhost\"\n",
    "MINIO_PORT = \"9000\"\n",
    "MINIO_ENDPOINT = f\"{MINIO_HOST}:{MINIO_PORT}\"\n",
    "MINIO_ACCESS_KEY = \"minioadmin\"\n",
    "MINIO_SECRET_KEY = \"minioadmin123\"\n",
    "PROJECT_NAME = \"Transaction Fraud Detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7514c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_PATHS = {\n",
    "    \"Transaction Fraud Detection\": \"s3://lakehouse/delta/transaction_fraud_detection\",\n",
    "    \"Estimated Time of Arrival\": \"s3://lakehouse/delta/estimated_time_of_arrival\",\n",
    "    \"E-Commerce Customer Interactions\": \"s3://lakehouse/delta/e_commerce_customer_interactions\",\n",
    "}\n",
    "\n",
    "delta_path = DELTA_PATHS.get(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc64e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7143b19d28488294f15082d86f010e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB extensions loaded and S3 secret configured\n"
     ]
    }
   ],
   "source": [
    "# Disable AWS EC2 metadata service lookup (prevents 169.254.169.254 errors)\n",
    "os.environ[\"AWS_EC2_METADATA_DISABLED\"] = \"true\"\n",
    "\n",
    "# Create connection (in-memory database)\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Install and load required extensions\n",
    "conn.execute(\"INSTALL delta; LOAD delta;\")\n",
    "conn.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Create a secret for S3/MinIO credentials\n",
    "conn.execute(f\"\"\"\n",
    "    CREATE SECRET minio_secret (\n",
    "        TYPE S3,\n",
    "        KEY_ID '{MINIO_ACCESS_KEY}',\n",
    "        SECRET '{MINIO_SECRET_KEY}',\n",
    "        REGION 'us-east-1',\n",
    "        ENDPOINT '{MINIO_ENDPOINT}',\n",
    "        URL_STYLE 'path',\n",
    "        USE_SSL false\n",
    "    );\n",
    "\"\"\")\n",
    "print(\"DuckDB extensions loaded and S3 secret configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4",
   "metadata": {},
   "source": [
    "## Feature Definitions\n",
    "\n",
    "Define features upfront for CatBoost's native categorical handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e2a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: 4\n",
      "Categorical features: 13\n",
      "Categorical indices: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "# Feature definitions for Transaction Fraud Detection\n",
    "TFD_NUMERICAL_FEATURES = [\n",
    "    \"amount\",\n",
    "    \"account_age_days\",\n",
    "    \"cvv_provided\",\n",
    "    \"billing_address_match\",\n",
    "]\n",
    "\n",
    "TFD_CATEGORICAL_FEATURES = [\n",
    "    \"currency\",\n",
    "    \"merchant_id\",\n",
    "    \"payment_method\",\n",
    "    \"product_category\",\n",
    "    \"transaction_type\",\n",
    "    \"browser\",\n",
    "    \"os\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"hour\",\n",
    "    \"minute\",\n",
    "    \"second\",\n",
    "]\n",
    "\n",
    "TFD_ALL_FEATURES = TFD_NUMERICAL_FEATURES + TFD_CATEGORICAL_FEATURES\n",
    "\n",
    "# Categorical feature indices for CatBoost (position in feature list)\n",
    "TFD_CAT_FEATURE_INDICES = list(range(\n",
    "    len(TFD_NUMERICAL_FEATURES),\n",
    "    len(TFD_ALL_FEATURES)\n",
    "))\n",
    "\n",
    "print(f\"Numerical features: {len(TFD_NUMERICAL_FEATURES)}\")\n",
    "print(f\"Categorical features: {len(TFD_CATEGORICAL_FEATURES)}\")\n",
    "print(f\"Categorical indices: {TFD_CAT_FEATURE_INDICES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## DuckDB SQL Preprocessing\n",
    "\n",
    "Two SQL query strategies based on model type:\n",
    "\n",
    "### CatBoost Query (Primary)\n",
    "- Keeps categorical features as **strings** (CatBoost handles natively)\n",
    "- Converts to `category` dtype in Python for memory efficiency\n",
    "- **Best performance** - CatBoost's native categorical handling is superior\n",
    "\n",
    "### XGBoost Query (Fallback)\n",
    "- **Label encodes** categoricals with `DENSE_RANK() - 1`\n",
    "- All features become integers (XGBoost requires numeric input)\n",
    "- Useful for YellowBrick visualization testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "154323c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def load_data_duckdb_sql(\n",
    "    delta_path: str,\n",
    "    model_type: Literal[\"catboost\", \"xgboost\"] = \"catboost\",\n",
    "    sample_frac: float | None = None,\n",
    "    max_rows: int | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and preprocess data using pure DuckDB SQL.\n",
    "    \n",
    "    Two query strategies based on model_type:\n",
    "    - CatBoost: Keeps categorical strings (native handling)\n",
    "    - XGBoost: Label encodes categoricals with DENSE_RANK() - 1\n",
    "    \n",
    "    Args:\n",
    "        delta_path: Path to Delta Lake table\n",
    "        model_type: \"catboost\" (strings) or \"xgboost\" (label encoded)\n",
    "        sample_frac: Optional fraction of data to sample (0.0-1.0)\n",
    "        max_rows: Optional maximum number of rows to load\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with preprocessed features and target\n",
    "    \"\"\"\n",
    "    if model_type == \"catboost\":\n",
    "        # CatBoost query: Keep categorical strings (native handling)\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            -- Numerical features\n",
    "            amount,\n",
    "            account_age_days,\n",
    "            CAST(cvv_provided AS INTEGER) AS cvv_provided,\n",
    "            CAST(billing_address_match AS INTEGER) AS billing_address_match,\n",
    "\n",
    "            -- Categorical features (keep as strings for CatBoost)\n",
    "            currency,\n",
    "            merchant_id,\n",
    "            payment_method,\n",
    "            product_category,\n",
    "            transaction_type,\n",
    "\n",
    "            -- JSON extraction (keep as strings)\n",
    "            json_extract_string(device_info, '$.browser') AS browser,\n",
    "            json_extract_string(device_info, '$.os') AS os,\n",
    "\n",
    "            -- Timestamp components\n",
    "            CAST(date_part('year', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS year,\n",
    "            CAST(date_part('month', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS month,\n",
    "            CAST(date_part('day', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS day,\n",
    "            CAST(date_part('hour', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS hour,\n",
    "            CAST(date_part('minute', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS minute,\n",
    "            CAST(date_part('second', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS second,\n",
    "\n",
    "            -- Target\n",
    "            is_fraud\n",
    "\n",
    "        FROM delta_scan('{delta_path}')\n",
    "        \"\"\"\n",
    "        print(f\"Loading data for CatBoost (categorical strings)...\")\n",
    "    \n",
    "    else:  # xgboost\n",
    "        # XGBoost query: Label encode categoricals with DENSE_RANK() - 1\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            -- Numerical features\n",
    "            amount,\n",
    "            account_age_days,\n",
    "            CAST(cvv_provided AS INTEGER) AS cvv_provided,\n",
    "            CAST(billing_address_match AS INTEGER) AS billing_address_match,\n",
    "\n",
    "            -- Categorical features: Label encoded with DENSE_RANK() - 1\n",
    "            DENSE_RANK() OVER (ORDER BY currency) - 1 AS currency,\n",
    "            DENSE_RANK() OVER (ORDER BY merchant_id) - 1 AS merchant_id,\n",
    "            DENSE_RANK() OVER (ORDER BY payment_method) - 1 AS payment_method,\n",
    "            DENSE_RANK() OVER (ORDER BY product_category) - 1 AS product_category,\n",
    "            DENSE_RANK() OVER (ORDER BY transaction_type) - 1 AS transaction_type,\n",
    "            \n",
    "            -- JSON extraction + Label encoded\n",
    "            DENSE_RANK() OVER (ORDER BY json_extract_string(device_info, '$.browser')) - 1 AS browser,\n",
    "            DENSE_RANK() OVER (ORDER BY json_extract_string(device_info, '$.os')) - 1 AS os,\n",
    "\n",
    "            -- Timestamp components\n",
    "            CAST(date_part('year', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS year,\n",
    "            CAST(date_part('month', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS month,\n",
    "            CAST(date_part('day', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS day,\n",
    "            CAST(date_part('hour', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS hour,\n",
    "            CAST(date_part('minute', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS minute,\n",
    "            CAST(date_part('second', CAST(timestamp AS TIMESTAMP)) AS INTEGER) AS second,\n",
    "\n",
    "            -- Target\n",
    "            is_fraud\n",
    "\n",
    "        FROM delta_scan('{delta_path}')\n",
    "        \"\"\"\n",
    "        print(f\"Loading data for XGBoost (label encoded integers)...\")\n",
    "\n",
    "    # Add sampling clause\n",
    "    if sample_frac is not None and 0 < sample_frac < 1:\n",
    "        query += f\" USING SAMPLE {sample_frac * 100}%\"\n",
    "        print(f\"  Sampling: {sample_frac * 100}%\")\n",
    "\n",
    "    # Add limit clause\n",
    "    if max_rows is not None:\n",
    "        query += f\" LIMIT {max_rows}\"\n",
    "        print(f\"  Max rows: {max_rows}\")\n",
    "\n",
    "    df = conn.execute(query).df()\n",
    "    print(f\"  Loaded {len(df)} rows with {len(df.columns)} columns\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for CatBoost (categorical strings)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9341ea933ebd4ba99c3da8e38d27e77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 1085213 rows with 18 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>cvv_provided</th>\n",
       "      <th>billing_address_match</th>\n",
       "      <th>currency</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>product_category</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>browser</th>\n",
       "      <th>os</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>463.77</td>\n",
       "      <td>556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CAD</td>\n",
       "      <td>merchant_43</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>travel</td>\n",
       "      <td>deposit</td>\n",
       "      <td>Safari</td>\n",
       "      <td>macOS</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157.54</td>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>JPY</td>\n",
       "      <td>merchant_70</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>luxury_items</td>\n",
       "      <td>purchase</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Linux</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312.80</td>\n",
       "      <td>1131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AUD</td>\n",
       "      <td>merchant_43</td>\n",
       "      <td>crypto</td>\n",
       "      <td>travel</td>\n",
       "      <td>purchase</td>\n",
       "      <td>Other</td>\n",
       "      <td>Linux</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.24</td>\n",
       "      <td>1444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>USD</td>\n",
       "      <td>merchant_52</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>clothing</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Linux</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>288.43</td>\n",
       "      <td>1752</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>USD</td>\n",
       "      <td>merchant_120</td>\n",
       "      <td>paypal</td>\n",
       "      <td>digital_goods</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>Safari</td>\n",
       "      <td>iOS</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount  account_age_days  cvv_provided  billing_address_match currency  \\\n",
       "0  463.77               556             1                      1      CAD   \n",
       "1  157.54               557             1                      1      JPY   \n",
       "2  312.80              1131             1                      1      AUD   \n",
       "3   81.24              1444             1                      1      USD   \n",
       "4  288.43              1752             1                      1      USD   \n",
       "\n",
       "    merchant_id payment_method product_category transaction_type  browser  \\\n",
       "0   merchant_43    credit_card           travel          deposit   Safari   \n",
       "1   merchant_70    credit_card     luxury_items         purchase  Firefox   \n",
       "2   merchant_43         crypto           travel         purchase    Other   \n",
       "3   merchant_52    credit_card         clothing       withdrawal     Edge   \n",
       "4  merchant_120         paypal    digital_goods       withdrawal   Safari   \n",
       "\n",
       "      os  year  month  day  hour  minute  second  is_fraud  \n",
       "0  macOS  2026      1   17    17      27       2         0  \n",
       "1  Linux  2026      1   17    17      27       3         0  \n",
       "2  Linux  2026      1   17    17      27       3         0  \n",
       "3  Linux  2026      1   17    17      27       3         0  \n",
       "4    iOS  2026      1   17    17      27       3         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model type FIRST - this determines which SQL query to use\n",
    "MODEL_TYPE = \"catboost\"  # \"catboost\" (primary) or \"xgboost\" (fallback for YellowBrick)\n",
    "\n",
    "# Load data with appropriate SQL query for the model type\n",
    "df = load_data_duckdb_sql(delta_path, model_type=MODEL_TYPE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1085213 entries, 0 to 1085212\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   amount                 1085213 non-null  float64\n",
      " 1   account_age_days       1085213 non-null  int32  \n",
      " 2   cvv_provided           1085213 non-null  int32  \n",
      " 3   billing_address_match  1085213 non-null  int32  \n",
      " 4   currency               1085213 non-null  object \n",
      " 5   merchant_id            1085213 non-null  object \n",
      " 6   payment_method         1085213 non-null  object \n",
      " 7   product_category       1085213 non-null  object \n",
      " 8   transaction_type       1085213 non-null  object \n",
      " 9   browser                1085213 non-null  object \n",
      " 10  os                     1085213 non-null  object \n",
      " 11  year                   1085213 non-null  int32  \n",
      " 12  month                  1085213 non-null  int32  \n",
      " 13  day                    1085213 non-null  int32  \n",
      " 14  hour                   1085213 non-null  int32  \n",
      " 15  minute                 1085213 non-null  int32  \n",
      " 16  second                 1085213 non-null  int32  \n",
      " 17  is_fraud               1085213 non-null  int32  \n",
      "dtypes: float64(1), int32(10), object(7)\n",
      "memory usage: 107.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## Process Batch Data\n",
    "\n",
    "Split features/target and prepare for training:\n",
    "- **CatBoost**: Convert categorical columns to `category` dtype (memory efficient + native handling)\n",
    "- **XGBoost**: All features already numeric from SQL label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_data_duckdb(\n",
    "    df: pd.DataFrame,\n",
    "    model_type: Literal[\"catboost\", \"xgboost\"] = \"catboost\",\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process batch data for model training.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame from load_data_duckdb_sql()\n",
    "        model_type: \"catboost\" or \"xgboost\" (determines dtype handling)\n",
    "        test_size: Fraction for test set\n",
    "        random_state: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Split features and target\n",
    "    y = df[\"is_fraud\"]\n",
    "    X = df.drop(\"is_fraud\", axis=1)\n",
    "    \n",
    "    if model_type == \"catboost\":\n",
    "        # Convert categorical columns to category dtype for CatBoost\n",
    "        for col in TFD_CATEGORICAL_FEATURES:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].astype(\"category\")\n",
    "        print(f\"Features: {len(X.columns)} ({len(TFD_NUMERICAL_FEATURES)} numeric, {len(TFD_CATEGORICAL_FEATURES)} category dtype)\")\n",
    "    else:\n",
    "        # XGBoost: all features already numeric from SQL label encoding\n",
    "        print(f\"Features: {len(X.columns)} (all numeric, label-encoded in SQL)\")\n",
    "    \n",
    "    # Stratified train/test split (keeps class balance)\n",
    "    print(f\"Splitting data: {1-test_size:.0%} train, {test_size:.0%} test (stratified)...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        stratify=y,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    \n",
    "    print(f\"  Training set: {len(X_train)} samples\")\n",
    "    print(f\"  Test set: {len(X_test)} samples\")\n",
    "    \n",
    "    # Calculate class balance\n",
    "    fraud_rate = y_train.sum() / len(y_train) * 100\n",
    "    print(f\"  Fraud rate in training set: {fraud_rate:.2f}%\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e6f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 17 (4 numeric, 13 category dtype)\n",
      "Splitting data: 80% train, 20% test (stratified)...\n",
      "  Training set: 868170 samples\n",
      "  Test set: 217043 samples\n",
      "  Fraud rate in training set: 1.00%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = process_batch_data_duckdb(df, model_type=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f7a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>cvv_provided</th>\n",
       "      <th>billing_address_match</th>\n",
       "      <th>currency</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>product_category</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>browser</th>\n",
       "      <th>os</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269378</th>\n",
       "      <td>398.38</td>\n",
       "      <td>1395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>merchant_78</td>\n",
       "      <td>paypal</td>\n",
       "      <td>luxury_items</td>\n",
       "      <td>payment</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Other</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518076</th>\n",
       "      <td>244.16</td>\n",
       "      <td>861</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AUD</td>\n",
       "      <td>merchant_11</td>\n",
       "      <td>debit_card</td>\n",
       "      <td>travel</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Windows</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506975</th>\n",
       "      <td>256.74</td>\n",
       "      <td>1141</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CAD</td>\n",
       "      <td>merchant_116</td>\n",
       "      <td>crypto</td>\n",
       "      <td>groceries</td>\n",
       "      <td>payment</td>\n",
       "      <td>Safari</td>\n",
       "      <td>macOS</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516981</th>\n",
       "      <td>368.74</td>\n",
       "      <td>1335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>USD</td>\n",
       "      <td>merchant_187</td>\n",
       "      <td>paypal</td>\n",
       "      <td>travel</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Windows</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178363</th>\n",
       "      <td>212.04</td>\n",
       "      <td>816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GBP</td>\n",
       "      <td>merchant_166</td>\n",
       "      <td>bank_transfer</td>\n",
       "      <td>electronics</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>iOS</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        amount  account_age_days  cvv_provided  billing_address_match  \\\n",
       "269378  398.38              1395             1                      1   \n",
       "518076  244.16               861             1                      1   \n",
       "506975  256.74              1141             1                      1   \n",
       "516981  368.74              1335             1                      1   \n",
       "178363  212.04               816             1                      1   \n",
       "\n",
       "       currency   merchant_id payment_method product_category  \\\n",
       "269378      EUR   merchant_78         paypal     luxury_items   \n",
       "518076      AUD   merchant_11     debit_card           travel   \n",
       "506975      CAD  merchant_116         crypto        groceries   \n",
       "516981      USD  merchant_187         paypal           travel   \n",
       "178363      GBP  merchant_166  bank_transfer      electronics   \n",
       "\n",
       "       transaction_type  browser       os  year month day hour minute second  \n",
       "269378          payment     Edge    Other  2026     1  13   15     39     50  \n",
       "518076       withdrawal   Safari  Windows  2026     1  14   12     32     39  \n",
       "506975          payment   Safari    macOS  2026     1  14   11     40     34  \n",
       "516981       withdrawal  Firefox  Windows  2026     1  14   12     27     28  \n",
       "178363       withdrawal   Chrome      iOS  2026     1  13    8     15     51  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a8b9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount                    float64\n",
       "account_age_days            int32\n",
       "cvv_provided                int32\n",
       "billing_address_match       int32\n",
       "currency                 category\n",
       "merchant_id              category\n",
       "payment_method           category\n",
       "product_category         category\n",
       "transaction_type         category\n",
       "browser                  category\n",
       "os                       category\n",
       "year                     category\n",
       "month                    category\n",
       "day                      category\n",
       "hour                     category\n",
       "minute                   category\n",
       "second                   category\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g8b9c0d1",
   "metadata": {},
   "source": [
    "## Model Creation (CatBoost Primary, XGBoost Fallback)\n",
    "\n",
    "### CatBoost (Primary)\n",
    "Optimal for fraud detection with categorical features:\n",
    "- **Native categorical handling** - no encoding needed (but we encode in SQL for uniformity)\n",
    "- **`auto_class_weights='Balanced'`** - handles class imbalance automatically\n",
    "- **Built-in regularization** - L2 leaf regularization, early stopping\n",
    "\n",
    "### XGBoost (Fallback for YellowBrick)\n",
    "sklearn-native, useful for testing YellowBrick visualizations:\n",
    "- **`scale_pos_weight`** - handles class imbalance (neg/pos ratio)\n",
    "- **sklearn BaseEstimator** - full compatibility with sklearn ecosystem\n",
    "- **Fast histogram-based** - efficient training on large datasets\n",
    "\n",
    "### Optimized Parameters\n",
    "\n",
    "Based on [CatBoost docs](https://catboost.ai/docs/en/references/training-parameters/common) and [fraud detection research](https://www.preprints.org/manuscript/202503.1199):\n",
    "\n",
    "| Parameter | CatBoost | XGBoost |\n",
    "|-----------|----------|---------|\n",
    "| **Iterations** | 1000 | 500 |\n",
    "| **Learning Rate** | 0.05 | 0.1 |\n",
    "| **Depth** | 6 | 6 |\n",
    "| **Regularization** | l2_leaf_reg=3 | reg_alpha=0.1, reg_lambda=1.0 |\n",
    "| **Imbalance** | auto_class_weights='Balanced' | scale_pos_weight |\n",
    "| **Boosting Type** | Plain (1M+ rows) | hist |\n",
    "| **Early Stopping** | 50 rounds | 50 rounds |\n",
    "\n",
    "**Note**: `boosting_type='Plain'` is recommended for large datasets (1M+ rows). Use `'Ordered'` for smaller datasets (<100K rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d4ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def create_batch_model(\n",
    "    model_type: Literal[\"catboost\", \"xgboost\"] = \"catboost\",\n",
    "    y_train=None,\n",
    "    cat_feature_indices: list[int] | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create classifier optimized for fraud detection.\n",
    "    \n",
    "    Args:\n",
    "        model_type: \"catboost\" (primary) or \"xgboost\" (fallback for YellowBrick)\n",
    "        y_train: Training labels for calculating class imbalance ratio\n",
    "        cat_feature_indices: Indices of categorical features (for CatBoost)\n",
    "    \n",
    "    Returns:\n",
    "        Configured classifier ready for training\n",
    "    \n",
    "    References:\n",
    "        - CatBoost docs: https://catboost.ai/docs/en/references/training-parameters/common\n",
    "        - Fraud detection research: CatBoost achieves F1=0.92, AUC=0.99\n",
    "    \"\"\"\n",
    "    # Calculate class imbalance ratio\n",
    "    scale_pos_weight = 1.0\n",
    "    if y_train is not None:\n",
    "        neg_samples = sum(y_train == 0)\n",
    "        pos_samples = sum(y_train == 1)\n",
    "        if pos_samples > 0:\n",
    "            scale_pos_weight = neg_samples / pos_samples\n",
    "        print(f\"Class imbalance ratio: {scale_pos_weight:.2f}:1 (negative:positive)\")\n",
    "        print(f\"Fraud rate: {pos_samples / len(y_train) * 100:.2f}%\")\n",
    "    \n",
    "    if model_type == \"catboost\":\n",
    "        print(f\"Creating CatBoostClassifier (primary model)\")\n",
    "        print(f\"  Using auto_class_weights='Balanced' for imbalanced data\")\n",
    "        if cat_feature_indices:\n",
    "            print(f\"  Categorical feature indices: {cat_feature_indices}\")\n",
    "        \n",
    "        # Optimized CatBoost parameters for fraud detection (1M+ rows, ~1% fraud)\n",
    "        model = CatBoostClassifier(\n",
    "            # Core parameters\n",
    "            iterations=1000,                # Max trees; early stopping finds optimal\n",
    "            learning_rate=0.05,             # Good balance for 1M+ rows\n",
    "            depth=6,                        # CatBoost default, good for most cases\n",
    "            \n",
    "            # Imbalanced data handling (critical for fraud detection)\n",
    "            auto_class_weights='Balanced',  # Weights positive class by neg/pos ratio\n",
    "            \n",
    "            # Loss function & evaluation\n",
    "            loss_function='Logloss',        # Binary cross-entropy\n",
    "            eval_metric='AUC',              # Best for imbalanced binary classification\n",
    "            \n",
    "            # Regularization\n",
    "            l2_leaf_reg=3,                  # L2 regularization (default=3)\n",
    "            \n",
    "            # Boosting type: 'Plain' for large datasets (1M+), 'Ordered' for <100K\n",
    "            boosting_type='Plain',\n",
    "            \n",
    "            # Early stopping\n",
    "            early_stopping_rounds=50,\n",
    "            \n",
    "            # Performance\n",
    "            task_type='CPU',\n",
    "            thread_count=-1,                # Use all CPU cores\n",
    "            random_seed=42,\n",
    "            \n",
    "            # Output\n",
    "            verbose=True,\n",
    "        )\n",
    "    \n",
    "    elif model_type == \"xgboost\":\n",
    "        print(f\"Creating XGBClassifier (fallback for YellowBrick testing)\")\n",
    "        print(f\"  Using scale_pos_weight={scale_pos_weight:.2f}\")\n",
    "        \n",
    "        model = XGBClassifier(\n",
    "            # Core parameters\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            \n",
    "            # Imbalanced data handling\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            \n",
    "            # Regularization (prevent overfitting)\n",
    "            min_child_weight=1,\n",
    "            gamma=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,  # L1 regularization\n",
    "            reg_lambda=1.0,  # L2 regularization\n",
    "            \n",
    "            # Training settings\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='auc',\n",
    "            \n",
    "            # Early stopping\n",
    "            early_stopping_rounds=50,\n",
    "            \n",
    "            # Performance\n",
    "            tree_method='hist',\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}. Use 'catboost' or 'xgboost'.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ec9b98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance ratio: 99.17:1 (negative:positive)\n",
      "Fraud rate: 1.00%\n",
      "Creating CatBoostClassifier (primary model)\n",
      "  Using auto_class_weights='Balanced' for imbalanced data\n",
      "  Categorical feature indices: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "# Create model using MODEL_TYPE defined earlier (determines both query and model)\n",
    "model = create_batch_model(\n",
    "    model_type=MODEL_TYPE,\n",
    "    y_train=y_train,\n",
    "    cat_feature_indices=TFD_CAT_FEATURE_INDICES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h9c0d1e2",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Training with all-numeric features (label-encoded in DuckDB SQL).\n",
    "\n",
    "- **CatBoost**: Pass `cat_features` for native categorical handling (optional since encoded)\n",
    "- **XGBoost**: All features already numeric, no extra params needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d16129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9889922\tbest: 0.9889922 (0)\ttotal: 4.3s\tremaining: 1h 11m 32s\n",
      "1:\ttest: 0.9899321\tbest: 0.9899321 (1)\ttotal: 8.62s\tremaining: 1h 11m 40s\n",
      "2:\ttest: 0.9897926\tbest: 0.9899321 (1)\ttotal: 12s\tremaining: 1h 6m 12s\n",
      "3:\ttest: 0.9891783\tbest: 0.9899321 (1)\ttotal: 17s\tremaining: 1h 10m 34s\n",
      "4:\ttest: 0.9891432\tbest: 0.9899321 (1)\ttotal: 23.2s\tremaining: 1h 16m 57s\n",
      "5:\ttest: 0.9891968\tbest: 0.9899321 (1)\ttotal: 32.6s\tremaining: 1h 30m 6s\n",
      "6:\ttest: 0.9893614\tbest: 0.9899321 (1)\ttotal: 38.7s\tremaining: 1h 31m 23s\n",
      "7:\ttest: 0.9896820\tbest: 0.9899321 (1)\ttotal: 44.2s\tremaining: 1h 31m 14s\n",
      "8:\ttest: 0.9899649\tbest: 0.9899649 (8)\ttotal: 50.1s\tremaining: 1h 31m 58s\n",
      "9:\ttest: 0.9899759\tbest: 0.9899759 (9)\ttotal: 56.9s\tremaining: 1h 33m 49s\n",
      "10:\ttest: 0.9901069\tbest: 0.9901069 (10)\ttotal: 1m 3s\tremaining: 1h 34m 45s\n",
      "11:\ttest: 0.9901144\tbest: 0.9901144 (11)\ttotal: 1m 5s\tremaining: 1h 29m 49s\n",
      "12:\ttest: 0.9925603\tbest: 0.9925603 (12)\ttotal: 1m 9s\tremaining: 1h 28m 28s\n",
      "13:\ttest: 0.9926791\tbest: 0.9926791 (13)\ttotal: 1m 13s\tremaining: 1h 26m 28s\n",
      "14:\ttest: 0.9927600\tbest: 0.9927600 (14)\ttotal: 1m 17s\tremaining: 1h 24m 41s\n",
      "15:\ttest: 0.9927433\tbest: 0.9927600 (14)\ttotal: 1m 21s\tremaining: 1h 23m 45s\n",
      "16:\ttest: 0.9927856\tbest: 0.9927856 (16)\ttotal: 1m 27s\tremaining: 1h 23m 54s\n",
      "17:\ttest: 0.9927616\tbest: 0.9927856 (16)\ttotal: 1m 33s\tremaining: 1h 24m 40s\n",
      "18:\ttest: 0.9927546\tbest: 0.9927856 (16)\ttotal: 1m 37s\tremaining: 1h 24m 8s\n",
      "19:\ttest: 0.9927456\tbest: 0.9927856 (16)\ttotal: 1m 43s\tremaining: 1h 24m 20s\n",
      "20:\ttest: 0.9928253\tbest: 0.9928253 (20)\ttotal: 1m 47s\tremaining: 1h 23m 15s\n",
      "21:\ttest: 0.9928174\tbest: 0.9928253 (20)\ttotal: 1m 51s\tremaining: 1h 22m 54s\n",
      "22:\ttest: 0.9927924\tbest: 0.9928253 (20)\ttotal: 1m 56s\tremaining: 1h 22m 42s\n",
      "23:\ttest: 0.9927934\tbest: 0.9928253 (20)\ttotal: 1m 58s\tremaining: 1h 20m 35s\n",
      "24:\ttest: 0.9927955\tbest: 0.9928253 (20)\ttotal: 2m 2s\tremaining: 1h 19m 34s\n",
      "25:\ttest: 0.9927985\tbest: 0.9928253 (20)\ttotal: 2m 7s\tremaining: 1h 19m 19s\n",
      "26:\ttest: 0.9928068\tbest: 0.9928253 (20)\ttotal: 2m 10s\tremaining: 1h 18m 11s\n",
      "27:\ttest: 0.9928503\tbest: 0.9928503 (27)\ttotal: 2m 15s\tremaining: 1h 18m 21s\n",
      "28:\ttest: 0.9928384\tbest: 0.9928503 (27)\ttotal: 2m 18s\tremaining: 1h 17m 7s\n",
      "29:\ttest: 0.9928133\tbest: 0.9928503 (27)\ttotal: 2m 24s\tremaining: 1h 17m 41s\n",
      "30:\ttest: 0.9928125\tbest: 0.9928503 (27)\ttotal: 2m 25s\tremaining: 1h 16m\n",
      "31:\ttest: 0.9928135\tbest: 0.9928503 (27)\ttotal: 2m 29s\tremaining: 1h 15m 7s\n",
      "32:\ttest: 0.9927841\tbest: 0.9928503 (27)\ttotal: 2m 36s\tremaining: 1h 16m 37s\n",
      "33:\ttest: 0.9927843\tbest: 0.9928503 (27)\ttotal: 2m 42s\tremaining: 1h 17m 4s\n",
      "34:\ttest: 0.9927853\tbest: 0.9928503 (27)\ttotal: 2m 46s\tremaining: 1h 16m 19s\n",
      "35:\ttest: 0.9927796\tbest: 0.9928503 (27)\ttotal: 2m 50s\tremaining: 1h 15m 53s\n",
      "36:\ttest: 0.9927795\tbest: 0.9928503 (27)\ttotal: 2m 51s\tremaining: 1h 14m 26s\n",
      "37:\ttest: 0.9928046\tbest: 0.9928503 (27)\ttotal: 2m 57s\tremaining: 1h 14m 50s\n",
      "38:\ttest: 0.9928138\tbest: 0.9928503 (27)\ttotal: 3m 1s\tremaining: 1h 14m 23s\n",
      "39:\ttest: 0.9928104\tbest: 0.9928503 (27)\ttotal: 3m 5s\tremaining: 1h 14m 22s\n",
      "40:\ttest: 0.9928062\tbest: 0.9928503 (27)\ttotal: 3m 8s\tremaining: 1h 13m 36s\n",
      "41:\ttest: 0.9928045\tbest: 0.9928503 (27)\ttotal: 3m 11s\tremaining: 1h 12m 50s\n",
      "42:\ttest: 0.9928048\tbest: 0.9928503 (27)\ttotal: 3m 14s\tremaining: 1h 11m 58s\n",
      "43:\ttest: 0.9928074\tbest: 0.9928503 (27)\ttotal: 3m 16s\tremaining: 1h 11m 11s\n",
      "44:\ttest: 0.9928081\tbest: 0.9928503 (27)\ttotal: 3m 20s\tremaining: 1h 10m 58s\n",
      "45:\ttest: 0.9928879\tbest: 0.9928879 (45)\ttotal: 3m 27s\tremaining: 1h 11m 39s\n",
      "46:\ttest: 0.9928859\tbest: 0.9928879 (45)\ttotal: 3m 29s\tremaining: 1h 10m 54s\n",
      "47:\ttest: 0.9928869\tbest: 0.9928879 (45)\ttotal: 3m 31s\tremaining: 1h 9m 54s\n",
      "48:\ttest: 0.9929133\tbest: 0.9929133 (48)\ttotal: 3m 36s\tremaining: 1h 10m 5s\n",
      "49:\ttest: 0.9929103\tbest: 0.9929133 (48)\ttotal: 3m 39s\tremaining: 1h 9m 32s\n",
      "50:\ttest: 0.9929059\tbest: 0.9929133 (48)\ttotal: 3m 43s\tremaining: 1h 9m 12s\n",
      "51:\ttest: 0.9929154\tbest: 0.9929154 (51)\ttotal: 3m 44s\tremaining: 1h 8m 15s\n",
      "52:\ttest: 0.9929081\tbest: 0.9929154 (51)\ttotal: 3m 48s\tremaining: 1h 8m 7s\n",
      "53:\ttest: 0.9929031\tbest: 0.9929154 (51)\ttotal: 3m 53s\tremaining: 1h 8m 3s\n",
      "54:\ttest: 0.9929034\tbest: 0.9929154 (51)\ttotal: 3m 56s\tremaining: 1h 7m 37s\n",
      "55:\ttest: 0.9928792\tbest: 0.9929154 (51)\ttotal: 3m 58s\tremaining: 1h 7m 3s\n",
      "56:\ttest: 0.9928743\tbest: 0.9929154 (51)\ttotal: 4m\tremaining: 1h 6m 19s\n",
      "57:\ttest: 0.9928758\tbest: 0.9929154 (51)\ttotal: 4m 5s\tremaining: 1h 6m 33s\n",
      "58:\ttest: 0.9928737\tbest: 0.9929154 (51)\ttotal: 4m 7s\tremaining: 1h 5m 43s\n",
      "59:\ttest: 0.9928725\tbest: 0.9929154 (51)\ttotal: 4m 8s\tremaining: 1h 4m 58s\n",
      "60:\ttest: 0.9928714\tbest: 0.9929154 (51)\ttotal: 4m 13s\tremaining: 1h 5m 7s\n",
      "61:\ttest: 0.9928758\tbest: 0.9929154 (51)\ttotal: 4m 18s\tremaining: 1h 5m 17s\n",
      "62:\ttest: 0.9928584\tbest: 0.9929154 (51)\ttotal: 4m 20s\tremaining: 1h 4m 36s\n",
      "63:\ttest: 0.9928921\tbest: 0.9929154 (51)\ttotal: 4m 24s\tremaining: 1h 4m 34s\n",
      "64:\ttest: 0.9928979\tbest: 0.9929154 (51)\ttotal: 4m 29s\tremaining: 1h 4m 33s\n",
      "65:\ttest: 0.9928935\tbest: 0.9929154 (51)\ttotal: 4m 34s\tremaining: 1h 4m 45s\n",
      "66:\ttest: 0.9928951\tbest: 0.9929154 (51)\ttotal: 4m 40s\tremaining: 1h 4m 59s\n",
      "67:\ttest: 0.9928951\tbest: 0.9929154 (51)\ttotal: 4m 40s\tremaining: 1h 4m 10s\n",
      "68:\ttest: 0.9928937\tbest: 0.9929154 (51)\ttotal: 4m 42s\tremaining: 1h 3m 32s\n",
      "69:\ttest: 0.9928933\tbest: 0.9929154 (51)\ttotal: 4m 44s\tremaining: 1h 2m 56s\n",
      "70:\ttest: 0.9928888\tbest: 0.9929154 (51)\ttotal: 4m 46s\tremaining: 1h 2m 25s\n",
      "71:\ttest: 0.9928895\tbest: 0.9929154 (51)\ttotal: 4m 47s\tremaining: 1h 1m 49s\n",
      "72:\ttest: 0.9928867\tbest: 0.9929154 (51)\ttotal: 4m 49s\tremaining: 1h 1m 15s\n",
      "73:\ttest: 0.9928867\tbest: 0.9929154 (51)\ttotal: 4m 50s\tremaining: 1h 30s\n",
      "74:\ttest: 0.9928874\tbest: 0.9929154 (51)\ttotal: 4m 52s\tremaining: 1h 7s\n",
      "75:\ttest: 0.9929183\tbest: 0.9929183 (75)\ttotal: 4m 56s\tremaining: 1h 6s\n",
      "76:\ttest: 0.9929227\tbest: 0.9929227 (76)\ttotal: 5m 1s\tremaining: 1h 8s\n",
      "77:\ttest: 0.9929236\tbest: 0.9929236 (77)\ttotal: 5m 4s\tremaining: 1h 3s\n",
      "78:\ttest: 0.9929292\tbest: 0.9929292 (78)\ttotal: 5m 7s\tremaining: 59m 40s\n",
      "79:\ttest: 0.9929288\tbest: 0.9929292 (78)\ttotal: 5m 11s\tremaining: 59m 37s\n",
      "80:\ttest: 0.9929205\tbest: 0.9929292 (78)\ttotal: 5m 14s\tremaining: 59m 31s\n",
      "81:\ttest: 0.9929206\tbest: 0.9929292 (78)\ttotal: 5m 16s\tremaining: 59m\n",
      "82:\ttest: 0.9929307\tbest: 0.9929307 (82)\ttotal: 5m 17s\tremaining: 58m 32s\n",
      "83:\ttest: 0.9929390\tbest: 0.9929390 (83)\ttotal: 5m 20s\tremaining: 58m 19s\n",
      "84:\ttest: 0.9929580\tbest: 0.9929580 (84)\ttotal: 5m 26s\tremaining: 58m 35s\n",
      "85:\ttest: 0.9929369\tbest: 0.9929580 (84)\ttotal: 5m 34s\tremaining: 59m 9s\n",
      "86:\ttest: 0.9929455\tbest: 0.9929580 (84)\ttotal: 5m 37s\tremaining: 58m 57s\n",
      "87:\ttest: 0.9929499\tbest: 0.9929580 (84)\ttotal: 5m 38s\tremaining: 58m 28s\n",
      "88:\ttest: 0.9929500\tbest: 0.9929580 (84)\ttotal: 5m 40s\tremaining: 58m 6s\n",
      "89:\ttest: 0.9929472\tbest: 0.9929580 (84)\ttotal: 5m 42s\tremaining: 57m 38s\n",
      "90:\ttest: 0.9929472\tbest: 0.9929580 (84)\ttotal: 5m 42s\tremaining: 57m 5s\n",
      "91:\ttest: 0.9929497\tbest: 0.9929580 (84)\ttotal: 5m 47s\tremaining: 57m 11s\n",
      "92:\ttest: 0.9929536\tbest: 0.9929580 (84)\ttotal: 5m 49s\tremaining: 56m 46s\n",
      "93:\ttest: 0.9929536\tbest: 0.9929580 (84)\ttotal: 5m 52s\tremaining: 56m 35s\n",
      "94:\ttest: 0.9929369\tbest: 0.9929580 (84)\ttotal: 5m 54s\tremaining: 56m 16s\n",
      "95:\ttest: 0.9929365\tbest: 0.9929580 (84)\ttotal: 5m 59s\tremaining: 56m 21s\n",
      "96:\ttest: 0.9929805\tbest: 0.9929805 (96)\ttotal: 6m 4s\tremaining: 56m 28s\n",
      "97:\ttest: 0.9929849\tbest: 0.9929849 (97)\ttotal: 6m 10s\tremaining: 56m 49s\n",
      "98:\ttest: 0.9929849\tbest: 0.9929849 (97)\ttotal: 6m 12s\tremaining: 56m 26s\n",
      "99:\ttest: 0.9929849\tbest: 0.9929849 (97)\ttotal: 6m 13s\tremaining: 56m\n",
      "100:\ttest: 0.9929250\tbest: 0.9929849 (97)\ttotal: 6m 19s\tremaining: 56m 17s\n",
      "101:\ttest: 0.9929253\tbest: 0.9929849 (97)\ttotal: 6m 22s\tremaining: 56m 3s\n",
      "102:\ttest: 0.9929253\tbest: 0.9929849 (97)\ttotal: 6m 23s\tremaining: 55m 36s\n",
      "103:\ttest: 0.9929250\tbest: 0.9929849 (97)\ttotal: 6m 24s\tremaining: 55m 15s\n",
      "104:\ttest: 0.9929250\tbest: 0.9929849 (97)\ttotal: 6m 25s\tremaining: 54m 46s\n",
      "105:\ttest: 0.9929250\tbest: 0.9929849 (97)\ttotal: 6m 29s\tremaining: 54m 43s\n",
      "106:\ttest: 0.9929254\tbest: 0.9929849 (97)\ttotal: 6m 30s\tremaining: 54m 21s\n",
      "107:\ttest: 0.9929246\tbest: 0.9929849 (97)\ttotal: 6m 34s\tremaining: 54m 19s\n",
      "108:\ttest: 0.9929264\tbest: 0.9929849 (97)\ttotal: 6m 40s\tremaining: 54m 32s\n",
      "109:\ttest: 0.9929112\tbest: 0.9929849 (97)\ttotal: 6m 43s\tremaining: 54m 28s\n",
      "110:\ttest: 0.9929114\tbest: 0.9929849 (97)\ttotal: 6m 49s\tremaining: 54m 39s\n",
      "111:\ttest: 0.9929114\tbest: 0.9929849 (97)\ttotal: 6m 53s\tremaining: 54m 34s\n",
      "112:\ttest: 0.9929116\tbest: 0.9929849 (97)\ttotal: 6m 54s\tremaining: 54m 12s\n",
      "113:\ttest: 0.9929116\tbest: 0.9929849 (97)\ttotal: 6m 55s\tremaining: 53m 47s\n",
      "114:\ttest: 0.9929116\tbest: 0.9929849 (97)\ttotal: 6m 58s\tremaining: 53m 40s\n",
      "115:\ttest: 0.9929306\tbest: 0.9929849 (97)\ttotal: 7m 4s\tremaining: 53m 54s\n",
      "116:\ttest: 0.9928960\tbest: 0.9929849 (97)\ttotal: 7m 12s\tremaining: 54m 23s\n",
      "117:\ttest: 0.9928998\tbest: 0.9929849 (97)\ttotal: 7m 16s\tremaining: 54m 23s\n",
      "118:\ttest: 0.9928992\tbest: 0.9929849 (97)\ttotal: 7m 18s\tremaining: 54m 4s\n",
      "119:\ttest: 0.9928992\tbest: 0.9929849 (97)\ttotal: 7m 20s\tremaining: 53m 46s\n",
      "120:\ttest: 0.9928986\tbest: 0.9929849 (97)\ttotal: 7m 21s\tremaining: 53m 30s\n",
      "121:\ttest: 0.9928992\tbest: 0.9929849 (97)\ttotal: 7m 23s\tremaining: 53m 13s\n",
      "122:\ttest: 0.9928992\tbest: 0.9929849 (97)\ttotal: 7m 24s\tremaining: 52m 51s\n",
      "123:\ttest: 0.9929514\tbest: 0.9929849 (97)\ttotal: 7m 30s\tremaining: 53m 1s\n",
      "124:\ttest: 0.9929514\tbest: 0.9929849 (97)\ttotal: 7m 31s\tremaining: 52m 41s\n",
      "125:\ttest: 0.9929514\tbest: 0.9929849 (97)\ttotal: 7m 34s\tremaining: 52m 35s\n",
      "126:\ttest: 0.9929523\tbest: 0.9929849 (97)\ttotal: 7m 40s\tremaining: 52m 47s\n",
      "127:\ttest: 0.9929518\tbest: 0.9929849 (97)\ttotal: 7m 45s\tremaining: 52m 52s\n",
      "128:\ttest: 0.9929529\tbest: 0.9929849 (97)\ttotal: 7m 48s\tremaining: 52m 44s\n",
      "129:\ttest: 0.9929529\tbest: 0.9929849 (97)\ttotal: 7m 50s\tremaining: 52m 29s\n",
      "130:\ttest: 0.9929519\tbest: 0.9929849 (97)\ttotal: 7m 53s\tremaining: 52m 18s\n",
      "131:\ttest: 0.9929705\tbest: 0.9929849 (97)\ttotal: 7m 55s\tremaining: 52m 8s\n",
      "132:\ttest: 0.9929705\tbest: 0.9929849 (97)\ttotal: 7m 56s\tremaining: 51m 44s\n",
      "133:\ttest: 0.9929718\tbest: 0.9929849 (97)\ttotal: 7m 59s\tremaining: 51m 37s\n",
      "134:\ttest: 0.9929730\tbest: 0.9929849 (97)\ttotal: 8m 4s\tremaining: 51m 42s\n",
      "135:\ttest: 0.9929730\tbest: 0.9929849 (97)\ttotal: 8m 5s\tremaining: 51m 27s\n",
      "136:\ttest: 0.9929730\tbest: 0.9929849 (97)\ttotal: 8m 7s\tremaining: 51m 8s\n",
      "137:\ttest: 0.9929730\tbest: 0.9929849 (97)\ttotal: 8m 8s\tremaining: 50m 51s\n",
      "138:\ttest: 0.9929761\tbest: 0.9929849 (97)\ttotal: 8m 12s\tremaining: 50m 48s\n",
      "139:\ttest: 0.9929761\tbest: 0.9929849 (97)\ttotal: 8m 13s\tremaining: 50m 28s\n",
      "140:\ttest: 0.9929761\tbest: 0.9929849 (97)\ttotal: 8m 13s\tremaining: 50m 7s\n",
      "141:\ttest: 0.9929700\tbest: 0.9929849 (97)\ttotal: 8m 17s\tremaining: 50m 4s\n",
      "142:\ttest: 0.9929638\tbest: 0.9929849 (97)\ttotal: 8m 22s\tremaining: 50m 9s\n",
      "143:\ttest: 0.9929638\tbest: 0.9929849 (97)\ttotal: 8m 23s\tremaining: 49m 52s\n",
      "144:\ttest: 0.9929666\tbest: 0.9929849 (97)\ttotal: 8m 29s\tremaining: 50m 3s\n",
      "145:\ttest: 0.9929666\tbest: 0.9929849 (97)\ttotal: 8m 30s\tremaining: 49m 47s\n",
      "146:\ttest: 0.9929656\tbest: 0.9929849 (97)\ttotal: 8m 34s\tremaining: 49m 48s\n",
      "147:\ttest: 0.9929889\tbest: 0.9929889 (147)\ttotal: 8m 38s\tremaining: 49m 45s\n",
      "148:\ttest: 0.9929889\tbest: 0.9929889 (147)\ttotal: 8m 40s\tremaining: 49m 31s\n",
      "149:\ttest: 0.9929769\tbest: 0.9929889 (147)\ttotal: 8m 47s\tremaining: 49m 46s\n",
      "150:\ttest: 0.9929810\tbest: 0.9929889 (147)\ttotal: 8m 57s\tremaining: 50m 19s\n",
      "151:\ttest: 0.9929768\tbest: 0.9929889 (147)\ttotal: 9m 2s\tremaining: 50m 28s\n",
      "152:\ttest: 0.9929768\tbest: 0.9929889 (147)\ttotal: 9m 4s\tremaining: 50m 14s\n",
      "153:\ttest: 0.9929768\tbest: 0.9929889 (147)\ttotal: 9m 6s\tremaining: 49m 59s\n",
      "154:\ttest: 0.9929755\tbest: 0.9929889 (147)\ttotal: 9m 8s\tremaining: 49m 52s\n",
      "155:\ttest: 0.9929773\tbest: 0.9929889 (147)\ttotal: 9m 17s\tremaining: 50m 15s\n",
      "156:\ttest: 0.9929692\tbest: 0.9929889 (147)\ttotal: 9m 32s\tremaining: 51m 12s\n",
      "157:\ttest: 0.9929667\tbest: 0.9929889 (147)\ttotal: 9m 41s\tremaining: 51m 38s\n",
      "158:\ttest: 0.9929497\tbest: 0.9929889 (147)\ttotal: 9m 44s\tremaining: 51m 31s\n",
      "159:\ttest: 0.9929497\tbest: 0.9929889 (147)\ttotal: 9m 45s\tremaining: 51m 12s\n",
      "160:\ttest: 0.9929497\tbest: 0.9929889 (147)\ttotal: 9m 47s\tremaining: 50m 59s\n",
      "161:\ttest: 0.9929497\tbest: 0.9929889 (147)\ttotal: 9m 48s\tremaining: 50m 44s\n",
      "162:\ttest: 0.9929493\tbest: 0.9929889 (147)\ttotal: 9m 51s\tremaining: 50m 35s\n",
      "163:\ttest: 0.9929494\tbest: 0.9929889 (147)\ttotal: 9m 54s\tremaining: 50m 30s\n",
      "164:\ttest: 0.9929493\tbest: 0.9929889 (147)\ttotal: 9m 58s\tremaining: 50m 26s\n",
      "165:\ttest: 0.9929493\tbest: 0.9929889 (147)\ttotal: 9m 59s\tremaining: 50m 13s\n",
      "166:\ttest: 0.9929492\tbest: 0.9929889 (147)\ttotal: 10m 2s\tremaining: 50m 3s\n",
      "167:\ttest: 0.9929492\tbest: 0.9929889 (147)\ttotal: 10m 3s\tremaining: 49m 49s\n",
      "168:\ttest: 0.9929490\tbest: 0.9929889 (147)\ttotal: 10m 6s\tremaining: 49m 42s\n",
      "169:\ttest: 0.9929438\tbest: 0.9929889 (147)\ttotal: 10m 7s\tremaining: 49m 27s\n",
      "170:\ttest: 0.9929438\tbest: 0.9929889 (147)\ttotal: 10m 9s\tremaining: 49m 16s\n",
      "171:\ttest: 0.9929438\tbest: 0.9929889 (147)\ttotal: 10m 11s\tremaining: 49m 1s\n",
      "172:\ttest: 0.9929420\tbest: 0.9929889 (147)\ttotal: 10m 12s\tremaining: 48m 47s\n",
      "173:\ttest: 0.9929426\tbest: 0.9929889 (147)\ttotal: 10m 14s\tremaining: 48m 39s\n",
      "174:\ttest: 0.9929647\tbest: 0.9929889 (147)\ttotal: 10m 19s\tremaining: 48m 40s\n",
      "175:\ttest: 0.9929647\tbest: 0.9929889 (147)\ttotal: 10m 20s\tremaining: 48m 24s\n",
      "176:\ttest: 0.9929647\tbest: 0.9929889 (147)\ttotal: 10m 21s\tremaining: 48m 8s\n",
      "177:\ttest: 0.9929647\tbest: 0.9929889 (147)\ttotal: 10m 22s\tremaining: 47m 54s\n",
      "178:\ttest: 0.9929641\tbest: 0.9929889 (147)\ttotal: 10m 26s\tremaining: 47m 54s\n",
      "179:\ttest: 0.9929640\tbest: 0.9929889 (147)\ttotal: 10m 28s\tremaining: 47m 41s\n",
      "180:\ttest: 0.9929640\tbest: 0.9929889 (147)\ttotal: 10m 29s\tremaining: 47m 26s\n",
      "181:\ttest: 0.9929606\tbest: 0.9929889 (147)\ttotal: 10m 31s\tremaining: 47m 20s\n",
      "182:\ttest: 0.9929601\tbest: 0.9929889 (147)\ttotal: 10m 36s\tremaining: 47m 20s\n",
      "183:\ttest: 0.9929601\tbest: 0.9929889 (147)\ttotal: 10m 37s\tremaining: 47m 5s\n",
      "184:\ttest: 0.9929601\tbest: 0.9929889 (147)\ttotal: 10m 38s\tremaining: 46m 52s\n",
      "185:\ttest: 0.9929601\tbest: 0.9929889 (147)\ttotal: 10m 39s\tremaining: 46m 36s\n",
      "186:\ttest: 0.9929591\tbest: 0.9929889 (147)\ttotal: 10m 42s\tremaining: 46m 33s\n",
      "187:\ttest: 0.9929591\tbest: 0.9929889 (147)\ttotal: 10m 44s\tremaining: 46m 21s\n",
      "188:\ttest: 0.9929591\tbest: 0.9929889 (147)\ttotal: 10m 49s\tremaining: 46m 28s\n",
      "189:\ttest: 0.9929591\tbest: 0.9929889 (147)\ttotal: 10m 53s\tremaining: 46m 24s\n",
      "190:\ttest: 0.9929591\tbest: 0.9929889 (147)\ttotal: 10m 54s\tremaining: 46m 13s\n",
      "191:\ttest: 0.9929580\tbest: 0.9929889 (147)\ttotal: 11m\tremaining: 46m 19s\n",
      "192:\ttest: 0.9929580\tbest: 0.9929889 (147)\ttotal: 11m 2s\tremaining: 46m 8s\n",
      "193:\ttest: 0.9929580\tbest: 0.9929889 (147)\ttotal: 11m 4s\tremaining: 46m\n",
      "194:\ttest: 0.9929604\tbest: 0.9929889 (147)\ttotal: 11m 12s\tremaining: 46m 16s\n",
      "195:\ttest: 0.9929604\tbest: 0.9929889 (147)\ttotal: 11m 13s\tremaining: 46m 4s\n",
      "196:\ttest: 0.9930218\tbest: 0.9930218 (196)\ttotal: 11m 24s\tremaining: 46m 29s\n",
      "197:\ttest: 0.9930218\tbest: 0.9930218 (196)\ttotal: 11m 25s\tremaining: 46m 15s\n",
      "198:\ttest: 0.9930218\tbest: 0.9930218 (196)\ttotal: 11m 26s\tremaining: 46m 1s\n",
      "199:\ttest: 0.9930215\tbest: 0.9930218 (196)\ttotal: 11m 28s\tremaining: 45m 54s\n",
      "200:\ttest: 0.9930177\tbest: 0.9930218 (196)\ttotal: 11m 31s\tremaining: 45m 50s\n",
      "201:\ttest: 0.9930177\tbest: 0.9930218 (196)\ttotal: 11m 37s\tremaining: 45m 54s\n",
      "202:\ttest: 0.9930177\tbest: 0.9930218 (196)\ttotal: 11m 38s\tremaining: 45m 43s\n",
      "203:\ttest: 0.9930177\tbest: 0.9930218 (196)\ttotal: 11m 42s\tremaining: 45m 42s\n",
      "204:\ttest: 0.9930177\tbest: 0.9930218 (196)\ttotal: 11m 45s\tremaining: 45m 35s\n",
      "205:\ttest: 0.9930177\tbest: 0.9930218 (196)\ttotal: 11m 46s\tremaining: 45m 23s\n",
      "206:\ttest: 0.9930119\tbest: 0.9930218 (196)\ttotal: 11m 50s\tremaining: 45m 20s\n",
      "207:\ttest: 0.9930064\tbest: 0.9930218 (196)\ttotal: 11m 59s\tremaining: 45m 38s\n",
      "208:\ttest: 0.9930069\tbest: 0.9930218 (196)\ttotal: 12m\tremaining: 45m 28s\n",
      "209:\ttest: 0.9930085\tbest: 0.9930218 (196)\ttotal: 12m 3s\tremaining: 45m 23s\n",
      "210:\ttest: 0.9930085\tbest: 0.9930218 (196)\ttotal: 12m 5s\tremaining: 45m 13s\n",
      "211:\ttest: 0.9930085\tbest: 0.9930218 (196)\ttotal: 12m 6s\tremaining: 45m 1s\n",
      "212:\ttest: 0.9930085\tbest: 0.9930218 (196)\ttotal: 12m 8s\tremaining: 44m 53s\n",
      "213:\ttest: 0.9930055\tbest: 0.9930218 (196)\ttotal: 12m 12s\tremaining: 44m 50s\n",
      "214:\ttest: 0.9930048\tbest: 0.9930218 (196)\ttotal: 12m 15s\tremaining: 44m 44s\n",
      "215:\ttest: 0.9930048\tbest: 0.9930218 (196)\ttotal: 12m 16s\tremaining: 44m 33s\n",
      "216:\ttest: 0.9930037\tbest: 0.9930218 (196)\ttotal: 12m 19s\tremaining: 44m 29s\n",
      "217:\ttest: 0.9930037\tbest: 0.9930218 (196)\ttotal: 12m 20s\tremaining: 44m 14s\n",
      "218:\ttest: 0.9930074\tbest: 0.9930218 (196)\ttotal: 12m 21s\tremaining: 44m 3s\n",
      "219:\ttest: 0.9930072\tbest: 0.9930218 (196)\ttotal: 12m 21s\tremaining: 43m 50s\n",
      "220:\ttest: 0.9930072\tbest: 0.9930218 (196)\ttotal: 12m 22s\tremaining: 43m 36s\n",
      "221:\ttest: 0.9930072\tbest: 0.9930218 (196)\ttotal: 12m 22s\tremaining: 43m 22s\n",
      "222:\ttest: 0.9929901\tbest: 0.9930218 (196)\ttotal: 12m 23s\tremaining: 43m 11s\n",
      "223:\ttest: 0.9929901\tbest: 0.9930218 (196)\ttotal: 12m 24s\tremaining: 42m 57s\n",
      "224:\ttest: 0.9929901\tbest: 0.9930218 (196)\ttotal: 12m 24s\tremaining: 42m 43s\n",
      "225:\ttest: 0.9930036\tbest: 0.9930218 (196)\ttotal: 12m 25s\tremaining: 42m 33s\n",
      "226:\ttest: 0.9930139\tbest: 0.9930218 (196)\ttotal: 12m 26s\tremaining: 42m 20s\n",
      "227:\ttest: 0.9930140\tbest: 0.9930218 (196)\ttotal: 12m 26s\tremaining: 42m 7s\n",
      "228:\ttest: 0.9930140\tbest: 0.9930218 (196)\ttotal: 12m 26s\tremaining: 41m 54s\n",
      "229:\ttest: 0.9930144\tbest: 0.9930218 (196)\ttotal: 12m 27s\tremaining: 41m 43s\n",
      "230:\ttest: 0.9930144\tbest: 0.9930218 (196)\ttotal: 12m 28s\tremaining: 41m 30s\n",
      "231:\ttest: 0.9930505\tbest: 0.9930505 (231)\ttotal: 12m 29s\tremaining: 41m 22s\n",
      "232:\ttest: 0.9930505\tbest: 0.9930505 (231)\ttotal: 12m 31s\tremaining: 41m 13s\n",
      "233:\ttest: 0.9930505\tbest: 0.9930505 (231)\ttotal: 12m 31s\tremaining: 41m\n",
      "234:\ttest: 0.9930479\tbest: 0.9930505 (231)\ttotal: 12m 32s\tremaining: 40m 48s\n",
      "235:\ttest: 0.9930478\tbest: 0.9930505 (231)\ttotal: 12m 32s\tremaining: 40m 36s\n",
      "236:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 33s\tremaining: 40m 27s\n",
      "237:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 34s\tremaining: 40m 14s\n",
      "238:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 34s\tremaining: 40m 2s\n",
      "239:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 35s\tremaining: 39m 53s\n",
      "240:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 36s\tremaining: 39m 41s\n",
      "241:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 36s\tremaining: 39m 29s\n",
      "242:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 36s\tremaining: 39m 17s\n",
      "243:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 38s\tremaining: 39m 8s\n",
      "244:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 39s\tremaining: 39m 1s\n",
      "245:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 40s\tremaining: 38m 49s\n",
      "246:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 40s\tremaining: 38m 38s\n",
      "247:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 40s\tremaining: 38m 27s\n",
      "248:\ttest: 0.9930322\tbest: 0.9930505 (231)\ttotal: 12m 41s\tremaining: 38m 16s\n",
      "249:\ttest: 0.9930304\tbest: 0.9930505 (231)\ttotal: 12m 42s\tremaining: 38m 7s\n",
      "250:\ttest: 0.9930304\tbest: 0.9930505 (231)\ttotal: 12m 42s\tremaining: 37m 56s\n",
      "251:\ttest: 0.9930351\tbest: 0.9930505 (231)\ttotal: 12m 45s\tremaining: 37m 50s\n",
      "252:\ttest: 0.9930348\tbest: 0.9930505 (231)\ttotal: 12m 45s\tremaining: 37m 40s\n",
      "253:\ttest: 0.9930346\tbest: 0.9930505 (231)\ttotal: 12m 46s\tremaining: 37m 30s\n",
      "254:\ttest: 0.9930402\tbest: 0.9930505 (231)\ttotal: 12m 46s\tremaining: 37m 20s\n",
      "255:\ttest: 0.9930391\tbest: 0.9930505 (231)\ttotal: 12m 47s\tremaining: 37m 11s\n",
      "256:\ttest: 0.9930391\tbest: 0.9930505 (231)\ttotal: 12m 48s\tremaining: 37m 1s\n",
      "257:\ttest: 0.9931058\tbest: 0.9931058 (257)\ttotal: 12m 50s\tremaining: 36m 54s\n",
      "258:\ttest: 0.9931026\tbest: 0.9931058 (257)\ttotal: 12m 51s\tremaining: 36m 47s\n",
      "259:\ttest: 0.9931130\tbest: 0.9931130 (259)\ttotal: 12m 52s\tremaining: 36m 39s\n",
      "260:\ttest: 0.9931135\tbest: 0.9931135 (260)\ttotal: 12m 53s\tremaining: 36m 29s\n",
      "261:\ttest: 0.9931135\tbest: 0.9931135 (260)\ttotal: 12m 54s\tremaining: 36m 21s\n",
      "262:\ttest: 0.9931135\tbest: 0.9931135 (260)\ttotal: 12m 54s\tremaining: 36m 10s\n",
      "263:\ttest: 0.9931168\tbest: 0.9931168 (263)\ttotal: 12m 55s\tremaining: 36m 3s\n",
      "264:\ttest: 0.9931180\tbest: 0.9931180 (264)\ttotal: 12m 57s\tremaining: 35m 56s\n",
      "265:\ttest: 0.9931180\tbest: 0.9931180 (264)\ttotal: 12m 58s\tremaining: 35m 46s\n",
      "266:\ttest: 0.9931179\tbest: 0.9931180 (264)\ttotal: 12m 59s\tremaining: 35m 41s\n",
      "267:\ttest: 0.9931147\tbest: 0.9931180 (264)\ttotal: 13m 1s\tremaining: 35m 34s\n",
      "268:\ttest: 0.9931144\tbest: 0.9931180 (264)\ttotal: 13m 2s\tremaining: 35m 25s\n",
      "269:\ttest: 0.9931116\tbest: 0.9931180 (264)\ttotal: 13m 2s\tremaining: 35m 15s\n",
      "270:\ttest: 0.9931171\tbest: 0.9931180 (264)\ttotal: 13m 4s\tremaining: 35m 9s\n",
      "271:\ttest: 0.9931115\tbest: 0.9931180 (264)\ttotal: 13m 5s\tremaining: 35m 2s\n",
      "272:\ttest: 0.9931232\tbest: 0.9931232 (272)\ttotal: 13m 7s\tremaining: 34m 56s\n",
      "273:\ttest: 0.9931865\tbest: 0.9931865 (273)\ttotal: 13m 9s\tremaining: 34m 50s\n",
      "274:\ttest: 0.9931813\tbest: 0.9931865 (273)\ttotal: 13m 10s\tremaining: 34m 45s\n",
      "275:\ttest: 0.9931819\tbest: 0.9931865 (273)\ttotal: 13m 11s\tremaining: 34m 36s\n",
      "276:\ttest: 0.9931554\tbest: 0.9931865 (273)\ttotal: 13m 12s\tremaining: 34m 29s\n",
      "277:\ttest: 0.9931492\tbest: 0.9931865 (273)\ttotal: 13m 14s\tremaining: 34m 23s\n",
      "278:\ttest: 0.9931577\tbest: 0.9931865 (273)\ttotal: 13m 15s\tremaining: 34m 16s\n",
      "279:\ttest: 0.9931932\tbest: 0.9931932 (279)\ttotal: 13m 17s\tremaining: 34m 10s\n",
      "280:\ttest: 0.9931918\tbest: 0.9931932 (279)\ttotal: 13m 17s\tremaining: 34m 1s\n",
      "281:\ttest: 0.9932070\tbest: 0.9932070 (281)\ttotal: 13m 20s\tremaining: 33m 57s\n",
      "282:\ttest: 0.9932366\tbest: 0.9932366 (282)\ttotal: 13m 20s\tremaining: 33m 49s\n",
      "283:\ttest: 0.9932291\tbest: 0.9932366 (282)\ttotal: 13m 22s\tremaining: 33m 43s\n",
      "284:\ttest: 0.9932294\tbest: 0.9932366 (282)\ttotal: 13m 24s\tremaining: 33m 37s\n",
      "285:\ttest: 0.9932285\tbest: 0.9932366 (282)\ttotal: 13m 24s\tremaining: 33m 29s\n",
      "286:\ttest: 0.9933091\tbest: 0.9933091 (286)\ttotal: 13m 26s\tremaining: 33m 23s\n",
      "287:\ttest: 0.9932863\tbest: 0.9933091 (286)\ttotal: 13m 28s\tremaining: 33m 18s\n",
      "288:\ttest: 0.9932893\tbest: 0.9933091 (286)\ttotal: 13m 29s\tremaining: 33m 12s\n",
      "289:\ttest: 0.9933027\tbest: 0.9933091 (286)\ttotal: 13m 31s\tremaining: 33m 5s\n",
      "290:\ttest: 0.9932833\tbest: 0.9933091 (286)\ttotal: 13m 32s\tremaining: 33m\n",
      "291:\ttest: 0.9932459\tbest: 0.9933091 (286)\ttotal: 13m 34s\tremaining: 32m 55s\n",
      "292:\ttest: 0.9932594\tbest: 0.9933091 (286)\ttotal: 13m 36s\tremaining: 32m 49s\n",
      "293:\ttest: 0.9932576\tbest: 0.9933091 (286)\ttotal: 13m 38s\tremaining: 32m 44s\n",
      "294:\ttest: 0.9932656\tbest: 0.9933091 (286)\ttotal: 13m 39s\tremaining: 32m 39s\n",
      "295:\ttest: 0.9932683\tbest: 0.9933091 (286)\ttotal: 13m 41s\tremaining: 32m 33s\n",
      "296:\ttest: 0.9932776\tbest: 0.9933091 (286)\ttotal: 13m 43s\tremaining: 32m 28s\n",
      "297:\ttest: 0.9932767\tbest: 0.9933091 (286)\ttotal: 13m 44s\tremaining: 32m 22s\n",
      "298:\ttest: 0.9932783\tbest: 0.9933091 (286)\ttotal: 13m 46s\tremaining: 32m 17s\n",
      "299:\ttest: 0.9932813\tbest: 0.9933091 (286)\ttotal: 13m 48s\tremaining: 32m 12s\n",
      "300:\ttest: 0.9932833\tbest: 0.9933091 (286)\ttotal: 13m 50s\tremaining: 32m 8s\n",
      "301:\ttest: 0.9932846\tbest: 0.9933091 (286)\ttotal: 13m 52s\tremaining: 32m 3s\n",
      "302:\ttest: 0.9932648\tbest: 0.9933091 (286)\ttotal: 13m 54s\tremaining: 31m 59s\n",
      "303:\ttest: 0.9932683\tbest: 0.9933091 (286)\ttotal: 13m 56s\tremaining: 31m 54s\n",
      "304:\ttest: 0.9932640\tbest: 0.9933091 (286)\ttotal: 13m 58s\tremaining: 31m 49s\n",
      "305:\ttest: 0.9932451\tbest: 0.9933091 (286)\ttotal: 13m 59s\tremaining: 31m 45s\n",
      "306:\ttest: 0.9932420\tbest: 0.9933091 (286)\ttotal: 14m 1s\tremaining: 31m 39s\n",
      "307:\ttest: 0.9932220\tbest: 0.9933091 (286)\ttotal: 14m 3s\tremaining: 31m 34s\n",
      "308:\ttest: 0.9931959\tbest: 0.9933091 (286)\ttotal: 14m 4s\tremaining: 31m 28s\n",
      "309:\ttest: 0.9931994\tbest: 0.9933091 (286)\ttotal: 14m 5s\tremaining: 31m 22s\n",
      "310:\ttest: 0.9931996\tbest: 0.9933091 (286)\ttotal: 14m 7s\tremaining: 31m 18s\n",
      "311:\ttest: 0.9931983\tbest: 0.9933091 (286)\ttotal: 14m 9s\tremaining: 31m 13s\n",
      "312:\ttest: 0.9931778\tbest: 0.9933091 (286)\ttotal: 14m 11s\tremaining: 31m 8s\n",
      "313:\ttest: 0.9931997\tbest: 0.9933091 (286)\ttotal: 14m 12s\tremaining: 31m 2s\n",
      "314:\ttest: 0.9932024\tbest: 0.9933091 (286)\ttotal: 14m 14s\tremaining: 30m 57s\n",
      "315:\ttest: 0.9931962\tbest: 0.9933091 (286)\ttotal: 14m 15s\tremaining: 30m 52s\n",
      "316:\ttest: 0.9931945\tbest: 0.9933091 (286)\ttotal: 14m 17s\tremaining: 30m 47s\n",
      "317:\ttest: 0.9931956\tbest: 0.9933091 (286)\ttotal: 14m 19s\tremaining: 30m 42s\n",
      "318:\ttest: 0.9931889\tbest: 0.9933091 (286)\ttotal: 14m 20s\tremaining: 30m 37s\n",
      "319:\ttest: 0.9931773\tbest: 0.9933091 (286)\ttotal: 14m 22s\tremaining: 30m 32s\n",
      "320:\ttest: 0.9931767\tbest: 0.9933091 (286)\ttotal: 14m 23s\tremaining: 30m 27s\n",
      "321:\ttest: 0.9931905\tbest: 0.9933091 (286)\ttotal: 14m 25s\tremaining: 30m 22s\n",
      "322:\ttest: 0.9931682\tbest: 0.9933091 (286)\ttotal: 14m 26s\tremaining: 30m 16s\n",
      "323:\ttest: 0.9931689\tbest: 0.9933091 (286)\ttotal: 14m 28s\tremaining: 30m 12s\n",
      "324:\ttest: 0.9931757\tbest: 0.9933091 (286)\ttotal: 14m 30s\tremaining: 30m 7s\n",
      "325:\ttest: 0.9931845\tbest: 0.9933091 (286)\ttotal: 14m 31s\tremaining: 30m 2s\n",
      "326:\ttest: 0.9932096\tbest: 0.9933091 (286)\ttotal: 14m 33s\tremaining: 29m 57s\n",
      "327:\ttest: 0.9932092\tbest: 0.9933091 (286)\ttotal: 14m 34s\tremaining: 29m 51s\n",
      "328:\ttest: 0.9932100\tbest: 0.9933091 (286)\ttotal: 14m 35s\tremaining: 29m 46s\n",
      "329:\ttest: 0.9932073\tbest: 0.9933091 (286)\ttotal: 14m 37s\tremaining: 29m 40s\n",
      "330:\ttest: 0.9932069\tbest: 0.9933091 (286)\ttotal: 14m 38s\tremaining: 29m 36s\n",
      "331:\ttest: 0.9932276\tbest: 0.9933091 (286)\ttotal: 14m 40s\tremaining: 29m 31s\n",
      "332:\ttest: 0.9932351\tbest: 0.9933091 (286)\ttotal: 14m 42s\tremaining: 29m 26s\n",
      "333:\ttest: 0.9932394\tbest: 0.9933091 (286)\ttotal: 14m 43s\tremaining: 29m 22s\n",
      "334:\ttest: 0.9932466\tbest: 0.9933091 (286)\ttotal: 14m 45s\tremaining: 29m 18s\n",
      "335:\ttest: 0.9932418\tbest: 0.9933091 (286)\ttotal: 14m 47s\tremaining: 29m 14s\n",
      "336:\ttest: 0.9932413\tbest: 0.9933091 (286)\ttotal: 14m 49s\tremaining: 29m 9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9933091212\n",
      "bestIteration = 286\n",
      "\n",
      "Shrink model to first 287 iterations.\n",
      "\n",
      "CATBOOST training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train model based on type\n",
    "if MODEL_TYPE == \"catboost\":\n",
    "    # CatBoost training with native categorical handling\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_test, y_test),\n",
    "        cat_features=TFD_CAT_FEATURE_INDICES,  # Optional: CatBoost handles encoded cats too\n",
    "        use_best_model=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "else:\n",
    "    # XGBoost training\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "print(f\"\\n{MODEL_TYPE.upper()} training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i0d1e2f3",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0d94023",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e30ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics:\n",
      "========================================\n",
      "Accuracy            : 0.9878\n",
      "Precision           : 0.4465\n",
      "Recall              : 0.9234\n",
      "F1                  : 0.6019\n",
      "ROCAUC              : 0.9933\n",
      "GeometricMean       : 0.9554\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = {\n",
    "    \"Accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "    \"Precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "    \"Recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "    \"F1\": float(f1_score(y_test, y_pred, zero_division=0)),\n",
    "    \"ROCAUC\": float(roc_auc_score(y_test, y_pred_proba)),\n",
    "    \"GeometricMean\": float(geometric_mean_score(y_test, y_pred)),\n",
    "}\n",
    "\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(\"=\" * 40)\n",
    "for name, value in eval_metrics.items():\n",
    "    print(f\"{name:20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j1e2f3g4",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Compare CatBoost (primary) vs XGBoost (fallback) on this dataset.\n",
    "\n",
    "Run the notebook twice with `MODEL_TYPE = \"catboost\"` and `MODEL_TYPE = \"xgboost\"` to compare.\n",
    "\n",
    "| Metric | CatBoost | XGBoost | Winner |\n",
    "|--------|----------|---------|--------|\n",
    "| Accuracy | ? | ? | ? |\n",
    "| Precision | ? | ? | ? |\n",
    "| Recall | ? | ? | ? |\n",
    "| F1 | ? | ? | ? |\n",
    "| ROCAUC | ? | ? | ? |\n",
    "| GeometricMean | ? | ? | ? |\n",
    "\n",
    "**Key Differences:**\n",
    "- **CatBoost**: Native categorical handling, ordered boosting, auto class weights\n",
    "- **XGBoost**: sklearn-native, compatible with YellowBrick visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "k2f3g4h5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CATBOOST Model Metrics:\n",
      "==================================================\n",
      "  Accuracy            : 0.9878\n",
      "  Precision           : 0.4465\n",
      "  Recall              : 0.9234\n",
      "  F1                  : 0.6019\n",
      "  ROCAUC              : 0.9933\n",
      "  GeometricMean       : 0.9554\n"
     ]
    }
   ],
   "source": [
    "# Store metrics for comparison\n",
    "# Run with MODEL_TYPE=\"catboost\" first, then \"xgboost\" to populate both\n",
    "\n",
    "print(f\"\\n{MODEL_TYPE.upper()} Model Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for name, value in eval_metrics.items():\n",
    "    print(f\"  {name:20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df2e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# PRIMARY METRICS - Class-based metrics for fraud detection\n",
    "# These use y_pred (predicted labels), not probabilities\n",
    "# -----------------------------------------------------------------------------\n",
    "primary_metric_functions = {\n",
    "    # Recall: Fraud detection rate (minimize missed fraud)\n",
    "    # TP / (TP + FN) - How many actual frauds did we catch?\n",
    "    \"recall_score\": metrics.recall_score,\n",
    "    # Precision: False alarm rate (customer experience)\n",
    "    # TP / (TP + FP) - Of predicted frauds, how many were actually fraud?\n",
    "    \"precision_score\": metrics.precision_score,\n",
    "    # F1: Harmonic mean of Precision & Recall\n",
    "    # Best when you want balance between precision and recall\n",
    "    \"f1_score\": metrics.f1_score,\n",
    "    # F-beta with beta=2: Weights Recall 2x more than Precision\n",
    "    # CRITICAL for fraud detection where missing fraud is costly\n",
    "    \"fbeta_score\": metrics.fbeta_score,\n",
    "}\n",
    "primary_metric_args = {\n",
    "    \"recall_score\": {\n",
    "        \"pos_label\": 1,\n",
    "        \"average\": \"binary\",\n",
    "        \"zero_division\": 0.0,\n",
    "    },\n",
    "    \"precision_score\": {\n",
    "        \"pos_label\": 1,\n",
    "        \"average\": \"binary\",\n",
    "        \"zero_division\": 0.0,\n",
    "    },\n",
    "    \"f1_score\": {\n",
    "        \"pos_label\": 1,\n",
    "        \"average\": \"binary\",\n",
    "        \"zero_division\": 0.0,\n",
    "    },\n",
    "    \"fbeta_score\": {\n",
    "        \"beta\": 2.0,\n",
    "        \"pos_label\": 1,\n",
    "        \"average\": \"binary\",\n",
    "        \"zero_division\": 0.0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16e68522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# SECONDARY METRICS - Good for monitoring and additional insights\n",
    "# These provide complementary information but shouldn't drive model selection\n",
    "# -----------------------------------------------------------------------------\n",
    "secondary_metric_functions = {\n",
    "    # Accuracy: Overall correctness (TP + TN) / Total\n",
    "    # CAUTION: Misleading for imbalanced data when used alone!\n",
    "    # Include for: baseline comparison, sanity checks, stakeholder reporting\n",
    "    # With 3% fraud: predicting all non-fraud = 97% accuracy (useless!)\n",
    "    # ALWAYS show alongside balanced_accuracy and recall\n",
    "    \"accuracy_score\": metrics.accuracy_score,\n",
    "    # Balanced Accuracy: Average of recall on each class\n",
    "    # = (TPR + TNR) / 2 = (Recall_fraud + Recall_non_fraud) / 2\n",
    "    # Better than accuracy for imbalanced data - penalizes ignoring minority\n",
    "    \"balanced_accuracy_score\": metrics.balanced_accuracy_score,\n",
    "    # Matthews Correlation Coefficient: Most robust single metric\n",
    "    # Balanced measure, works well with imbalanced classes\n",
    "    # Range: [-1, +1], 0 = random, +1 = perfect, -1 = inverse\n",
    "    # Only metric that gives high score when all 4 confusion matrix categories are good\n",
    "    \"matthews_corrcoef\": metrics.matthews_corrcoef,\n",
    "    # Cohen's Kappa: Agreement beyond chance\n",
    "    # Useful for comparing with baseline/random classifier\n",
    "    # Range: [-1, +1], 0 = no better than chance, +1 = perfect\n",
    "    \"cohen_kappa_score\": metrics.cohen_kappa_score,\n",
    "    # Jaccard Score: Intersection over Union (IoU)\n",
    "    # TP / (TP + FP + FN) - stricter than F1\n",
    "    # Ignores TN, focuses only on positive class predictions\n",
    "    \"jaccard_score\": metrics.jaccard_score,\n",
    "}\n",
    "secondary_metric_args = {\n",
    "    # Accuracy: normalize=True returns fraction [0, 1]\n",
    "    # sample_weight=None means equal weight for all samples\n",
    "    # For imbalanced data: use alongside balanced_accuracy, never alone!\n",
    "    \"accuracy_score\": {\n",
    "        \"normalize\": True,  # Return fraction (0.0 to 1.0), not count\n",
    "        # sample_weight: Can be set dynamically to correct for imbalance\n",
    "        # Example: weight fraud samples higher to penalize missing them\n",
    "    },\n",
    "    # Balanced Accuracy: adjusted=False returns [0, 1], adjusted=True shifts to [-0.5, 1]\n",
    "    # adjusted=True: random classifier scores 0, adjusted=False: random scores ~0.5\n",
    "    \"balanced_accuracy_score\": {\n",
    "        \"adjusted\": False,  # Keep in [0, 1] range for interpretability\n",
    "    },\n",
    "    # MCC: No special args, works on y_true vs y_pred\n",
    "    # Handles imbalanced data well by design\n",
    "    \"matthews_corrcoef\": {},\n",
    "    # Cohen's Kappa: weights=None for unweighted agreement\n",
    "    # weights='linear' or 'quadratic' for ordinal classification\n",
    "    \"cohen_kappa_score\": {\n",
    "        \"weights\": None,  # Unweighted (linear/quadratic for ordinal data)\n",
    "    },\n",
    "    # Jaccard: binary classification with fraud as positive class\n",
    "    \"jaccard_score\": {\n",
    "        \"pos_label\": 1,\n",
    "        \"average\": \"binary\",\n",
    "        \"zero_division\": 0.0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce5b26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# PROBABILISTIC METRICS - Use y_pred_proba (probability scores)\n",
    "# These measure ranking ability and probability calibration\n",
    "# -----------------------------------------------------------------------------\n",
    "probabilistic_metric_functions = {\n",
    "    # ROC-AUC: Best overall threshold-independent metric for imbalanced binary\n",
    "    # Area under ROC curve, measures ranking ability\n",
    "    \"roc_auc_score\": metrics.roc_auc_score,\n",
    "    # Average Precision (PR-AUC): Area under precision-recall curve\n",
    "    # Better than ROC-AUC for highly imbalanced data\n",
    "    \"average_precision_score\": metrics.average_precision_score,\n",
    "    # Log Loss (Cross-Entropy): Penalizes confident wrong predictions\n",
    "    # Lower is better, heavily penalizes confident mistakes\n",
    "    \"log_loss\": metrics.log_loss,\n",
    "    # Brier Score: Mean squared error of probability predictions\n",
    "    # Lower is better, range [0, 1]\n",
    "    \"brier_score_loss\": metrics.brier_score_loss,\n",
    "    # D^2 Log Loss Score: Fraction of log loss explained\n",
    "    # Similar to R^2, but for log loss; higher is better\n",
    "    \"d2_log_loss_score\": metrics.d2_log_loss_score,\n",
    "    # D^2 Brier Score: Fraction of Brier score explained\n",
    "    # Similar to R^2, but for Brier score; higher is better\n",
    "    \"d2_brier_score\": metrics.d2_brier_score,\n",
    "}\n",
    "probabilistic_metric_args = {\n",
    "    \"roc_auc_score\": {},\n",
    "    \"average_precision_score\": {\n",
    "        \"pos_label\": 1,\n",
    "    },\n",
    "    \"log_loss\": {\n",
    "        \"normalize\": True,\n",
    "    },\n",
    "    \"brier_score_loss\": {\n",
    "        \"pos_label\": 1,\n",
    "    },\n",
    "    \"d2_log_loss_score\": {},\n",
    "    \"d2_brier_score\": {\n",
    "        \"pos_label\": 1,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "703cd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ANALYSIS/REPORTING METRICS - For detailed analysis and threshold tuning\n",
    "# These return multiple values or structured outputs\n",
    "# -----------------------------------------------------------------------------\n",
    "analysis_metric_functions = {\n",
    "    # Confusion Matrix: Foundation for many other metrics\n",
    "    # Returns 2x2 matrix: [[TN, FP], [FN, TP]]\n",
    "    \"confusion_matrix\": metrics.confusion_matrix,\n",
    "    # NEW IN SKLEARN 1.8! Confusion Matrix at Thresholds\n",
    "    # Returns TN, FP, FN, TP arrays for each threshold\n",
    "    # CRITICAL for threshold optimization in fraud detection\n",
    "    \"confusion_matrix_at_thresholds\": metrics.confusion_matrix_at_thresholds,\n",
    "    # Classification Report: Text summary of P, R, F1 per class\n",
    "    # Can return dict with output_dict=True\n",
    "    \"classification_report\": metrics.classification_report,\n",
    "    # Precision-Recall Curve: For threshold analysis\n",
    "    # Returns (precision, recall, thresholds)\n",
    "    \"precision_recall_curve\": metrics.precision_recall_curve,\n",
    "    # ROC Curve: For threshold analysis\n",
    "    # Returns (fpr, tpr, thresholds)\n",
    "    \"roc_curve\": metrics.roc_curve,\n",
    "    # DET Curve: Detection Error Tradeoff\n",
    "    # Returns (fpr, fnr, thresholds) - plots FNR vs FPR\n",
    "    # Useful for fraud: visualize false alarm vs missed fraud tradeoff\n",
    "    \"det_curve\": metrics.det_curve,\n",
    "    # Class Likelihood Ratios: LR+, LR- for diagnostic testing\n",
    "    # Returns (positive_lr, negative_lr)\n",
    "    \"class_likelihood_ratios\": metrics.class_likelihood_ratios,\n",
    "    # Precision-Recall-FScore-Support: All in one\n",
    "    # Returns (precision, recall, fbeta, support) arrays\n",
    "    \"precision_recall_fscore_support\": metrics.precision_recall_fscore_support,\n",
    "    # AUC: General utility to compute area under any curve\n",
    "    \"auc\": metrics.auc,\n",
    "}\n",
    "analysis_metric_args = {\n",
    "    # Confusion Matrix: labels=[0, 1] ensures consistent ordering\n",
    "    # normalize='true' normalizes over actual (row-wise)\n",
    "    \"confusion_matrix\": {\n",
    "        \"labels\": [0, 1],  # [non-fraud, fraud]\n",
    "        \"normalize\": None,  # Return raw counts; use 'true'/'pred'/'all' for proportions\n",
    "    },\n",
    "    # Confusion Matrix at Thresholds: pos_label=1 for fraud\n",
    "    # Returns (tns, fps, fns, tps, thresholds) arrays\n",
    "    \"confusion_matrix_at_thresholds\": {\n",
    "        \"pos_label\": 1,  # Fraud is positive class\n",
    "    },\n",
    "    # Classification Report: output_dict=True for programmatic access\n",
    "    \"classification_report\": {\n",
    "        \"target_names\": [\"Non-Fraud\", \"Fraud\"],\n",
    "        \"output_dict\": True,  # Return dict instead of string\n",
    "        \"zero_division\": 0.0,\n",
    "    },\n",
    "    # Precision-Recall Curve: pos_label=1 for fraud class\n",
    "    \"precision_recall_curve\": {\n",
    "        \"pos_label\": 1,\n",
    "    },\n",
    "    # ROC Curve: pos_label=1 for fraud class\n",
    "    \"roc_curve\": {\n",
    "        \"pos_label\": 1,\n",
    "        \"drop_intermediate\": True,  # Reduce points for efficiency\n",
    "    },\n",
    "    # DET Curve: pos_label=1 for fraud class\n",
    "    \"det_curve\": {\n",
    "        \"pos_label\": 1,\n",
    "        \"drop_intermediate\": True,  # Reduce points for efficiency\n",
    "    },\n",
    "    # Class Likelihood Ratios: labels=[non-fraud, fraud] ordering\n",
    "    \"class_likelihood_ratios\": {\n",
    "        \"labels\": [0, 1],  # [negative_class, positive_class]\n",
    "    },\n",
    "    # Precision-Recall-FScore-Support: beta=1.0 for F1\n",
    "    \"precision_recall_fscore_support\": {\n",
    "        \"beta\": 1.0,\n",
    "        \"pos_label\": 1,\n",
    "        \"average\": \"binary\",\n",
    "        \"zero_division\": 0.0,\n",
    "    },\n",
    "    # AUC: No default args, takes x and y arrays directly\n",
    "    \"auc\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5gb742dhycg",
   "metadata": {},
   "source": [
    "## Comprehensive Metrics Evaluation\n",
    "\n",
    "Sklearn metrics organized following River ML structure for consistency:\n",
    "\n",
    "| Category | River (Online) | Sklearn (Batch) |\n",
    "|----------|----------------|-----------------|\n",
    "| **Class-based** | `.update(y, pred)` | `func(y_true, y_pred)` |\n",
    "| **Probability-based** | `.update(y, proba)` | `func(y_true, y_proba)` |\n",
    "| **Report/Matrix** | `.update(y, pred)` | `func(y_true, y_pred)` |\n",
    "\n",
    "Key difference: River metrics are incremental (`.update()`), sklearn are batch functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "nd5mxg45vd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall_score': 0.9233964005537609,\n",
       " 'precision_score': 0.4464524765729585,\n",
       " 'f1_score': 0.6018950218077906,\n",
       " 'fbeta_score': 0.7608365019011407,\n",
       " 'accuracy_score': 0.9878042599853485,\n",
       " 'balanced_accuracy_score': 0.9559251032348655,\n",
       " 'matthews_corrcoef': 0.6374838597438147,\n",
       " 'cohen_kappa_score': 0.5964632472381868,\n",
       " 'jaccard_score': 0.4305077452667814,\n",
       " 'roc_auc_score': 0.9933091211885177,\n",
       " 'average_precision_score': 0.9179367645715938,\n",
       " 'log_loss': 0.07253448486036858,\n",
       " 'brier_score_loss': 0.019032686368593052,\n",
       " 'd2_log_loss_score': -0.29690518159390145,\n",
       " 'd2_brier_score': -0.9255058228904667}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMPUTE ALL METRICS\n",
    "# =============================================================================\n",
    "metrics_to_log = {}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PRIMARY METRICS (class-based, use y_pred)\n",
    "# -----------------------------------------------------------------------------\n",
    "for name, func in primary_metric_functions.items():\n",
    "    metrics_to_log[name] = func(y_test, y_pred, **primary_metric_args[name])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SECONDARY METRICS (class-based, use y_pred)\n",
    "# -----------------------------------------------------------------------------\n",
    "for name, func in secondary_metric_functions.items():\n",
    "    metrics_to_log[name] = func(y_test, y_pred, **secondary_metric_args[name])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PROBABILISTIC METRICS (use y_pred_proba)\n",
    "# -----------------------------------------------------------------------------\n",
    "for name, func in probabilistic_metric_functions.items():\n",
    "    metrics_to_log[name] = func(y_test, y_pred_proba, **probabilistic_metric_args[name])\n",
    "\n",
    "metrics_to_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ts4i6vtd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[212395   2481]\n",
      " [   166   2001]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Fraud       1.00      0.99      0.99    214876\n",
      "       Fraud       0.45      0.92      0.60      2167\n",
      "\n",
      "    accuracy                           0.99    217043\n",
      "   macro avg       0.72      0.96      0.80    217043\n",
      "weighted avg       0.99      0.99      0.99    217043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display report metrics (ConfusionMatrix, ClassificationReport)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred, **analysis_metric_args[\"confusion_matrix\"]))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(metrics.classification_report(\n",
    "    y_test, y_pred, \n",
    "    target_names=[\"Non-Fraud\", \"Fraud\"],\n",
    "    zero_division=0.0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d1f496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model parameters:\n",
      "  nan_mode: Min\n",
      "  eval_metric: AUC\n",
      "  combinations_ctr: ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1', 'Counter:CtrBorderCount=15:CtrBorderType=Uniform:Prior=0/1']\n",
      "  iterations: 1000\n",
      "  sampling_frequency: PerTree\n",
      "  fold_permutation_block: 0\n",
      "  leaf_estimation_method: Newton\n",
      "  od_pval: 0\n",
      "  random_score_type: NormalWithModelSizeDecrease\n",
      "  counter_calc_method: SkipTest\n",
      "  grow_policy: SymmetricTree\n",
      "  penalties_coefficient: 1\n",
      "  boosting_type: Plain\n",
      "  model_shrink_mode: Constant\n",
      "  feature_border_type: GreedyLogSum\n",
      "  ctr_leaf_count_limit: 18446744073709551615\n",
      "  bayesian_matrix_reg: 0.10000000149011612\n",
      "  one_hot_max_size: 2\n",
      "  eval_fraction: 0\n",
      "  force_unit_auto_pair_weights: False\n",
      "  l2_leaf_reg: 3\n",
      "  random_strength: 1\n",
      "  od_type: Iter\n",
      "  rsm: 1\n",
      "  boost_from_average: False\n",
      "  max_ctr_complexity: 4\n",
      "  model_size_reg: 0.5\n",
      "  simple_ctr: ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1', 'Counter:CtrBorderCount=15:CtrBorderType=Uniform:Prior=0/1']\n",
      "  pool_metainfo_options: {'tags': {}}\n",
      "  subsample: 0.800000011920929\n",
      "  use_best_model: True\n",
      "  od_wait: 50\n",
      "  class_names: [0, 1]\n",
      "  random_seed: 42\n",
      "  depth: 6\n",
      "  ctr_target_border_count: 1\n",
      "  posterior_sampling: False\n",
      "  has_time: False\n",
      "  store_all_simple_ctr: False\n",
      "  border_count: 254\n",
      "  class_weights: [1, 99.16960906982422]\n",
      "  classes_count: 0\n",
      "  auto_class_weights: Balanced\n",
      "  sparse_features_conflict_fraction: 0\n",
      "  leaf_estimation_backtracking: AnyImprovement\n",
      "  best_model_min_trees: 1\n",
      "  model_shrink_rate: 0\n",
      "  min_data_in_leaf: 1\n",
      "  loss_function: Logloss\n",
      "  learning_rate: 0.05000000074505806\n",
      "  score_function: Cosine\n",
      "  task_type: CPU\n",
      "  leaf_estimation_iterations: 10\n",
      "  bootstrap_type: MVS\n",
      "  max_leaves: 64\n",
      "  permutation_count: 4\n"
     ]
    }
   ],
   "source": [
    "# Print all model parameters\n",
    "print(\"\\nModel parameters:\")\n",
    "all_params = model.get_all_params()\n",
    "for param_name, param_value in all_params.items():\n",
    "    print(f\"  {param_name}: {param_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
