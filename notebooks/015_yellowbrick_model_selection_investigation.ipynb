{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list_all_model_selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get all items from yellowbrick.model_selection\n",
    "all_items = [name for name in dir(model_selection) if not name.startswith('_')]\n",
    "print(\"All items in yellowbrick.model_selection module:\")\n",
    "print(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "categorize_items",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize items by type\n",
    "functions = []\n",
    "classes = []\n",
    "submodules = []\n",
    "\n",
    "for name in all_items:\n",
    "    obj = getattr(model_selection, name)\n",
    "    if inspect.isfunction(obj):\n",
    "        functions.append(name)\n",
    "    elif inspect.isclass(obj):\n",
    "        classes.append(name)\n",
    "    elif inspect.ismodule(obj):\n",
    "        submodules.append(name)\n",
    "\n",
    "print(f\"Functions (quick methods): {len(functions)}\")\n",
    "print(functions)\n",
    "print(f\"\\nClasses (visualizers): {len(classes)}\")\n",
    "print(classes)\n",
    "print(f\"\\nSubmodules: {len(submodules)}\")\n",
    "print(submodules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_selection_overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YELLOWBRICK MODEL SELECTION MODULE OVERVIEW\n",
    "# =============================================================================\n",
    "#\n",
    "# yellowbrick.model_selection provides visualizers for model evaluation:\n",
    "# - Hyperparameter tuning (ValidationCurve)\n",
    "# - Dataset size impact (LearningCurve)\n",
    "# - Cross-validation performance (CVScores)\n",
    "# - Feature importance analysis (FeatureImportances)\n",
    "# - Feature selection (RFECV, DroppingCurve)\n",
    "#\n",
    "# Reference: https://www.scikit-yb.org/en/latest/api/model_selection/index.html\n",
    "#\n",
    "# =============================================================================\n",
    "# AVAILABLE VISUALIZERS (6 total):\n",
    "# =============================================================================\n",
    "#\n",
    "# 1. ValidationCurve     - Hyperparameter tuning (bias-variance tradeoff)\n",
    "# 2. LearningCurve       - Training size vs performance\n",
    "# 3. CVScores            - Cross-validation scores bar chart\n",
    "# 4. FeatureImportances  - Feature importance ranking\n",
    "# 5. RFECV               - Recursive Feature Elimination with CV\n",
    "# 6. DroppingCurve       - Feature dropping impact analysis\n",
    "#\n",
    "# =============================================================================\n",
    "# CATBOOST COMPATIBILITY ANALYSIS\n",
    "# =============================================================================\n",
    "#\n",
    "# CatBoost is NOT sklearn-compatible:\n",
    "# - Does NOT inherit from sklearn.base.BaseEstimator\n",
    "# - Cannot be cloned with sklearn.base.clone()\n",
    "# - Missing __sklearn_tags__ attribute\n",
    "#\n",
    "# BUT CatBoost HAS:\n",
    "# - feature_importances_ attribute (for FeatureImportances)\n",
    "# - classes_ attribute\n",
    "# - fit(), predict(), predict_proba() methods\n",
    "#\n",
    "# SOLUTION: Use CatBoostWrapperCV for CV-based visualizers\n",
    "# (see apps/sklearn/functions.py for implementation)\n",
    "#\n",
    "# =============================================================================\n",
    "print(\"Yellowbrick Model Selection Module - 6 Visualizers Available\")\n",
    "print(\"  - ALL require an estimator\")\n",
    "print(\"  - Most require CV (cloning) - need CatBoostWrapperCV\")\n",
    "print(\"  - FeatureImportances works with pre-fitted CatBoost (has feature_importances_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catboost_wrapper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATBOOST SKLEARN-COMPATIBLE WRAPPER\n",
    "# =============================================================================\n",
    "# Required for all CV-based visualizers (ValidationCurve, LearningCurve, etc.)\n",
    "# These visualizers clone the estimator for each CV fold.\n",
    "# =============================================================================\n",
    "\n",
    "class CatBoostWrapperCV(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"CatBoost wrapper for CV-based visualizers (can be cloned and re-fitted).\n",
    "    \n",
    "    This wrapper inherits from sklearn's BaseEstimator and ClassifierMixin,\n",
    "    making it compatible with sklearn's clone() function and YellowBrick\n",
    "    visualizers that require cross-validation.\n",
    "    \"\"\"\n",
    "    _estimator_type = 'classifier'\n",
    "\n",
    "    def __init__(self, iterations=100, depth=6, learning_rate=0.1,\n",
    "                 auto_class_weights='Balanced', random_state=42):\n",
    "        self.iterations = iterations\n",
    "        self.depth = depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.auto_class_weights = auto_class_weights\n",
    "        self.random_state = random_state\n",
    "        self.model_ = None\n",
    "        self.classes_ = None\n",
    "        self.feature_importances_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        from catboost import CatBoostClassifier\n",
    "        self.model_ = CatBoostClassifier(\n",
    "            iterations=self.iterations,\n",
    "            depth=self.depth,\n",
    "            learning_rate=self.learning_rate,\n",
    "            auto_class_weights=self.auto_class_weights,\n",
    "            random_seed=self.random_state,\n",
    "            verbose=0\n",
    "        )\n",
    "        self.model_.fit(X, y)\n",
    "        self.classes_ = np.array(self.model_.classes_)\n",
    "        self.feature_importances_ = self.model_.feature_importances_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_.predict(X).flatten()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model_.predict_proba(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X))\n",
    "\n",
    "\n",
    "# Test cloning\n",
    "from sklearn.base import clone\n",
    "wrapper = CatBoostWrapperCV(iterations=10)\n",
    "try:\n",
    "    cloned = clone(wrapper)\n",
    "    print(\"CatBoostWrapperCV can be cloned\")\n",
    "except Exception as e:\n",
    "    print(f\"Cloning failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validation_curve_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. VALIDATION CURVE VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Examines how adjusting a hyperparameter affects training and test\n",
    "# scores, helping identify the optimal value and detect overfitting.\n",
    "#\n",
    "# Use Case: Tune hyperparameters by visualizing bias-variance tradeoff.\n",
    "#\n",
    "# CatBoost Compatibility: REQUIRES CatBoostWrapperCV\n",
    "# - Clones estimator for each param value x CV fold\n",
    "# - Very computationally expensive\n",
    "#\n",
    "# Reference: https://www.scikit-yb.org/en/latest/api/model_selection/validation_curve.html\n",
    "# =============================================================================\n",
    "\n",
    "validation_curve_class = model_selection.ValidationCurve\n",
    "\n",
    "validation_curve_kwargs = {\n",
    "    # REQUIRED\n",
    "    \"estimator\": None,             # sklearn-compatible estimator (use CatBoostWrapperCV)\n",
    "    \"param_name\": \"depth\",         # Hyperparameter to vary\n",
    "    \"param_range\": [2, 4, 6, 8],   # Values to test\n",
    "    \n",
    "    # Cross-validation\n",
    "    \"cv\": None,                    # CV strategy (default: 5-fold)\n",
    "    \"scoring\": \"f1\",               # Metric: 'f1', 'accuracy', 'roc_auc', etc.\n",
    "    \n",
    "    # Display options\n",
    "    \"ax\": None,                    # matplotlib Axes\n",
    "    \"logx\": False,                 # Log scale for x-axis\n",
    "    \"n_jobs\": 1,                   # Parallel jobs (-1 for all cores)\n",
    "}\n",
    "\n",
    "print(\"ValidationCurve kwargs:\")\n",
    "for key, value in validation_curve_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nWARNING: ValidationCurve is VERY SLOW!\")\n",
    "print(\"  Fits: n_params * n_splits models\")\n",
    "print(f\"  Example: {len(validation_curve_kwargs['param_range'])} params * 5 folds = {len(validation_curve_kwargs['param_range']) * 5} fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning_curve_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. LEARNING CURVE VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Shows how model performance changes with training set size,\n",
    "# helping diagnose high variance (overfitting) vs high bias (underfitting).\n",
    "#\n",
    "# Use Case: Determine if more data would help improve performance.\n",
    "#\n",
    "# CatBoost Compatibility: REQUIRES CatBoostWrapperCV\n",
    "# - Clones estimator for each train_size x CV fold\n",
    "#\n",
    "# Reference: https://www.scikit-yb.org/en/latest/api/model_selection/learning_curve.html\n",
    "# =============================================================================\n",
    "\n",
    "learning_curve_class = model_selection.LearningCurve\n",
    "\n",
    "learning_curve_kwargs = {\n",
    "    # REQUIRED\n",
    "    \"estimator\": None,             # sklearn-compatible estimator\n",
    "    \n",
    "    # Training sizes (default: [0.1, 0.325, 0.55, 0.775, 1.0])\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \n",
    "    # Cross-validation\n",
    "    \"cv\": None,                    # CV strategy (default: 3-fold)\n",
    "    \"scoring\": \"f1\",               # Metric\n",
    "    \n",
    "    # Display options\n",
    "    \"ax\": None,                    # matplotlib Axes\n",
    "    \"n_jobs\": 1,                   # Parallel jobs\n",
    "    \"random_state\": 42,            # Reproducibility\n",
    "}\n",
    "\n",
    "print(\"LearningCurve kwargs:\")\n",
    "for key, value in learning_curve_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Training score >> Test score: Overfitting (high variance)\")\n",
    "print(\"  - Both scores low: Underfitting (high bias)\")\n",
    "print(\"  - Both scores high and close: Good fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv_scores_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. CV SCORES VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Displays cross-validated scores as a bar chart with mean line,\n",
    "# showing performance consistency across folds.\n",
    "#\n",
    "# Use Case: Evaluate model stability and identify problematic folds.\n",
    "#\n",
    "# CatBoost Compatibility: REQUIRES CatBoostWrapperCV\n",
    "# - Wraps sklearn.model_selection.cross_val_score\n",
    "#\n",
    "# Reference: https://www.scikit-yb.org/en/latest/api/model_selection/cross_validation.html\n",
    "# =============================================================================\n",
    "\n",
    "cv_scores_class = model_selection.CVScores\n",
    "\n",
    "cv_scores_kwargs = {\n",
    "    # REQUIRED\n",
    "    \"estimator\": None,             # sklearn-compatible estimator\n",
    "    \n",
    "    # Cross-validation\n",
    "    \"cv\": None,                    # CV strategy (int or cross-validator)\n",
    "    \"scoring\": \"f1\",               # Metric\n",
    "    \n",
    "    # Display options\n",
    "    \"ax\": None,                    # matplotlib Axes\n",
    "    \"color\": None,                 # Bar color\n",
    "}\n",
    "\n",
    "print(\"CVScores kwargs:\")\n",
    "for key, value in cv_scores_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nBest practices for TFD:\")\n",
    "print(\"  - Use StratifiedKFold for imbalanced data\")\n",
    "print(\"  - Use scoring='f1' or 'average_precision' (not 'accuracy')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importances_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. FEATURE IMPORTANCES VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Displays feature importances as a horizontal bar chart,\n",
    "# showing which features the model relies on most.\n",
    "#\n",
    "# Use Case: Model interpretation, feature selection, debugging.\n",
    "#\n",
    "# CatBoost Compatibility: WORKS with pre-fitted CatBoost!\n",
    "# - CatBoost HAS feature_importances_ attribute\n",
    "# - Use is_fitted=True to skip refitting\n",
    "#\n",
    "# Reference: https://www.scikit-yb.org/en/latest/api/model_selection/importances.html\n",
    "# =============================================================================\n",
    "\n",
    "feature_importances_class = model_selection.FeatureImportances\n",
    "\n",
    "feature_importances_kwargs = {\n",
    "    # REQUIRED\n",
    "    \"estimator\": None,             # Estimator with feature_importances_\n",
    "    \n",
    "    # Display options\n",
    "    \"ax\": None,                    # matplotlib Axes\n",
    "    \"labels\": None,                # Feature names\n",
    "    \"relative\": True,              # Show as % of max importance\n",
    "    \"absolute\": False,             # Use absolute values\n",
    "    \"stack\": False,                # Stack for multi-class\n",
    "    \"topn\": None,                  # Show only top N features\n",
    "    \"colors\": None,                # Bar colors\n",
    "    \"colormap\": None,              # Colormap\n",
    "    \n",
    "    # CatBoost compatibility\n",
    "    \"is_fitted\": True,             # IMPORTANT: Skip refitting for CatBoost\n",
    "}\n",
    "\n",
    "print(\"FeatureImportances kwargs:\")\n",
    "for key, value in feature_importances_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nCatBoost Note:\")\n",
    "print(\"  - Set is_fitted=True to use pre-fitted CatBoost model\")\n",
    "print(\"  - CatBoost provides feature_importances_ after fit()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rfecv_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. RFECV VISUALIZER (Recursive Feature Elimination with CV)\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Progressively removes features and plots CV scores,\n",
    "# finding the optimal number of features.\n",
    "#\n",
    "# Use Case: Automated feature selection with performance optimization.\n",
    "#\n",
    "# CatBoost Compatibility: REQUIRES CatBoostWrapperCV\n",
    "# - Requires coef_ OR feature_importances_\n",
    "# - CatBoostWrapperCV exposes feature_importances_\n",
    "#\n",
    "# WARNING: EXTREMELY SLOW! Fits n_features * n_splits models.\n",
    "#\n",
    "# Reference: https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html\n",
    "# =============================================================================\n",
    "\n",
    "rfecv_class = model_selection.RFECV\n",
    "\n",
    "rfecv_kwargs = {\n",
    "    # REQUIRED\n",
    "    \"estimator\": None,             # Estimator with coef_ or feature_importances_\n",
    "    \n",
    "    # Feature elimination\n",
    "    \"step\": 1,                     # Features to remove per iteration\n",
    "    \"min_features_to_select\": 1,   # Minimum features to keep\n",
    "    \n",
    "    # Cross-validation\n",
    "    \"cv\": None,                    # CV strategy\n",
    "    \"scoring\": \"f1\",               # Metric\n",
    "    \"groups\": None,                # Group labels for GroupKFold\n",
    "    \n",
    "    # Display options\n",
    "    \"ax\": None,                    # matplotlib Axes\n",
    "}\n",
    "\n",
    "print(\"RFECV kwargs:\")\n",
    "for key, value in rfecv_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nWARNING: RFECV is EXTREMELY SLOW!\")\n",
    "print(\"  For 16 features with 5-fold CV:\")\n",
    "print(\"  16 * 5 = 80 model fits minimum\")\n",
    "print(\"  Consider using step=2 or higher to reduce fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dropping_curve_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. DROPPING CURVE VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Evaluates performance while randomly removing feature subsets,\n",
    "# showing how sensitive the model is to feature count.\n",
    "#\n",
    "# Use Case: Understand feature redundancy and model robustness.\n",
    "#\n",
    "# CatBoost Compatibility: REQUIRES CatBoostWrapperCV\n",
    "# - Similar to LearningCurve but varies feature count\n",
    "#\n",
    "# Reference: https://www.scikit-yb.org/en/latest/api/model_selection/dropping_curve.html\n",
    "# =============================================================================\n",
    "\n",
    "dropping_curve_class = model_selection.DroppingCurve\n",
    "\n",
    "dropping_curve_kwargs = {\n",
    "    # REQUIRED\n",
    "    \"estimator\": None,             # sklearn-compatible estimator\n",
    "    \n",
    "    # Feature sizes (default: [0.1, 0.325, 0.55, 0.775, 1.0])\n",
    "    \"feature_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \n",
    "    # Cross-validation\n",
    "    \"cv\": None,                    # CV strategy (default: 3-fold)\n",
    "    \"scoring\": \"f1\",               # Metric\n",
    "    \n",
    "    # Display options\n",
    "    \"ax\": None,                    # matplotlib Axes\n",
    "    \"n_jobs\": 1,                   # Parallel jobs\n",
    "    \"random_state\": 42,            # Reproducibility\n",
    "}\n",
    "\n",
    "print(\"DroppingCurve kwargs:\")\n",
    "for key, value in dropping_curve_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Score stable across feature counts: Redundant features\")\n",
    "print(\"  - Score drops sharply: Important features being removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatibility_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATBOOST COMPATIBILITY SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*72)\n",
    "print(\" CATBOOST COMPATIBILITY SUMMARY \".center(72))\n",
    "print(\"=\"*72)\n",
    "print()\n",
    "print(\"| Visualizer          | CatBoost Direct | With Wrapper | Speed     |\")\n",
    "print(\"|---------------------|-----------------|--------------|-----------|\")\n",
    "print(\"| ValidationCurve     | NO (needs CV)   | YES          | VERY SLOW |\")\n",
    "print(\"| LearningCurve       | NO (needs CV)   | YES          | SLOW      |\")\n",
    "print(\"| CVScores            | NO (needs CV)   | YES          | MODERATE  |\")\n",
    "print(\"| FeatureImportances  | YES (is_fitted) | N/A          | FAST      |\")\n",
    "print(\"| RFECV               | NO (needs CV)   | YES          | VERY SLOW |\")\n",
    "print(\"| DroppingCurve       | NO (needs CV)   | YES          | SLOW      |\")\n",
    "print()\n",
    "print(\"RECOMMENDATION FOR TFD:\")\n",
    "print(\"  1. FeatureImportances - ALWAYS USE (fast, works with CatBoost)\")\n",
    "print(\"  2. CVScores - USE for model stability assessment\")\n",
    "print(\"  3. LearningCurve - USE if time permits\")\n",
    "print(\"  4. ValidationCurve - SKIP unless hyperparameter tuning needed\")\n",
    "print(\"  5. DroppingCurve - OPTIONAL for feature redundancy analysis\")\n",
    "print(\"  6. RFECV - SKIP (too slow, use FeatureImportances instead)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tfd_best_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BEST CONFIGURATION FOR TRANSACTION FRAUD DETECTION (TFD)\n",
    "# =============================================================================\n",
    "\n",
    "def yellowbrick_model_selection_kwargs(\n",
    "    classes=None,\n",
    "    feature_names=None,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate kwargs for ALL yellowbrick.model_selection visualizers (TFD optimized).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    classes : list, optional\n",
    "        Class labels (default: [\"Non-Fraud\", \"Fraud\"])\n",
    "    feature_names : list, optional\n",
    "        Feature names for labels (default: None)\n",
    "    verbose : bool\n",
    "        Print configuration details (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of visualizer name -> kwargs\n",
    "    \n",
    "    Note:\n",
    "    -----\n",
    "    All CV-based visualizers require CatBoostWrapperCV.\n",
    "    FeatureImportances works with pre-fitted CatBoost (is_fitted=True).\n",
    "    \"\"\"\n",
    "    if classes is None:\n",
    "        classes = [\"Non-Fraud\", \"Fraud\"]\n",
    "    \n",
    "    kwargs = {\n",
    "        # =================================================================\n",
    "        # PRIMARY: FeatureImportances (FAST, works with CatBoost directly)\n",
    "        # =================================================================\n",
    "        \"FeatureImportances\": {\n",
    "            \"labels\": feature_names,\n",
    "            \"relative\": True,              # Show as % of max\n",
    "            \"absolute\": False,\n",
    "            \"topn\": None,                  # Show all features\n",
    "            \"is_fitted\": True,             # CatBoost compatibility\n",
    "        },\n",
    "        \n",
    "        # =================================================================\n",
    "        # SECONDARY: CVScores (moderate speed with CatBoostWrapperCV)\n",
    "        # =================================================================\n",
    "        \"CVScores\": {\n",
    "            \"cv\": 5,                       # 5-fold stratified CV\n",
    "            \"scoring\": \"f1\",               # F1 score for imbalanced data\n",
    "        },\n",
    "        \n",
    "        # =================================================================\n",
    "        # OPTIONAL: LearningCurve (slow but insightful)\n",
    "        # =================================================================\n",
    "        \"LearningCurve\": {\n",
    "            \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "            \"cv\": 3,                       # Reduce folds for speed\n",
    "            \"scoring\": \"f1\",\n",
    "            \"random_state\": 42,\n",
    "        },\n",
    "        \n",
    "        # =================================================================\n",
    "        # OPTIONAL: DroppingCurve (slow, for feature redundancy)\n",
    "        # =================================================================\n",
    "        \"DroppingCurve\": {\n",
    "            \"feature_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "            \"cv\": 3,\n",
    "            \"scoring\": \"f1\",\n",
    "            \"random_state\": 42,\n",
    "        },\n",
    "        \n",
    "        # =================================================================\n",
    "        # SLOW: ValidationCurve (only for hyperparameter tuning)\n",
    "        # Uncomment if needed for specific hyperparameter analysis\n",
    "        # =================================================================\n",
    "        # \"ValidationCurve\": {\n",
    "        #     \"param_name\": \"depth\",\n",
    "        #     \"param_range\": [4, 6, 8, 10],\n",
    "        #     \"cv\": 3,\n",
    "        #     \"scoring\": \"f1\",\n",
    "        # },\n",
    "        \n",
    "        # =================================================================\n",
    "        # VERY SLOW: RFECV (skip for TFD, use FeatureImportances instead)\n",
    "        # =================================================================\n",
    "        # \"RFECV\": {\n",
    "        #     \"step\": 2,                   # Remove 2 features per iteration\n",
    "        #     \"cv\": 3,\n",
    "        #     \"scoring\": \"f1\",\n",
    "        # },\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print(\"|\" + \" YELLOWBRICK MODEL SELECTION CONFIGURATION \".center(72) + \"|\")\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print(f\"| {'Classes:':<20} {str(classes):<50} |\")\n",
    "        print(f\"| {'Features:':<20} {(str(len(feature_names)) + ' features') if feature_names else 'auto-detect':<50} |\")\n",
    "        print(\"+\" + \"-\" * 72 + \"+\")\n",
    "        print(f\"| {'Configured ' + str(len(kwargs)) + ' visualizers:':<72} |\")\n",
    "        print(\"+\" + \"-\" * 72 + \"+\")\n",
    "        \n",
    "        speed_map = {\n",
    "            \"FeatureImportances\": \"FAST\",\n",
    "            \"CVScores\": \"MODERATE\",\n",
    "            \"LearningCurve\": \"SLOW\",\n",
    "            \"DroppingCurve\": \"SLOW\",\n",
    "            \"ValidationCurve\": \"VERY SLOW\",\n",
    "            \"RFECV\": \"VERY SLOW\",\n",
    "        }\n",
    "        \n",
    "        for i, name in enumerate(kwargs.keys(), 1):\n",
    "            speed = speed_map.get(name, \"UNKNOWN\")\n",
    "            wrapper = \"CatBoost direct\" if name == \"FeatureImportances\" else \"CatBoostWrapperCV\"\n",
    "            print(f\"|   {i:>2}. {name:<25} [{speed:<10}] {wrapper:<20} |\")\n",
    "        \n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print()\n",
    "    \n",
    "    return kwargs\n",
    "\n",
    "\n",
    "# Test the configuration\n",
    "test_kwargs = yellowbrick_model_selection_kwargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualizers_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZERS EXECUTION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def yellowbrick_model_selection_visualizers(\n",
    "    yb_model_selection_kwargs,\n",
    "    estimator,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    YELLOWBRICK_PATH,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Run all model selection visualizers and save to disk.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    yb_model_selection_kwargs : dict\n",
    "        Output from yellowbrick_model_selection_kwargs()\n",
    "    estimator : fitted model\n",
    "        Pre-fitted CatBoost model (for FeatureImportances)\n",
    "    X_train, X_test : array-like\n",
    "        Training and test features\n",
    "    y_train, y_test : array-like\n",
    "        Training and test labels\n",
    "    YELLOWBRICK_PATH : str\n",
    "        Path to save visualizations\n",
    "    verbose : bool\n",
    "        Print progress details (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Summary with successful, failed counts and timing info\n",
    "    \n",
    "    CatBoost Handling:\n",
    "    ------------------\n",
    "    - FeatureImportances: Uses pre-fitted estimator with is_fitted=True\n",
    "    - All others: Creates CatBoostWrapperCV for CV-based training\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    from yellowbrick.model_selection import (\n",
    "        FeatureImportances,\n",
    "        CVScores,\n",
    "        LearningCurve,\n",
    "        DroppingCurve,\n",
    "        ValidationCurve,\n",
    "        RFECV,\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"{YELLOWBRICK_PATH}/model_selection\", exist_ok=True)\n",
    "\n",
    "    # Map visualizer names to classes\n",
    "    visualizer_map = {\n",
    "        \"FeatureImportances\": FeatureImportances,\n",
    "        \"CVScores\": CVScores,\n",
    "        \"LearningCurve\": LearningCurve,\n",
    "        \"DroppingCurve\": DroppingCurve,\n",
    "        \"ValidationCurve\": ValidationCurve,\n",
    "        \"RFECV\": RFECV,\n",
    "    }\n",
    "\n",
    "    total = len(yb_model_selection_kwargs)\n",
    "    results = []\n",
    "    start_total = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print(\"|\" + \" YELLOWBRICK MODEL SELECTION ANALYSIS \".center(72) + \"|\")\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print(f\"| {'Started:':<15} {datetime.now().strftime('%Y-%m-%d %H:%M:%S'):<55} |\")\n",
    "        print(f\"| {'Train shape:':<15} {str(X_train.shape[0]) + ' samples':<55} |\")\n",
    "        print(f\"| {'Test shape:':<15} {str(X_test.shape[0]) + ' samples':<55} |\")\n",
    "        print(f\"| {'Model:':<15} {type(estimator).__name__:<55} |\")\n",
    "        print(f\"| {'Output:':<15} {YELLOWBRICK_PATH + '/model_selection/':<55} |\")\n",
    "        print(f\"| {'Visualizers:':<15} {str(total) + ' to process':<55} |\")\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print()\n",
    "\n",
    "    # Combine data for CV-based visualizers\n",
    "    X_full = pd.concat([X_train, X_test], ignore_index=True) if hasattr(X_train, 'concat') else np.vstack([X_train, X_test])\n",
    "    y_full = pd.concat([y_train, y_test], ignore_index=True) if hasattr(y_train, 'concat') else np.hstack([y_train, y_test])\n",
    "\n",
    "    for idx, (visualizer_name, kwargs) in enumerate(yb_model_selection_kwargs.items(), 1):\n",
    "        start_time = time.time()\n",
    "        status = \"OK\"\n",
    "        error_msg = None\n",
    "        output_path = None\n",
    "\n",
    "        if verbose:\n",
    "            progress = f\"[{idx}/{total}]\"\n",
    "            bar_width = 20\n",
    "            filled = int(bar_width * idx / total)\n",
    "            bar = \"\\u2588\" * filled + \"\\u2591\" * (bar_width - filled)\n",
    "            print(f\"{progress} |{bar}| {visualizer_name}...\", end=\" \", flush=True)\n",
    "\n",
    "        try:\n",
    "            vis_class = visualizer_map.get(visualizer_name)\n",
    "            if vis_class is None:\n",
    "                raise ValueError(f\"Unknown visualizer: {visualizer_name}\")\n",
    "\n",
    "            if visualizer_name == \"FeatureImportances\":\n",
    "                # FeatureImportances works with pre-fitted CatBoost\n",
    "                visualizer = vis_class(estimator, **kwargs)\n",
    "                visualizer.fit(X_train, y_train)\n",
    "            else:\n",
    "                # All other visualizers need CatBoostWrapperCV\n",
    "                cv_wrapper = CatBoostWrapperCV(\n",
    "                    iterations=100,\n",
    "                    depth=6,\n",
    "                    learning_rate=0.1,\n",
    "                )\n",
    "                visualizer = vis_class(cv_wrapper, **kwargs)\n",
    "                visualizer.fit(X_full, y_full)\n",
    "\n",
    "            visualizer.show()\n",
    "            output_path = f\"{YELLOWBRICK_PATH}/model_selection/{visualizer_name}.png\"\n",
    "            visualizer.fig.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "            plt.clf()\n",
    "            plt.close('all')\n",
    "\n",
    "        except Exception as e:\n",
    "            status = \"FAILED\"\n",
    "            error_msg = str(e)\n",
    "            plt.clf()\n",
    "            plt.close('all')\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        results.append({\n",
    "            \"name\": visualizer_name,\n",
    "            \"status\": status,\n",
    "            \"time\": elapsed,\n",
    "            \"output\": output_path,\n",
    "            \"error\": error_msg\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            if status == \"OK\":\n",
    "                print(f\"\\u2713 ({elapsed:.2f}s)\")\n",
    "            else:\n",
    "                print(f\"\\u2717 FAILED ({elapsed:.2f}s)\")\n",
    "                err_display = error_msg[:60] + \"...\" if len(str(error_msg)) > 60 else error_msg\n",
    "                print(f\"         \\u2514\\u2500 Error: {err_display}\")\n",
    "\n",
    "    total_time = time.time() - start_total\n",
    "    successful = sum(1 for r in results if r[\"status\"] == \"OK\")\n",
    "    failed = sum(1 for r in results if r[\"status\"] == \"FAILED\")\n",
    "\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print(\"|\" + \" SUMMARY \".center(72) + \"|\")\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "        print(f\"| {'Completed:':<15} {datetime.now().strftime('%Y-%m-%d %H:%M:%S'):<55} |\")\n",
    "        print(f\"| {'Total time:':<15} {f'{total_time:.2f} seconds':<55} |\")\n",
    "        print(f\"| {'Successful:':<15} {f'{successful}/{total} visualizers':<55} |\")\n",
    "        if failed > 0:\n",
    "            print(f\"| {'Failed:':<15} {f'{failed}/{total} visualizers':<55} |\")\n",
    "        print(\"+\" + \"-\" * 72 + \"+\")\n",
    "        print(\"|\" + \" TIMING BREAKDOWN \".center(72) + \"|\")\n",
    "        print(\"+\" + \"-\" * 72 + \"+\")\n",
    "\n",
    "        sorted_results = sorted(results, key=lambda x: x[\"time\"], reverse=True)\n",
    "        for r in sorted_results:\n",
    "            status_icon = \"\\u2713\" if r[\"status\"] == \"OK\" else \"\\u2717\"\n",
    "            time_bar_width = 20\n",
    "            max_time = max(r[\"time\"] for r in results) if results else 1\n",
    "            filled = int(time_bar_width * r[\"time\"] / max_time) if max_time > 0 else 0\n",
    "            time_bar = \"\\u2593\" * filled + \"\\u2591\" * (time_bar_width - filled)\n",
    "            print(f\"| {status_icon} {r['name']:<30} |{time_bar}| {r['time']:>8.2f}s |\")\n",
    "\n",
    "        print(\"+\" + \"=\" * 72 + \"+\")\n",
    "\n",
    "        if successful > 0:\n",
    "            print()\n",
    "            print(\"Saved visualizations:\")\n",
    "            for r in results:\n",
    "                if r[\"status\"] == \"OK\" and r[\"output\"]:\n",
    "                    print(f\"  \\u2192 {r['output']}\")\n",
    "        print()\n",
    "\n",
    "    return {\n",
    "        \"successful\": successful,\n",
    "        \"failed\": failed,\n",
    "        \"total_time\": total_time,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"yellowbrick_model_selection_visualizers() function defined\")\n",
    "print(\"  - FeatureImportances: Uses pre-fitted CatBoost directly\")\n",
    "print(\"  - All others: Uses CatBoostWrapperCV for CV-based training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "key_insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# KEY INSIGHTS FOR TFD MODEL SELECTION\n",
    "# =============================================================================\n",
    "#\n",
    "# 1. VISUALIZER PRIORITY FOR TFD:\n",
    "#    - FeatureImportances: ESSENTIAL (understand model decisions)\n",
    "#    - CVScores: RECOMMENDED (validate model stability)\n",
    "#    - LearningCurve: OPTIONAL (check if more data helps)\n",
    "#    - DroppingCurve: OPTIONAL (feature redundancy analysis)\n",
    "#    - ValidationCurve: SKIP (use Optuna for hyperparameter tuning)\n",
    "#    - RFECV: SKIP (too slow, use FeatureImportances + domain knowledge)\n",
    "#\n",
    "# 2. CATBOOST COMPATIBILITY:\n",
    "#    | Visualizer          | Works with CatBoost | Wrapper Needed |\n",
    "#    |---------------------|---------------------|----------------|\n",
    "#    | FeatureImportances  | YES (is_fitted=True)| NO             |\n",
    "#    | CVScores            | NO                  | CatBoostWrapperCV |\n",
    "#    | LearningCurve       | NO                  | CatBoostWrapperCV |\n",
    "#    | DroppingCurve       | NO                  | CatBoostWrapperCV |\n",
    "#    | ValidationCurve     | NO                  | CatBoostWrapperCV |\n",
    "#    | RFECV               | NO                  | CatBoostWrapperCV |\n",
    "#\n",
    "# 3. PERFORMANCE CONSIDERATIONS:\n",
    "#    - FeatureImportances: O(1) - just reads model attributes\n",
    "#    - CVScores: O(n_folds) - moderate\n",
    "#    - LearningCurve: O(n_sizes * n_folds) - slow\n",
    "#    - DroppingCurve: O(n_sizes * n_folds) - slow\n",
    "#    - ValidationCurve: O(n_params * n_folds) - very slow\n",
    "#    - RFECV: O(n_features * n_folds) - extremely slow\n",
    "#\n",
    "# 4. BEST PRACTICES:\n",
    "#    - Always use FeatureImportances after training\n",
    "#    - Use CVScores with StratifiedKFold for imbalanced data\n",
    "#    - Use scoring='f1' or 'average_precision' (not 'accuracy')\n",
    "#    - Reduce CV folds (cv=3) for slow visualizers\n",
    "#    - Sample data for very slow visualizers\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "print(\"KEY INSIGHTS DOCUMENTED ABOVE\")\n",
    "print()\n",
    "print(\"YELLOWBRICK MODEL SELECTION SUMMARY:\")\n",
    "print(\"  Total Visualizers: 6\")\n",
    "print()\n",
    "print(\"  RECOMMENDED FOR TFD:\")\n",
    "print(\"    1. FeatureImportances (FAST, CatBoost-native)\")\n",
    "print(\"    2. CVScores (MODERATE, model stability)\")\n",
    "print()\n",
    "print(\"  OPTIONAL:\")\n",
    "print(\"    3. LearningCurve (SLOW, data sufficiency)\")\n",
    "print(\"    4. DroppingCurve (SLOW, feature redundancy)\")\n",
    "print()\n",
    "print(\"  SKIP FOR TFD:\")\n",
    "print(\"    5. ValidationCurve (use Optuna instead)\")\n",
    "print(\"    6. RFECV (too slow, use FeatureImportances)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
