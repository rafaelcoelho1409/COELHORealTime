{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick import classifier\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list_all_classifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get all items from yellowbrick.classifier\n",
    "all_items = [name for name in dir(classifier) if not name.startswith('_')]\n",
    "print(\"All items in yellowbrick.classifier module:\")\n",
    "print(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "categorize_items",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize items by type\n",
    "functions = []\n",
    "classes = []\n",
    "submodules = []\n",
    "\n",
    "for name in all_items:\n",
    "    obj = getattr(classifier, name)\n",
    "    if inspect.isfunction(obj):\n",
    "        functions.append(name)\n",
    "    elif inspect.isclass(obj):\n",
    "        classes.append(name)\n",
    "    elif inspect.ismodule(obj):\n",
    "        submodules.append(name)\n",
    "\n",
    "print(f\"Functions (quick methods): {len(functions)}\")\n",
    "print(functions)\n",
    "print(f\"\\nClasses (visualizers): {len(classes)}\")\n",
    "print(classes)\n",
    "print(f\"\\nSubmodules: {len(submodules)}\")\n",
    "print(submodules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classifier_overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YELLOWBRICK CLASSIFIER MODULE OVERVIEW\n",
    "# =============================================================================\n",
    "#\n",
    "# yellowbrick.classifier provides visualizers for classification model evaluation:\n",
    "# - Confusion matrices and classification reports\n",
    "# - ROC curves and AUC metrics\n",
    "# - Precision-Recall curves\n",
    "# - Class prediction errors\n",
    "# - Threshold analysis for binary classifiers\n",
    "#\n",
    "# IMPORTANT: CatBoost Compatibility\n",
    "# ---------------------------------\n",
    "# YellowBrick visualizers expect sklearn-compatible estimators.\n",
    "# CatBoost is NOT fully sklearn-compatible but has similar interface.\n",
    "#\n",
    "# Solutions:\n",
    "# 1. Use `force_model=True` to bypass sklearn validation\n",
    "# 2. Use `is_fitted=True` to skip fit checks\n",
    "# 3. For some visualizers, use pre-computed predictions directly\n",
    "#\n",
    "# =============================================================================\n",
    "# AVAILABLE VISUALIZERS (6 total):\n",
    "# =============================================================================\n",
    "#\n",
    "# METRICS VISUALIZERS (use predictions):\n",
    "# 1. ClassificationReport - Precision, Recall, F1 heatmap per class\n",
    "# 2. ConfusionMatrix - Confusion matrix heatmap\n",
    "# 3. ClassPredictionError - Bar chart showing prediction errors per class\n",
    "#\n",
    "# PROBABILITY-BASED VISUALIZERS (use predict_proba):\n",
    "# 4. ROCAUC - ROC curve and AUC score\n",
    "# 5. PrecisionRecallCurve - PR curve with optional ISO F1 curves\n",
    "#\n",
    "# THRESHOLD VISUALIZERS (binary only):\n",
    "# 6. DiscriminationThreshold - Metrics across decision thresholds\n",
    "#\n",
    "# =============================================================================\n",
    "print(\"Yellowbrick Classifier Module - 6 Visualizers Available\")\n",
    "print(\"  - 3 Metrics-based (ClassificationReport, ConfusionMatrix, ClassPredictionError)\")\n",
    "print(\"  - 2 Probability-based (ROCAUC, PrecisionRecallCurve)\")\n",
    "print(\"  - 1 Threshold-based (DiscriminationThreshold)\")\n",
    "print()\n",
    "print(\"CatBoost Compatibility: Use force_model=True and is_fitted=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catboost_compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATBOOST COMPATIBILITY ANALYSIS\n",
    "# =============================================================================\n",
    "#\n",
    "# YellowBrick uses sklearn's check_is_fitted() and is_classifier() functions\n",
    "# which may fail with CatBoost. Here's how to handle each visualizer:\n",
    "#\n",
    "# | Visualizer              | CatBoost Compatible | Solution                    |\n",
    "# |-------------------------|---------------------|-----------------------------|\n",
    "# | ClassificationReport    | Yes (with workaround) | force_model=True, is_fitted=True |\n",
    "# | ConfusionMatrix         | Yes (with workaround) | force_model=True, is_fitted=True |\n",
    "# | ClassPredictionError    | Yes (with workaround) | force_model=True, is_fitted=True |\n",
    "# | ROCAUC                  | Yes (with workaround) | force_model=True, is_fitted=True |\n",
    "# | PrecisionRecallCurve    | Yes (with workaround) | force_model=True, is_fitted=True |\n",
    "# | DiscriminationThreshold | PROBLEMATIC          | Requires multiple fit calls     |\n",
    "#\n",
    "# Key CatBoost methods that YellowBrick uses:\n",
    "# - predict(X) -> Returns class labels (0 or 1)\n",
    "# - predict_proba(X) -> Returns probability matrix [[p_0, p_1], ...]\n",
    "# - classes_ -> Class labels (CatBoost has this after fit)\n",
    "#\n",
    "# =============================================================================\n",
    "print(\"CatBoost Compatibility Summary:\")\n",
    "print(\"  - Most visualizers work with force_model=True\")\n",
    "print(\"  - DiscriminationThreshold may have issues (requires CV)\")\n",
    "print(\"  - Always use is_fitted=True with pre-trained CatBoost models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification_report_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. CLASSIFICATION REPORT VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Displays precision, recall, F1-score, and support for each class\n",
    "# as a color-coded heatmap. Essential for understanding per-class performance.\n",
    "#\n",
    "# Use Case: Compare model performance across different classes,\n",
    "# identify classes where model struggles (low recall/precision).\n",
    "#\n",
    "# Best For:\n",
    "# - Fraud Detection: See precision/recall for fraud vs non-fraud separately\n",
    "# - Multi-class: Compare performance across all classes\n",
    "# - Imbalanced Data: Support column shows class distribution\n",
    "#\n",
    "# CatBoost Compatibility: YES with force_model=True, is_fitted=True\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "classification_report_class = classifier.ClassificationReport\n",
    "\n",
    "classification_report_kwargs = {\n",
    "    # Core Configuration\n",
    "    \"ax\": None,                    # matplotlib Axes object (default: None)\n",
    "    \"classes\": None,               # Class labels ordered by sorted class index\n",
    "    \"cmap\": \"YlOrRd\",              # Colormap: 'YlOrRd', 'Blues', 'RdBu_r', etc.\n",
    "    \"support\": \"count\",            # Support display: True, False, None, 'percent', 'count'\n",
    "    \"encoder\": None,               # LabelEncoder or dict for class name mapping\n",
    "    \"colorbar\": True,              # Show colorbar legend (default: True)\n",
    "    \"fontsize\": None,              # Font size for labels (default: None = auto)\n",
    "    \n",
    "    # CatBoost Compatibility\n",
    "    \"is_fitted\": True,             # REQUIRED for CatBoost: skip fit check\n",
    "    \"force_model\": True,           # REQUIRED for CatBoost: bypass sklearn validation\n",
    "}\n",
    "\n",
    "# Quick method signature\n",
    "# classification_report(estimator, X_train, y_train, X_test=None, y_test=None,\n",
    "#                       ax=None, classes=None, cmap='YlOrRd', support=None,\n",
    "#                       encoder=None, is_fitted='auto', force_model=False,\n",
    "#                       colorbar=True, fontsize=None, show=True, **kwargs)\n",
    "\n",
    "print(\"ClassificationReport kwargs:\")\n",
    "for key, value in classification_report_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion_matrix_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. CONFUSION MATRIX VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Visualizes the confusion matrix as a heatmap showing\n",
    "# true vs predicted class distributions.\n",
    "#\n",
    "# Use Case: Understand where model confuses classes,\n",
    "# see TP, TN, FP, FN distributions.\n",
    "#\n",
    "# Best For:\n",
    "# - Fraud Detection: See false positives vs false negatives\n",
    "# - Error Analysis: Identify which classes are confused\n",
    "# - Model Comparison: Compare confusion patterns between models\n",
    "#\n",
    "# CatBoost Compatibility: YES with force_model=True, is_fitted=True\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "confusion_matrix_class = classifier.ConfusionMatrix\n",
    "\n",
    "confusion_matrix_kwargs = {\n",
    "    # Core Configuration\n",
    "    \"ax\": None,                    # matplotlib Axes object (default: None)\n",
    "    \"classes\": None,               # Class labels for display\n",
    "    \"cmap\": \"YlOrRd\",              # Colormap for heatmap\n",
    "    \"percent\": False,              # Show percentages instead of counts\n",
    "    \"fontsize\": None,              # Font size for cell values\n",
    "    \"encoder\": None,               # LabelEncoder or dict for class names\n",
    "    \"sample_weight\": None,         # Sample weights for confusion_matrix\n",
    "    \n",
    "    # CatBoost Compatibility\n",
    "    \"is_fitted\": True,             # REQUIRED for CatBoost\n",
    "    \"force_model\": True,           # REQUIRED for CatBoost\n",
    "}\n",
    "\n",
    "# Quick method signature\n",
    "# confusion_matrix(estimator, X_train, y_train, X_test=None, y_test=None,\n",
    "#                  ax=None, sample_weight=None, percent=False, classes=None,\n",
    "#                  encoder=None, cmap='YlOrRd', fontsize=None, is_fitted='auto',\n",
    "#                  force_model=False, show=True, **kwargs)\n",
    "\n",
    "print(\"ConfusionMatrix kwargs:\")\n",
    "for key, value in confusion_matrix_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocauc_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. ROCAUC VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Plots Receiver Operating Characteristic curve and calculates\n",
    "# Area Under the Curve (AUC) score.\n",
    "#\n",
    "# Use Case: Evaluate classifier's ability to discriminate between classes,\n",
    "# compare models using AUC metric.\n",
    "#\n",
    "# Best For:\n",
    "# - Fraud Detection: See trade-off between TPR and FPR\n",
    "# - Model Selection: AUC is robust to class imbalance\n",
    "# - Threshold Selection: Identify optimal operating point\n",
    "#\n",
    "# CatBoost Compatibility: YES with force_model=True, is_fitted=True\n",
    "# Requires: predict_proba() method (CatBoost has this)\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "rocauc_class = classifier.ROCAUC\n",
    "\n",
    "rocauc_kwargs = {\n",
    "    # Core Configuration\n",
    "    \"ax\": None,                    # matplotlib Axes object (default: None)\n",
    "    \"classes\": None,               # Class labels for legend\n",
    "    \"encoder\": None,               # LabelEncoder or dict for class names\n",
    "    \n",
    "    # Curve Options (for multi-class)\n",
    "    \"micro\": True,                 # Show micro-average ROC (aggregated TP/FP)\n",
    "    \"macro\": True,                 # Show macro-average ROC (average across classes)\n",
    "    \"per_class\": True,             # Show individual class ROC curves\n",
    "    \n",
    "    # Binary Classification Shortcut\n",
    "    \"binary\": False,               # If True, sets micro=macro=per_class=False\n",
    "    \n",
    "    # CatBoost Compatibility\n",
    "    \"is_fitted\": True,             # REQUIRED for CatBoost\n",
    "    \"force_model\": True,           # REQUIRED for CatBoost\n",
    "}\n",
    "\n",
    "# Quick method signature\n",
    "# roc_auc(estimator, X_train, y_train, X_test=None, y_test=None,\n",
    "#         ax=None, micro=True, macro=True, per_class=True, binary=False,\n",
    "#         classes=None, encoder=None, is_fitted='auto', force_model=False,\n",
    "#         show=True, **kwargs)\n",
    "\n",
    "print(\"ROCAUC kwargs:\")\n",
    "for key, value in rocauc_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precision_recall_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. PRECISION-RECALL CURVE VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Plots precision vs recall trade-off at different thresholds.\n",
    "# Better than ROC for imbalanced datasets!\n",
    "#\n",
    "# Use Case: Evaluate model on imbalanced data where precision matters,\n",
    "# understand threshold effects on precision/recall trade-off.\n",
    "#\n",
    "# Best For:\n",
    "# - Fraud Detection: CRITICAL - fraud is rare, PR curve is more informative\n",
    "# - Imbalanced Data: PR curve doesn't inflate with majority class\n",
    "# - Threshold Tuning: Find optimal precision/recall balance\n",
    "#\n",
    "# CatBoost Compatibility: YES with force_model=True, is_fitted=True\n",
    "# Requires: predict_proba() method (CatBoost has this)\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "precision_recall_class = classifier.PrecisionRecallCurve\n",
    "\n",
    "precision_recall_kwargs = {\n",
    "    # Core Configuration\n",
    "    \"ax\": None,                    # matplotlib Axes object (default: None)\n",
    "    \"classes\": None,               # Class labels for legend\n",
    "    \"encoder\": None,               # LabelEncoder or dict for class names\n",
    "    \n",
    "    # Curve Options\n",
    "    \"fill_area\": True,             # Fill area under curve\n",
    "    \"fill_opacity\": 0.2,           # Fill transparency (0-1)\n",
    "    \"line_opacity\": 0.8,           # Line transparency (0-1)\n",
    "    \"ap_score\": True,              # Show Average Precision score\n",
    "    \n",
    "    # Multi-class Options\n",
    "    \"micro\": True,                 # Micro-average PR curve\n",
    "    \"per_class\": False,            # Individual class curves\n",
    "    \n",
    "    # ISO F1 Curves (optional)\n",
    "    \"iso_f1_curves\": False,        # Show ISO F1 score curves\n",
    "    \"iso_f1_values\": (0.2, 0.4, 0.6, 0.8),  # F1 values for ISO curves\n",
    "    \n",
    "    # Color Options\n",
    "    \"colors\": None,                # Custom colors for per_class curves\n",
    "    \"cmap\": None,                  # Colormap for per_class curves\n",
    "    \n",
    "    # CatBoost Compatibility\n",
    "    \"is_fitted\": True,             # REQUIRED for CatBoost\n",
    "    \"force_model\": True,           # REQUIRED for CatBoost\n",
    "}\n",
    "\n",
    "# Quick method signature\n",
    "# precision_recall_curve(estimator, X_train, y_train, X_test=None, y_test=None,\n",
    "#                        ax=None, classes=None, colors=None, cmap=None,\n",
    "#                        encoder=None, fill_area=True, ap_score=True,\n",
    "#                        micro=True, iso_f1_curves=False, iso_f1_values=(0.2,0.4,0.6,0.8),\n",
    "#                        per_class=False, fill_opacity=0.2, line_opacity=0.8,\n",
    "#                        is_fitted='auto', force_model=False, show=True, **kwargs)\n",
    "\n",
    "print(\"PrecisionRecallCurve kwargs:\")\n",
    "for key, value in precision_recall_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "class_prediction_error_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. CLASS PREDICTION ERROR VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Bar chart showing both support and prediction errors per class.\n",
    "# Alternative to confusion matrix that's easier to read.\n",
    "#\n",
    "# Use Case: Quickly see which classes have most errors,\n",
    "# understand class-level prediction patterns.\n",
    "#\n",
    "# Best For:\n",
    "# - Multi-class: See error distribution across classes\n",
    "# - Imbalanced Data: Visualize how minority class is predicted\n",
    "# - Quick Analysis: Faster to interpret than confusion matrix\n",
    "#\n",
    "# CatBoost Compatibility: YES with force_model=True, is_fitted=True\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "class_prediction_error_class = classifier.ClassPredictionError\n",
    "\n",
    "class_prediction_error_kwargs = {\n",
    "    # Core Configuration\n",
    "    \"ax\": None,                    # matplotlib Axes object (default: None)\n",
    "    \"classes\": None,               # Class labels for legend\n",
    "    \"encoder\": None,               # LabelEncoder or dict for class names\n",
    "    \n",
    "    # CatBoost Compatibility\n",
    "    \"is_fitted\": True,             # REQUIRED for CatBoost\n",
    "    \"force_model\": True,           # REQUIRED for CatBoost\n",
    "}\n",
    "\n",
    "# Quick method signature\n",
    "# class_prediction_error(estimator, X_train, y_train, X_test=None, y_test=None,\n",
    "#                        ax=None, classes=None, encoder=None,\n",
    "#                        is_fitted='auto', force_model=False, show=True, **kwargs)\n",
    "\n",
    "print(\"ClassPredictionError kwargs:\")\n",
    "for key, value in class_prediction_error_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrimination_threshold_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. DISCRIMINATION THRESHOLD VISUALIZER\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose: Shows precision, recall, F1, and queue rate across all\n",
    "# decision thresholds. Helps find optimal threshold.\n",
    "#\n",
    "# Use Case: Tune decision threshold for binary classifier,\n",
    "# understand trade-offs at different operating points.\n",
    "#\n",
    "# Best For:\n",
    "# - Fraud Detection: Find threshold balancing false positives/negatives\n",
    "# - Cost-Sensitive: When FP and FN have different costs\n",
    "# - Threshold Optimization: Data-driven threshold selection\n",
    "#\n",
    "# CatBoost Compatibility: PROBLEMATIC\n",
    "# - Requires multiple fit calls with cross-validation\n",
    "# - May not work reliably with CatBoost\n",
    "# - Alternative: Use sklearn's precision_recall_curve manually\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "discrimination_threshold_class = classifier.DiscriminationThreshold\n",
    "\n",
    "discrimination_threshold_kwargs = {\n",
    "    # Core Configuration\n",
    "    \"ax\": None,                    # matplotlib Axes object (default: None)\n",
    "    \n",
    "    # Cross-validation Settings\n",
    "    \"n_trials\": 50,                # Number of shuffle/split trials\n",
    "    \"cv\": 0.1,                     # Test split fraction or CV generator\n",
    "    \n",
    "    # Metric Options\n",
    "    \"fbeta\": 1.0,                  # Beta for F-beta score (1.0 = F1)\n",
    "    \"argmax\": \"fscore\",            # Metric to highlight: 'precision', 'recall', 'queue_rate', 'fscore'\n",
    "    \"exclude\": None,               # Metrics to exclude from plot\n",
    "    \n",
    "    # Visualization Options\n",
    "    \"quantiles\": (0.1, 0.5, 0.9),  # Quantiles for uncertainty bands\n",
    "    \"random_state\": 42,            # Reproducibility seed\n",
    "    \n",
    "    # CatBoost Compatibility (may not work)\n",
    "    \"is_fitted\": False,            # Must be False - needs to fit multiple times\n",
    "    \"force_model\": True,           # Try to bypass validation\n",
    "}\n",
    "\n",
    "# Quick method signature\n",
    "# discrimination_threshold(estimator, X, y, ax=None, n_trials=50, cv=0.1,\n",
    "#                          fbeta=1.0, argmax='fscore', exclude=None,\n",
    "#                          quantiles=(0.1, 0.5, 0.9), random_state=None,\n",
    "#                          is_fitted='auto', force_model=False, show=True, **kwargs)\n",
    "\n",
    "print(\"DiscriminationThreshold kwargs:\")\n",
    "print(\"  WARNING: May not work with CatBoost (requires CV refitting)\")\n",
    "for key, value in discrimination_threshold_kwargs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tfd_recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RECOMMENDED CONFIGURATION FOR TRANSACTION FRAUD DETECTION (TFD)\n",
    "# =============================================================================\n",
    "#\n",
    "# TFD Characteristics:\n",
    "# - Binary classification (fraud=1, non-fraud=0)\n",
    "# - Highly imbalanced (~1-5% fraud rate)\n",
    "# - Model: CatBoost (not sklearn-native)\n",
    "#\n",
    "# Classification Goals:\n",
    "# 1. High Recall (catch most fraud)\n",
    "# 2. Acceptable Precision (minimize false alarms)\n",
    "# 3. Understand trade-offs at different thresholds\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "# Binary class labels for TFD\n",
    "tfd_classes = [\"Non-Fraud\", \"Fraud\"]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PRIMARY CLASSIFIER VISUALIZERS - Most useful for fraud detection\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "primary_classifier_visualizers = {\n",
    "    # ConfusionMatrix: See TP, TN, FP, FN distribution\n",
    "    # CRITICAL for understanding fraud detection performance\n",
    "    \"ConfusionMatrix\": {\n",
    "        \"classes\": tfd_classes,\n",
    "        \"cmap\": \"Blues\",            # Blue heatmap (professional look)\n",
    "        \"percent\": True,            # Show percentages (better for imbalanced)\n",
    "        \"is_fitted\": True,\n",
    "        \"force_model\": True,\n",
    "    },\n",
    "    \n",
    "    # ClassificationReport: Per-class precision, recall, F1\n",
    "    # Shows separate performance for fraud vs non-fraud\n",
    "    \"ClassificationReport\": {\n",
    "        \"classes\": tfd_classes,\n",
    "        \"cmap\": \"YlOrRd\",           # Yellow-Orange-Red (default)\n",
    "        \"support\": \"percent\",       # Show class distribution as %\n",
    "        \"colorbar\": True,\n",
    "        \"is_fitted\": True,\n",
    "        \"force_model\": True,\n",
    "    },\n",
    "    \n",
    "    # ROCAUC: ROC curve for binary classification\n",
    "    # AUC is threshold-independent metric\n",
    "    \"ROCAUC\": {\n",
    "        \"classes\": tfd_classes,\n",
    "        \"binary\": True,             # Binary mode for cleaner plot\n",
    "        \"is_fitted\": True,\n",
    "        \"force_model\": True,\n",
    "    },\n",
    "    \n",
    "    # PrecisionRecallCurve: BEST for imbalanced data!\n",
    "    # More informative than ROC for fraud detection\n",
    "    \"PrecisionRecallCurve\": {\n",
    "        \"classes\": tfd_classes,\n",
    "        \"fill_area\": True,\n",
    "        \"ap_score\": True,           # Show Average Precision\n",
    "        \"iso_f1_curves\": True,      # Show F1 score reference curves\n",
    "        \"is_fitted\": True,\n",
    "        \"force_model\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Primary Classifier Visualizers for TFD:\")\n",
    "for name, kwargs in primary_classifier_visualizers.items():\n",
    "    print(f\"\\n  {name}:\")\n",
    "    for key, value in kwargs.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary_visualizers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# SECONDARY CLASSIFIER VISUALIZERS - Additional analysis\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "secondary_classifier_visualizers = {\n",
    "    # ClassPredictionError: Bar chart of prediction errors\n",
    "    # Alternative to confusion matrix\n",
    "    \"ClassPredictionError\": {\n",
    "        \"classes\": tfd_classes,\n",
    "        \"is_fitted\": True,\n",
    "        \"force_model\": True,\n",
    "    },\n",
    "    \n",
    "    # DiscriminationThreshold: Threshold optimization\n",
    "    # WARNING: May not work with CatBoost\n",
    "    # \"DiscriminationThreshold\": {\n",
    "    #     \"n_trials\": 10,           # Reduce trials for speed\n",
    "    #     \"cv\": 0.2,                # 20% test split\n",
    "    #     \"argmax\": \"fscore\",       # Highlight best F1 threshold\n",
    "    #     \"random_state\": 42,\n",
    "    #     \"force_model\": True,\n",
    "    # },\n",
    "}\n",
    "\n",
    "print(\"Secondary Classifier Visualizers for TFD:\")\n",
    "for name, kwargs in secondary_classifier_visualizers.items():\n",
    "    print(f\"\\n  {name}:\")\n",
    "    for key, value in kwargs.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONSOLIDATED CONFIGURATION FOR NOTEBOOK 010 INTEGRATION\n",
    "# =============================================================================\n",
    "\n",
    "def yellowbrick_classification_kwargs(\n",
    "    project_name,\n",
    "    metric_name,\n",
    "    y_train=None,\n",
    "    classes=None,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate kwargs for a specific yellowbrick.classifier visualizer.\n",
    "    \n",
    "    Reference: https://www.scikit-yb.org/en/latest/api/classifier/index.html\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    project_name : str\n",
    "        Project identifier (e.g., 'Transaction Fraud Detection')\n",
    "    metric_name : str\n",
    "        Visualizer name: 'ConfusionMatrix', 'ClassificationReport', etc.\n",
    "    y_train : array-like, optional\n",
    "        Training labels for class detection\n",
    "    classes : list, optional\n",
    "        Class labels (default: auto-detected or ['Non-Fraud', 'Fraud'])\n",
    "    verbose : bool\n",
    "        Print configuration details (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : kwargs for the specified visualizer\n",
    "    \n",
    "    CatBoost Compatibility:\n",
    "    -----------------------\n",
    "    All visualizers use force_model=True and is_fitted=True to work with CatBoost.\n",
    "    \"\"\"\n",
    "    # Default classes for fraud detection\n",
    "    if classes is None:\n",
    "        classes = [\"Non-Fraud\", \"Fraud\"] if \"Fraud\" in project_name else None\n",
    "    \n",
    "    # Visualizer-specific configurations optimized for CatBoost + fraud detection\n",
    "    configs = {\n",
    "        # ConfusionMatrix: Essential for fraud detection\n",
    "        \"ConfusionMatrix\": {\n",
    "            \"classes\": classes,\n",
    "            \"cmap\": \"Blues\",\n",
    "            \"percent\": True,        # Percentages better for imbalanced data\n",
    "            \"is_fitted\": True,      # CatBoost compatibility\n",
    "            \"force_model\": True,    # CatBoost compatibility\n",
    "        },\n",
    "        \n",
    "        # ClassificationReport: Per-class metrics heatmap\n",
    "        \"ClassificationReport\": {\n",
    "            \"classes\": classes,\n",
    "            \"cmap\": \"YlOrRd\",\n",
    "            \"support\": \"percent\",   # Show class distribution\n",
    "            \"colorbar\": True,\n",
    "            \"is_fitted\": True,\n",
    "            \"force_model\": True,\n",
    "        },\n",
    "        \n",
    "        # ROCAUC: ROC curve with AUC score\n",
    "        \"ROCAUC\": {\n",
    "            \"classes\": classes,\n",
    "            \"binary\": True,         # Binary mode for TFD\n",
    "            \"is_fitted\": True,\n",
    "            \"force_model\": True,\n",
    "        },\n",
    "        \n",
    "        # PrecisionRecallCurve: BEST for imbalanced data\n",
    "        \"PrecisionRecallCurve\": {\n",
    "            \"classes\": classes,\n",
    "            \"fill_area\": True,\n",
    "            \"ap_score\": True,\n",
    "            \"iso_f1_curves\": True,  # Show F1 reference curves\n",
    "            \"is_fitted\": True,\n",
    "            \"force_model\": True,\n",
    "        },\n",
    "        \n",
    "        # ClassPredictionError: Bar chart of errors\n",
    "        \"ClassPredictionError\": {\n",
    "            \"classes\": classes,\n",
    "            \"is_fitted\": True,\n",
    "            \"force_model\": True,\n",
    "        },\n",
    "        \n",
    "        # DiscriminationThreshold: NOT recommended for CatBoost\n",
    "        # Requires multiple fit calls which may fail\n",
    "        \"DiscriminationThreshold\": {\n",
    "            \"n_trials\": 10,\n",
    "            \"cv\": 0.2,\n",
    "            \"argmax\": \"fscore\",\n",
    "            \"random_state\": 42,\n",
    "            \"is_fitted\": False,     # Must be False for CV\n",
    "            \"force_model\": True,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    kwargs = configs.get(metric_name, {})\n",
    "    \n",
    "    if verbose and kwargs:\n",
    "        print(f\"\\n{metric_name} kwargs for {project_name}:\")\n",
    "        for key, value in kwargs.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def yellowbrick_classification_visualizers(\n",
    "    yb_classification_kwargs,\n",
    "    estimator,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    metric_name=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and fit a yellowbrick.classifier visualizer.\n",
    "    \n",
    "    Reference: https://www.scikit-yb.org/en/latest/api/classifier/index.html\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    yb_classification_kwargs : dict\n",
    "        Output from yellowbrick_classification_kwargs()\n",
    "    estimator : fitted model\n",
    "        CatBoost or sklearn classifier (must be pre-fitted)\n",
    "    X_train, X_test : array-like\n",
    "        Training and test features\n",
    "    y_train, y_test : array-like\n",
    "        Training and test labels\n",
    "    metric_name : str, optional\n",
    "        Visualizer name to specify which visualizer to use\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Visualizer object (fitted and scored)\n",
    "    \n",
    "    Fit Methods:\n",
    "    ------------\n",
    "    All classifiers use: fit(X_train, y_train) then score(X_test, y_test)\n",
    "    For pre-fitted estimators with is_fitted=True, fit() skips training.\n",
    "    \"\"\"\n",
    "    from yellowbrick.classifier import (\n",
    "        ConfusionMatrix,\n",
    "        ClassificationReport,\n",
    "        ROCAUC,\n",
    "        PrecisionRecallCurve,\n",
    "        ClassPredictionError,\n",
    "        DiscriminationThreshold,\n",
    "    )\n",
    "    \n",
    "    # Map visualizer names to classes\n",
    "    visualizer_map = {\n",
    "        \"ConfusionMatrix\": ConfusionMatrix,\n",
    "        \"ClassificationReport\": ClassificationReport,\n",
    "        \"ROCAUC\": ROCAUC,\n",
    "        \"PrecisionRecallCurve\": PrecisionRecallCurve,\n",
    "        \"ClassPredictionError\": ClassPredictionError,\n",
    "        \"DiscriminationThreshold\": DiscriminationThreshold,\n",
    "    }\n",
    "    \n",
    "    if metric_name is None:\n",
    "        # Try to infer from kwargs keys\n",
    "        for key in yb_classification_kwargs.keys():\n",
    "            if key in visualizer_map:\n",
    "                metric_name = key\n",
    "                break\n",
    "    \n",
    "    visualizer_class = visualizer_map.get(metric_name)\n",
    "    if visualizer_class is None:\n",
    "        raise ValueError(f\"Unknown visualizer: {metric_name}\")\n",
    "    \n",
    "    # Create visualizer with estimator\n",
    "    visualizer = visualizer_class(estimator, **yb_classification_kwargs)\n",
    "    \n",
    "    # Fit and score\n",
    "    # With is_fitted=True, fit() just validates, doesn't retrain\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    \n",
    "    return visualizer\n",
    "\n",
    "\n",
    "print(\"Functions defined for notebook 010 integration:\")\n",
    "print(\"  - yellowbrick_classification_kwargs(project_name, metric_name, y_train, classes, verbose)\")\n",
    "print(\"  - yellowbrick_classification_visualizers(kwargs, estimator, X_train, X_test, y_train, y_test)\")\n",
    "print()\n",
    "print(\"ALL 6 CLASSIFIER VISUALIZERS SUPPORTED:\")\n",
    "print(\"  Metrics: ConfusionMatrix, ClassificationReport, ClassPredictionError\")\n",
    "print(\"  Probability: ROCAUC, PrecisionRecallCurve\")\n",
    "print(\"  Threshold: DiscriminationThreshold (may not work with CatBoost)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "key_insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# KEY INSIGHTS FOR TFD CLASSIFICATION ANALYSIS\n",
    "# =============================================================================\n",
    "#\n",
    "# 1. VISUALIZER SELECTION STRATEGY:\n",
    "#    - Start with ConfusionMatrix to see TP/TN/FP/FN\n",
    "#    - Use ClassificationReport for per-class metrics\n",
    "#    - Use PrecisionRecallCurve (better than ROC for imbalanced data!)\n",
    "#    - Use ROCAUC for threshold-independent comparison\n",
    "#\n",
    "# 2. CATBOOST COMPATIBILITY:\n",
    "#    | Visualizer              | Works? | Notes                           |\n",
    "#    |-------------------------|--------|--------------------------------|\n",
    "#    | ConfusionMatrix         | YES    | force_model=True, is_fitted=True |\n",
    "#    | ClassificationReport    | YES    | force_model=True, is_fitted=True |\n",
    "#    | ROCAUC                  | YES    | force_model=True, is_fitted=True |\n",
    "#    | PrecisionRecallCurve    | YES    | force_model=True, is_fitted=True |\n",
    "#    | ClassPredictionError    | YES    | force_model=True, is_fitted=True |\n",
    "#    | DiscriminationThreshold | MAYBE  | Requires CV refitting          |\n",
    "#\n",
    "# 3. FRAUD DETECTION SPECIFIC:\n",
    "#    - PrecisionRecallCurve is MORE INFORMATIVE than ROCAUC for imbalanced data\n",
    "#    - ConfusionMatrix with percent=True shows relative performance\n",
    "#    - ClassificationReport shows support to understand class distribution\n",
    "#    - iso_f1_curves=True helps visualize F1 trade-offs\n",
    "#\n",
    "# 4. PERFORMANCE CONSIDERATIONS:\n",
    "#    | Visualizer              | Speed    | Requires predict_proba |\n",
    "#    |-------------------------|----------|------------------------|\n",
    "#    | ConfusionMatrix         | Fast     | No                     |\n",
    "#    | ClassificationReport    | Fast     | No                     |\n",
    "#    | ClassPredictionError    | Fast     | No                     |\n",
    "#    | ROCAUC                  | Moderate | YES                    |\n",
    "#    | PrecisionRecallCurve    | Moderate | YES                    |\n",
    "#    | DiscriminationThreshold | SLOW     | YES (+ CV)             |\n",
    "#\n",
    "# 5. USAGE EXAMPLES:\n",
    "#\n",
    "#    # With CatBoost model:\n",
    "#    from catboost import CatBoostClassifier\n",
    "#    model = CatBoostClassifier().fit(X_train, y_train)\n",
    "#\n",
    "#    # Confusion Matrix\n",
    "#    kwargs = yellowbrick_classification_kwargs(\"TFD\", \"ConfusionMatrix\")\n",
    "#    viz = yellowbrick_classification_visualizers(kwargs, model, X_train, X_test, y_train, y_test)\n",
    "#    viz.show()\n",
    "#\n",
    "#    # Precision-Recall Curve (best for fraud detection)\n",
    "#    kwargs = yellowbrick_classification_kwargs(\"TFD\", \"PrecisionRecallCurve\")\n",
    "#    viz = yellowbrick_classification_visualizers(kwargs, model, X_train, X_test, y_train, y_test)\n",
    "#    viz.show()\n",
    "#\n",
    "# =============================================================================\n",
    "print(\"Key insights documented above.\")\n",
    "print()\n",
    "print(\"YELLOWBRICK CLASSIFIER SUMMARY:\")\n",
    "print(\"  - Total Visualizers: 6\")\n",
    "print()\n",
    "print(\"  FOR FRAUD DETECTION (Classification):\")\n",
    "print(\"    Primary: ConfusionMatrix, ClassificationReport\")\n",
    "print(\"    Primary: PrecisionRecallCurve (BEST for imbalanced!)\")\n",
    "print(\"    Primary: ROCAUC\")\n",
    "print()\n",
    "print(\"  SECONDARY:\")\n",
    "print(\"    ClassPredictionError (alternative to ConfusionMatrix)\")\n",
    "print(\"    DiscriminationThreshold (may not work with CatBoost)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPLETE PARAMETER REFERENCE TABLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"+\" + \"=\" * 80 + \"+\")\n",
    "print(\"|\" + \" YELLOWBRICK CLASSIFIER VISUALIZERS - COMPLETE PARAMETER REFERENCE \".center(80) + \"|\")\n",
    "print(\"+\" + \"=\" * 80 + \"+\")\n",
    "print()\n",
    "\n",
    "# ConfusionMatrix\n",
    "print(\"1. ConfusionMatrix\")\n",
    "print(\"-\" * 40)\n",
    "print(\"  Purpose: Heatmap of true vs predicted class distributions\")\n",
    "print(\"  CatBoost: YES (force_model=True, is_fitted=True)\")\n",
    "print(\"  Parameters:\")\n",
    "print(\"    classes      : list         - Class labels (default: None)\")\n",
    "print(\"    cmap         : str          - Colormap (default: 'YlOrRd')\")\n",
    "print(\"    percent      : bool         - Show percentages (default: False)\")\n",
    "print(\"    fontsize     : int          - Font size (default: None)\")\n",
    "print(\"    sample_weight: array        - Sample weights (default: None)\")\n",
    "print(\"    is_fitted    : bool/str     - Pre-fitted estimator (default: 'auto')\")\n",
    "print(\"    force_model  : bool         - Bypass sklearn check (default: False)\")\n",
    "print()\n",
    "\n",
    "# ClassificationReport\n",
    "print(\"2. ClassificationReport\")\n",
    "print(\"-\" * 40)\n",
    "print(\"  Purpose: Precision, recall, F1 heatmap per class\")\n",
    "print(\"  CatBoost: YES (force_model=True, is_fitted=True)\")\n",
    "print(\"  Parameters:\")\n",
    "print(\"    classes      : list         - Class labels (default: None)\")\n",
    "print(\"    cmap         : str          - Colormap (default: 'YlOrRd')\")\n",
    "print(\"    support      : str/bool     - Show support: True/False/'percent'/'count' (default: None)\")\n",
    "print(\"    colorbar     : bool         - Show colorbar (default: True)\")\n",
    "print(\"    fontsize     : int          - Font size (default: None)\")\n",
    "print(\"    is_fitted    : bool/str     - Pre-fitted estimator (default: 'auto')\")\n",
    "print(\"    force_model  : bool         - Bypass sklearn check (default: False)\")\n",
    "print()\n",
    "\n",
    "# ROCAUC\n",
    "print(\"3. ROCAUC\")\n",
    "print(\"-\" * 40)\n",
    "print(\"  Purpose: ROC curve with AUC score\")\n",
    "print(\"  CatBoost: YES (force_model=True, is_fitted=True)\")\n",
    "print(\"  Requires: predict_proba() method\")\n",
    "print(\"  Parameters:\")\n",
    "print(\"    classes      : list         - Class labels (default: None)\")\n",
    "print(\"    micro        : bool         - Micro-average curve (default: True)\")\n",
    "print(\"    macro        : bool         - Macro-average curve (default: True)\")\n",
    "print(\"    per_class    : bool         - Per-class curves (default: True)\")\n",
    "print(\"    binary       : bool         - Binary mode (sets above to False) (default: False)\")\n",
    "print(\"    is_fitted    : bool/str     - Pre-fitted estimator (default: 'auto')\")\n",
    "print(\"    force_model  : bool         - Bypass sklearn check (default: False)\")\n",
    "print()\n",
    "\n",
    "# PrecisionRecallCurve\n",
    "print(\"4. PrecisionRecallCurve\")\n",
    "print(\"-\" * 40)\n",
    "print(\"  Purpose: Precision vs recall trade-off (BEST for imbalanced data!)\")\n",
    "print(\"  CatBoost: YES (force_model=True, is_fitted=True)\")\n",
    "print(\"  Requires: predict_proba() method\")\n",
    "print(\"  Parameters:\")\n",
    "print(\"    classes       : list        - Class labels (default: None)\")\n",
    "print(\"    fill_area     : bool        - Fill under curve (default: True)\")\n",
    "print(\"    fill_opacity  : float       - Fill transparency (default: 0.2)\")\n",
    "print(\"    line_opacity  : float       - Line transparency (default: 0.8)\")\n",
    "print(\"    ap_score      : bool        - Show Average Precision (default: True)\")\n",
    "print(\"    micro         : bool        - Micro-average curve (default: True)\")\n",
    "print(\"    per_class     : bool        - Per-class curves (default: False)\")\n",
    "print(\"    iso_f1_curves : bool        - Show ISO F1 curves (default: False)\")\n",
    "print(\"    iso_f1_values : tuple       - F1 values for ISO curves (default: (0.2,0.4,0.6,0.8))\")\n",
    "print(\"    is_fitted     : bool/str    - Pre-fitted estimator (default: 'auto')\")\n",
    "print(\"    force_model   : bool        - Bypass sklearn check (default: False)\")\n",
    "print()\n",
    "\n",
    "# ClassPredictionError\n",
    "print(\"5. ClassPredictionError\")\n",
    "print(\"-\" * 40)\n",
    "print(\"  Purpose: Bar chart showing prediction errors per class\")\n",
    "print(\"  CatBoost: YES (force_model=True, is_fitted=True)\")\n",
    "print(\"  Parameters:\")\n",
    "print(\"    classes      : list         - Class labels (default: None)\")\n",
    "print(\"    is_fitted    : bool/str     - Pre-fitted estimator (default: 'auto')\")\n",
    "print(\"    force_model  : bool         - Bypass sklearn check (default: False)\")\n",
    "print()\n",
    "\n",
    "# DiscriminationThreshold\n",
    "print(\"6. DiscriminationThreshold\")\n",
    "print(\"-\" * 40)\n",
    "print(\"  Purpose: Metrics across decision thresholds (binary only)\")\n",
    "print(\"  CatBoost: PROBLEMATIC (requires CV refitting)\")\n",
    "print(\"  Requires: predict_proba() method + CV\")\n",
    "print(\"  Parameters:\")\n",
    "print(\"    n_trials     : int          - Number of CV trials (default: 50)\")\n",
    "print(\"    cv           : float/CV     - Test split or CV generator (default: 0.1)\")\n",
    "print(\"    fbeta        : float        - F-beta weight (default: 1.0 = F1)\")\n",
    "print(\"    argmax       : str          - Metric to highlight (default: 'fscore')\")\n",
    "print(\"    exclude      : list         - Metrics to exclude (default: None)\")\n",
    "print(\"    quantiles    : tuple        - Uncertainty bands (default: (0.1, 0.5, 0.9))\")\n",
    "print(\"    random_state : int          - Reproducibility seed (default: None)\")\n",
    "print(\"    is_fitted    : bool/str     - Pre-fitted estimator (default: 'auto')\")\n",
    "print(\"    force_model  : bool         - Bypass sklearn check (default: False)\")\n",
    "print()\n",
    "print(\"+\" + \"=\" * 80 + \"+\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
