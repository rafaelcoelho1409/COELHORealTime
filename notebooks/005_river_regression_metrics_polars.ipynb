{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "120786ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import orjson\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, Hashable, Optional, List\n",
    "import tqdm\n",
    "from river import (\n",
    "    base,\n",
    "    compose,\n",
    "    metrics,\n",
    "    drift,\n",
    "    forest,\n",
    "    cluster,\n",
    "    preprocessing,\n",
    "    time_series,\n",
    "    linear_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b787005",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_HOST = \"localhost\"\n",
    "MINIO_ENDPOINT = f\"http://{MINIO_HOST}:9000\"\n",
    "MINIO_ACCESS_KEY = \"minioadmin\"\n",
    "MINIO_SECRET_KEY = \"minioadmin123\"\n",
    "PROJECT_NAME = \"Transaction Fraud Detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "372fdffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_STORAGE_OPTIONS = {\n",
    "    \"AWS_ENDPOINT_URL\": MINIO_ENDPOINT,\n",
    "    \"AWS_ACCESS_KEY_ID\": MINIO_ACCESS_KEY,\n",
    "    \"AWS_SECRET_ACCESS_KEY\": MINIO_SECRET_KEY,\n",
    "    \"AWS_REGION\": \"us-east-1\",\n",
    "    \"AWS_S3_ALLOW_UNSAFE_RENAME\": \"true\",\n",
    "    \"AWS_ALLOW_HTTP\": \"true\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "603f1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_PATHS = {\n",
    "    \"Transaction Fraud Detection\": \"s3://lakehouse/delta/transaction_fraud_detection\",\n",
    "    \"Estimated Time of Arrival\": \"s3://lakehouse/delta/estimated_time_of_arrival\",\n",
    "    \"E-Commerce Customer Interactions\": \"s3://lakehouse/delta/e_commerce_customer_interactions\",\n",
    "    \"Sales Forecasting\": \"s3://lakehouse/delta/sales_forecasting\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f977d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_path = DELTA_PATHS.get(\"Estimated Time of Arrival\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1bfbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_delta(\n",
    "    delta_path, \n",
    "    storage_options = DELTA_STORAGE_OPTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da25e37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SQLContext [tables:1] at 0x7f7bae29fd90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = pl.SQLContext()\n",
    "sql.register(\"data\", lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6930f434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>trip_id</th><th>driver_id</th><th>vehicle_id</th><th>timestamp</th><th>origin</th><th>destination</th><th>estimated_distance_km</th><th>weather</th><th>temperature_celsius</th><th>day_of_week</th><th>hour_of_day</th><th>driver_rating</th><th>vehicle_type</th><th>initial_estimated_travel_time_seconds</th><th>simulated_actual_travel_time_seconds</th><th>debug_traffic_factor</th><th>debug_weather_factor</th><th>debug_incident_delay_seconds</th><th>debug_driver_factor</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>i32</td><td>i32</td><td>f64</td><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>i32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;6c6429de-5d72-4a6e-9843-5e71d6…</td><td>&quot;driver_2502&quot;</td><td>&quot;vehicle_977&quot;</td><td>&quot;2025-12-29T21:45:01.446634+00:…</td><td>&quot;{&quot;lat&quot;:29.828526,&quot;lon&quot;:-95.245…</td><td>&quot;{&quot;lat&quot;:29.975473,&quot;lon&quot;:-95.045…</td><td>25.29</td><td>&quot;Clouds&quot;</td><td>19.7</td><td>0</td><td>21</td><td>3.8</td><td>&quot;Motorcycle&quot;</td><td>2501</td><td>2605</td><td>1.1</td><td>1.0</td><td>0</td><td>1.03</td></tr><tr><td>&quot;1e3da605-e251-43a9-b8ba-f1bbb4…</td><td>&quot;driver_1647&quot;</td><td>&quot;vehicle_182&quot;</td><td>&quot;2025-12-29T21:45:01.569208+00:…</td><td>&quot;{&quot;lat&quot;:30.0287,&quot;lon&quot;:-95.73198…</td><td>&quot;{&quot;lat&quot;:29.764542,&quot;lon&quot;:-95.390…</td><td>44.12</td><td>&quot;Clear&quot;</td><td>23.3</td><td>0</td><td>21</td><td>4.1</td><td>&quot;Sedan&quot;</td><td>4103</td><td>4530</td><td>1.1</td><td>1.0</td><td>0</td><td>1.02</td></tr><tr><td>&quot;86cb0ede-7f6b-4a79-997b-c52019…</td><td>&quot;driver_4068&quot;</td><td>&quot;vehicle_122&quot;</td><td>&quot;2025-12-29T21:45:02.049161+00:…</td><td>&quot;{&quot;lat&quot;:29.788907,&quot;lon&quot;:-95.570…</td><td>&quot;{&quot;lat&quot;:29.552983,&quot;lon&quot;:-95.485…</td><td>27.49</td><td>&quot;Thunderstorm&quot;</td><td>24.9</td><td>0</td><td>21</td><td>4.8</td><td>&quot;Hatchback&quot;</td><td>2652</td><td>2385</td><td>0.96</td><td>1.0</td><td>0</td><td>0.98</td></tr><tr><td>&quot;72def807-01a9-48b9-9db5-b752bd…</td><td>&quot;driver_3653&quot;</td><td>&quot;vehicle_897&quot;</td><td>&quot;2025-12-29T21:45:03.019405+00:…</td><td>&quot;{&quot;lat&quot;:29.812463,&quot;lon&quot;:-95.705…</td><td>&quot;{&quot;lat&quot;:29.922032,&quot;lon&quot;:-95.149…</td><td>55.0</td><td>&quot;Fog&quot;</td><td>22.9</td><td>0</td><td>21</td><td>4.8</td><td>&quot;Motorcycle&quot;</td><td>4867</td><td>10144</td><td>1.39</td><td>1.49</td><td>0</td><td>0.98</td></tr><tr><td>&quot;a32c3a1d-13ad-4674-a29b-429a6e…</td><td>&quot;driver_2955&quot;</td><td>&quot;vehicle_221&quot;</td><td>&quot;2025-12-29T21:45:03.755616+00:…</td><td>&quot;{&quot;lat&quot;:29.97569,&quot;lon&quot;:-95.6535…</td><td>&quot;{&quot;lat&quot;:30.091343,&quot;lon&quot;:-95.688…</td><td>13.3</td><td>&quot;Clouds&quot;</td><td>24.3</td><td>0</td><td>21</td><td>4.7</td><td>&quot;Hatchback&quot;</td><td>1307</td><td>1094</td><td>0.93</td><td>1.0</td><td>0</td><td>0.99</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;9b47160c-021e-4fa2-b5ba-edef91…</td><td>&quot;driver_3349&quot;</td><td>&quot;vehicle_468&quot;</td><td>&quot;2026-01-14T13:17:09.863182+00:…</td><td>&quot;{&quot;lat&quot;:29.718243,&quot;lon&quot;:-95.244…</td><td>&quot;{&quot;lat&quot;:29.964426,&quot;lon&quot;:-95.479…</td><td>35.58</td><td>&quot;Clear&quot;</td><td>21.7</td><td>2</td><td>13</td><td>4.0</td><td>&quot;Van&quot;</td><td>2928</td><td>3775</td><td>1.16</td><td>1.0</td><td>0</td><td>1.02</td></tr><tr><td>&quot;9fa5bff4-c591-4f12-916c-a9448a…</td><td>&quot;driver_1870&quot;</td><td>&quot;vehicle_622&quot;</td><td>&quot;2026-01-14T13:17:10.441598+00:…</td><td>&quot;{&quot;lat&quot;:29.794235,&quot;lon&quot;:-95.516…</td><td>&quot;{&quot;lat&quot;:29.591784,&quot;lon&quot;:-95.512…</td><td>22.52</td><td>&quot;Clear&quot;</td><td>20.3</td><td>2</td><td>13</td><td>4.3</td><td>&quot;Motorcycle&quot;</td><td>1917</td><td>1857</td><td>0.92</td><td>1.0</td><td>0</td><td>1.01</td></tr><tr><td>&quot;a14664b7-3e58-4e50-a7ee-b68ac1…</td><td>&quot;driver_4622&quot;</td><td>&quot;vehicle_464&quot;</td><td>&quot;2026-01-14T13:17:10.663561+00:…</td><td>&quot;{&quot;lat&quot;:29.711525,&quot;lon&quot;:-95.744…</td><td>&quot;{&quot;lat&quot;:29.5236,&quot;lon&quot;:-95.48543…</td><td>32.64</td><td>&quot;Fog&quot;</td><td>20.5</td><td>2</td><td>13</td><td>4.1</td><td>&quot;Hatchback&quot;</td><td>2845</td><td>4133</td><td>1.38</td><td>1.0</td><td>0</td><td>1.02</td></tr><tr><td>&quot;11d37598-3fe6-492b-9422-98273c…</td><td>&quot;driver_4606&quot;</td><td>&quot;vehicle_758&quot;</td><td>&quot;2026-01-14T13:17:10.882418+00:…</td><td>&quot;{&quot;lat&quot;:29.654642,&quot;lon&quot;:-95.552…</td><td>&quot;{&quot;lat&quot;:30.051371,&quot;lon&quot;:-95.686…</td><td>45.95</td><td>&quot;Clear&quot;</td><td>24.9</td><td>2</td><td>13</td><td>3.9</td><td>&quot;Hatchback&quot;</td><td>3942</td><td>5672</td><td>1.33</td><td>1.0</td><td>0</td><td>1.03</td></tr><tr><td>&quot;764bb8bb-cc13-40de-9d54-ae8934…</td><td>&quot;driver_3499&quot;</td><td>&quot;vehicle_262&quot;</td><td>&quot;2026-01-14T13:17:11.591963+00:…</td><td>&quot;{&quot;lat&quot;:29.558643,&quot;lon&quot;:-95.290…</td><td>&quot;{&quot;lat&quot;:29.698536,&quot;lon&quot;:-95.180…</td><td>18.82</td><td>&quot;Clear&quot;</td><td>28.5</td><td>2</td><td>13</td><td>4.3</td><td>&quot;Van&quot;</td><td>1641</td><td>1994</td><td>1.19</td><td>1.0</td><td>0</td><td>1.01</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 19)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ trip_id   ┆ driver_id ┆ vehicle_i ┆ timestamp ┆ … ┆ debug_tra ┆ debug_wea ┆ debug_inc ┆ debug_dr │\n",
       "│ ---       ┆ ---       ┆ d         ┆ ---       ┆   ┆ ffic_fact ┆ ther_fact ┆ ident_del ┆ iver_fac │\n",
       "│ str       ┆ str       ┆ ---       ┆ str       ┆   ┆ or        ┆ or        ┆ ay_second ┆ tor      │\n",
       "│           ┆           ┆ str       ┆           ┆   ┆ ---       ┆ ---       ┆ s         ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ i32       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 6c6429de- ┆ driver_25 ┆ vehicle_9 ┆ 2025-12-2 ┆ … ┆ 1.1       ┆ 1.0       ┆ 0         ┆ 1.03     │\n",
       "│ 5d72-4a6e ┆ 02        ┆ 77        ┆ 9T21:45:0 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -9843-5e7 ┆           ┆           ┆ 1.446634+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1d6…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1e3da605- ┆ driver_16 ┆ vehicle_1 ┆ 2025-12-2 ┆ … ┆ 1.1       ┆ 1.0       ┆ 0         ┆ 1.02     │\n",
       "│ e251-43a9 ┆ 47        ┆ 82        ┆ 9T21:45:0 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -b8ba-f1b ┆           ┆           ┆ 1.569208+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ bb4…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 86cb0ede- ┆ driver_40 ┆ vehicle_1 ┆ 2025-12-2 ┆ … ┆ 0.96      ┆ 1.0       ┆ 0         ┆ 0.98     │\n",
       "│ 7f6b-4a79 ┆ 68        ┆ 22        ┆ 9T21:45:0 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -997b-c52 ┆           ┆           ┆ 2.049161+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 019…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 72def807- ┆ driver_36 ┆ vehicle_8 ┆ 2025-12-2 ┆ … ┆ 1.39      ┆ 1.49      ┆ 0         ┆ 0.98     │\n",
       "│ 01a9-48b9 ┆ 53        ┆ 97        ┆ 9T21:45:0 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -9db5-b75 ┆           ┆           ┆ 3.019405+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2bd…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ a32c3a1d- ┆ driver_29 ┆ vehicle_2 ┆ 2025-12-2 ┆ … ┆ 0.93      ┆ 1.0       ┆ 0         ┆ 0.99     │\n",
       "│ 13ad-4674 ┆ 55        ┆ 21        ┆ 9T21:45:0 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -a29b-429 ┆           ┆           ┆ 3.755616+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ a6e…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 9b47160c- ┆ driver_33 ┆ vehicle_4 ┆ 2026-01-1 ┆ … ┆ 1.16      ┆ 1.0       ┆ 0         ┆ 1.02     │\n",
       "│ 021e-4fa2 ┆ 49        ┆ 68        ┆ 4T13:17:0 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -b5ba-ede ┆           ┆           ┆ 9.863182+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ f91…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 9fa5bff4- ┆ driver_18 ┆ vehicle_6 ┆ 2026-01-1 ┆ … ┆ 0.92      ┆ 1.0       ┆ 0         ┆ 1.01     │\n",
       "│ c591-4f12 ┆ 70        ┆ 22        ┆ 4T13:17:1 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -916c-a94 ┆           ┆           ┆ 0.441598+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 48a…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ a14664b7- ┆ driver_46 ┆ vehicle_4 ┆ 2026-01-1 ┆ … ┆ 1.38      ┆ 1.0       ┆ 0         ┆ 1.02     │\n",
       "│ 3e58-4e50 ┆ 22        ┆ 64        ┆ 4T13:17:1 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -a7ee-b68 ┆           ┆           ┆ 0.663561+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ac1…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 11d37598- ┆ driver_46 ┆ vehicle_7 ┆ 2026-01-1 ┆ … ┆ 1.33      ┆ 1.0       ┆ 0         ┆ 1.03     │\n",
       "│ 3fe6-492b ┆ 06        ┆ 58        ┆ 4T13:17:1 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -9422-982 ┆           ┆           ┆ 0.882418+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 73c…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 764bb8bb- ┆ driver_34 ┆ vehicle_2 ┆ 2026-01-1 ┆ … ┆ 1.19      ┆ 1.0       ┆ 0         ┆ 1.01     │\n",
       "│ cc13-40de ┆ 99        ┆ 62        ┆ 4T13:17:1 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ -9d54-ae8 ┆           ┆           ┆ 1.591963+ ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 934…      ┆           ┆           ┆ 00:…      ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sql.execute(\"SELECT * FROM data LIMIT 1000\").collect()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2210797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'trip_id': '6c6429de-5d72-4a6e-9843-5e71d6349cbe',\n",
       "  'driver_id': 'driver_2502',\n",
       "  'vehicle_id': 'vehicle_977',\n",
       "  'timestamp': '2025-12-29T21:45:01.446634+00:00',\n",
       "  'origin': '{\"lat\":29.828526,\"lon\":-95.245478}',\n",
       "  'destination': '{\"lat\":29.975473,\"lon\":-95.045179}',\n",
       "  'estimated_distance_km': 25.29,\n",
       "  'weather': 'Clouds',\n",
       "  'temperature_celsius': 19.7,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 3.8,\n",
       "  'vehicle_type': 'Motorcycle',\n",
       "  'initial_estimated_travel_time_seconds': 2501,\n",
       "  'simulated_actual_travel_time_seconds': 2605,\n",
       "  'debug_traffic_factor': 1.1,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 1.03},\n",
       " {'trip_id': '1e3da605-e251-43a9-b8ba-f1bbb4a2fcdf',\n",
       "  'driver_id': 'driver_1647',\n",
       "  'vehicle_id': 'vehicle_182',\n",
       "  'timestamp': '2025-12-29T21:45:01.569208+00:00',\n",
       "  'origin': '{\"lat\":30.0287,\"lon\":-95.731989}',\n",
       "  'destination': '{\"lat\":29.764542,\"lon\":-95.390439}',\n",
       "  'estimated_distance_km': 44.12,\n",
       "  'weather': 'Clear',\n",
       "  'temperature_celsius': 23.3,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.1,\n",
       "  'vehicle_type': 'Sedan',\n",
       "  'initial_estimated_travel_time_seconds': 4103,\n",
       "  'simulated_actual_travel_time_seconds': 4530,\n",
       "  'debug_traffic_factor': 1.1,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 1.02},\n",
       " {'trip_id': '86cb0ede-7f6b-4a79-997b-c520197cf43a',\n",
       "  'driver_id': 'driver_4068',\n",
       "  'vehicle_id': 'vehicle_122',\n",
       "  'timestamp': '2025-12-29T21:45:02.049161+00:00',\n",
       "  'origin': '{\"lat\":29.788907,\"lon\":-95.570753}',\n",
       "  'destination': '{\"lat\":29.552983,\"lon\":-95.485716}',\n",
       "  'estimated_distance_km': 27.49,\n",
       "  'weather': 'Thunderstorm',\n",
       "  'temperature_celsius': 24.9,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.8,\n",
       "  'vehicle_type': 'Hatchback',\n",
       "  'initial_estimated_travel_time_seconds': 2652,\n",
       "  'simulated_actual_travel_time_seconds': 2385,\n",
       "  'debug_traffic_factor': 0.96,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 0.98},\n",
       " {'trip_id': '72def807-01a9-48b9-9db5-b752bd3a3df9',\n",
       "  'driver_id': 'driver_3653',\n",
       "  'vehicle_id': 'vehicle_897',\n",
       "  'timestamp': '2025-12-29T21:45:03.019405+00:00',\n",
       "  'origin': '{\"lat\":29.812463,\"lon\":-95.705464}',\n",
       "  'destination': '{\"lat\":29.922032,\"lon\":-95.149283}',\n",
       "  'estimated_distance_km': 55.0,\n",
       "  'weather': 'Fog',\n",
       "  'temperature_celsius': 22.9,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.8,\n",
       "  'vehicle_type': 'Motorcycle',\n",
       "  'initial_estimated_travel_time_seconds': 4867,\n",
       "  'simulated_actual_travel_time_seconds': 10144,\n",
       "  'debug_traffic_factor': 1.39,\n",
       "  'debug_weather_factor': 1.49,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 0.98},\n",
       " {'trip_id': 'a32c3a1d-13ad-4674-a29b-429a6ee606d1',\n",
       "  'driver_id': 'driver_2955',\n",
       "  'vehicle_id': 'vehicle_221',\n",
       "  'timestamp': '2025-12-29T21:45:03.755616+00:00',\n",
       "  'origin': '{\"lat\":29.97569,\"lon\":-95.653587}',\n",
       "  'destination': '{\"lat\":30.091343,\"lon\":-95.688743}',\n",
       "  'estimated_distance_km': 13.3,\n",
       "  'weather': 'Clouds',\n",
       "  'temperature_celsius': 24.3,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.7,\n",
       "  'vehicle_type': 'Hatchback',\n",
       "  'initial_estimated_travel_time_seconds': 1307,\n",
       "  'simulated_actual_travel_time_seconds': 1094,\n",
       "  'debug_traffic_factor': 0.93,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 0.99},\n",
       " {'trip_id': 'de8b68cf-18bd-402f-9fcb-6ddd5970b017',\n",
       "  'driver_id': 'driver_4034',\n",
       "  'vehicle_id': 'vehicle_924',\n",
       "  'timestamp': '2025-12-29T21:45:04.156907+00:00',\n",
       "  'origin': '{\"lat\":29.930259,\"lon\":-95.18012}',\n",
       "  'destination': '{\"lat\":29.684991,\"lon\":-95.336035}',\n",
       "  'estimated_distance_km': 31.15,\n",
       "  'weather': 'Clouds',\n",
       "  'temperature_celsius': 19.3,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.4,\n",
       "  'vehicle_type': 'SUV',\n",
       "  'initial_estimated_travel_time_seconds': 2664,\n",
       "  'simulated_actual_travel_time_seconds': 2706,\n",
       "  'debug_traffic_factor': 0.96,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 1.0},\n",
       " {'trip_id': '263b9dea-e41e-480b-ad0e-459ac010f1b9',\n",
       "  'driver_id': 'driver_2855',\n",
       "  'vehicle_id': 'vehicle_271',\n",
       "  'timestamp': '2025-12-29T21:45:04.558225+00:00',\n",
       "  'origin': '{\"lat\":29.580499,\"lon\":-95.624451}',\n",
       "  'destination': '{\"lat\":29.644425,\"lon\":-95.361102}',\n",
       "  'estimated_distance_km': 26.43,\n",
       "  'weather': 'Clear',\n",
       "  'temperature_celsius': 23.6,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.1,\n",
       "  'vehicle_type': 'Hatchback',\n",
       "  'initial_estimated_travel_time_seconds': 2324,\n",
       "  'simulated_actual_travel_time_seconds': 2890,\n",
       "  'debug_traffic_factor': 1.18,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 1.02},\n",
       " {'trip_id': '537f4dfa-9ce7-44bd-9a82-57b52b736cbe',\n",
       "  'driver_id': 'driver_4436',\n",
       "  'vehicle_id': 'vehicle_891',\n",
       "  'timestamp': '2025-12-29T21:45:04.861380+00:00',\n",
       "  'origin': '{\"lat\":29.744104,\"lon\":-95.113712}',\n",
       "  'destination': '{\"lat\":29.878764,\"lon\":-95.795386}',\n",
       "  'estimated_distance_km': 67.45,\n",
       "  'weather': 'Clouds',\n",
       "  'temperature_celsius': 27.4,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.6,\n",
       "  'vehicle_type': 'Sedan',\n",
       "  'initial_estimated_travel_time_seconds': 6085,\n",
       "  'simulated_actual_travel_time_seconds': 7053,\n",
       "  'debug_traffic_factor': 1.16,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 0.99},\n",
       " {'trip_id': '015c85a2-2713-448d-a654-2c62a529e4d2',\n",
       "  'driver_id': 'driver_4168',\n",
       "  'vehicle_id': 'vehicle_117',\n",
       "  'timestamp': '2025-12-29T21:45:05.625447+00:00',\n",
       "  'origin': '{\"lat\":29.664047,\"lon\":-95.429522}',\n",
       "  'destination': '{\"lat\":29.80636,\"lon\":-95.095114}',\n",
       "  'estimated_distance_km': 35.96,\n",
       "  'weather': 'Clear',\n",
       "  'temperature_celsius': 28.5,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 3.9,\n",
       "  'vehicle_type': 'SUV',\n",
       "  'initial_estimated_travel_time_seconds': 3136,\n",
       "  'simulated_actual_travel_time_seconds': 3171,\n",
       "  'debug_traffic_factor': 0.95,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 1.03},\n",
       " {'trip_id': '59171b7b-e2f3-47d5-bb5e-94aaebb5ab29',\n",
       "  'driver_id': 'driver_2286',\n",
       "  'vehicle_id': 'vehicle_247',\n",
       "  'timestamp': '2025-12-29T21:45:06.074810+00:00',\n",
       "  'origin': '{\"lat\":29.8238,\"lon\":-95.651224}',\n",
       "  'destination': '{\"lat\":29.724498,\"lon\":-95.125046}',\n",
       "  'estimated_distance_km': 51.97,\n",
       "  'weather': 'Heavy Rain',\n",
       "  'temperature_celsius': 24.8,\n",
       "  'day_of_week': 0,\n",
       "  'hour_of_day': 21,\n",
       "  'driver_rating': 4.6,\n",
       "  'vehicle_type': 'Hatchback',\n",
       "  'initial_estimated_travel_time_seconds': 5021,\n",
       "  'simulated_actual_travel_time_seconds': 4267,\n",
       "  'debug_traffic_factor': 0.93,\n",
       "  'debug_weather_factor': 1.0,\n",
       "  'debug_incident_delay_seconds': 0,\n",
       "  'debug_driver_factor': 0.99}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = result.to_dicts()\n",
    "samples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bd615cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'day_of_week': 0,\n",
      " 'debug_driver_factor': 1.03,\n",
      " 'debug_incident_delay_seconds': 0,\n",
      " 'debug_traffic_factor': 1.1,\n",
      " 'debug_weather_factor': 1.0,\n",
      " 'destination': '{\"lat\":29.975473,\"lon\":-95.045179}',\n",
      " 'driver_id': 'driver_2502',\n",
      " 'driver_rating': 3.8,\n",
      " 'estimated_distance_km': 25.29,\n",
      " 'hour_of_day': 21,\n",
      " 'initial_estimated_travel_time_seconds': 2501,\n",
      " 'origin': '{\"lat\":29.828526,\"lon\":-95.245478}',\n",
      " 'simulated_actual_travel_time_seconds': 2605,\n",
      " 'temperature_celsius': 19.7,\n",
      " 'timestamp': '2025-12-29T21:45:01.446634+00:00',\n",
      " 'trip_id': '6c6429de-5d72-4a6e-9843-5e71d6349cbe',\n",
      " 'vehicle_id': 'vehicle_977',\n",
      " 'vehicle_type': 'Motorcycle',\n",
      " 'weather': 'Clouds'}\n"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    pprint(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84f047bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOrdinalEncoder:\n",
    "    \"\"\"\n",
    "    An incremental ordinal encoder that is picklable and processes dictionaries.\n",
    "    Assigns a unique integer ID to each unique category encountered for each feature.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Dictionary to store mappings for each feature.\n",
    "        # Keys are feature names (from input dictionary), values are dictionaries\n",
    "        # mapping category value to integer ID for that feature.\n",
    "        self._feature_mappings: Dict[Hashable, Dict[Any, int]] = {}\n",
    "        # Dictionary to store the next available integer ID for each feature.\n",
    "        # Keys are feature names, values are integers.\n",
    "        self._feature_next_ids: Dict[Hashable, int] = {}\n",
    "    def learn_one(self, x: Dict[Hashable, Any]):\n",
    "        \"\"\"\n",
    "        Learns categories from a single sample dictionary.\n",
    "        Iterates through the dictionary's items and learns each category value\n",
    "        for its corresponding feature.\n",
    "        Args:\n",
    "            x: A dictionary representing a single sample.\n",
    "               Keys are feature names, values are feature values.\n",
    "               Assumes categorical features are present in this dictionary.\n",
    "        \"\"\"\n",
    "        for feature_name, category_value in x.items():\n",
    "            # Ensure the category value is hashable (dictionaries/lists are not)\n",
    "            # You might need more sophisticated type checking or handling\n",
    "            # if your input dictionaries contain complex unhashable types\n",
    "            if not isinstance(category_value, Hashable):\n",
    "                 print(f\"Warning: Skipping unhashable value for feature '{feature_name}': {category_value}\")\n",
    "                 continue # Skip this feature for learning\n",
    "            # If this is the first time we see this feature, initialize its mapping and counter\n",
    "            if feature_name not in self._feature_mappings:\n",
    "                self._feature_mappings[feature_name] = {}\n",
    "                self._feature_next_ids[feature_name] = 0\n",
    "            # Get the mapping and counter for this specific feature\n",
    "            feature_map = self._feature_mappings[feature_name]\n",
    "            feature_next_id = self._feature_next_ids[feature_name]\n",
    "            # Check if the category value is already in the mapping for this feature\n",
    "            if category_value not in feature_map:\n",
    "                # If it's a new category for this feature, assign the next available ID\n",
    "                feature_map[category_value] = feature_next_id\n",
    "                # Increment the counter for the next new category for this feature\n",
    "                self._feature_next_ids[feature_name] += 1\n",
    "    def transform_one(self, x: Dict[Hashable, Any]) -> Dict[Hashable, int]:\n",
    "        \"\"\"\n",
    "        Transforms categorical features in a single sample dictionary into integer IDs.\n",
    "        Args:\n",
    "            x: A dictionary representing a single sample.\n",
    "               Keys are feature names, values are feature values.\n",
    "        Returns:\n",
    "            A new dictionary containing the transformed integer IDs for the\n",
    "            categorical features that the encoder has seen. Features not\n",
    "            seen by the encoder are excluded from the output dictionary.\n",
    "        Raises:\n",
    "            KeyError: If a feature is seen but a specific category value\n",
    "                      within that feature has not been seen during learning.\n",
    "                      You might want to add logic here to handle unseen categories\n",
    "                      (e.g., return a default value like -1 or NaN for that feature).\n",
    "        \"\"\"\n",
    "        transformed_sample: Dict[Hashable, int] = {}\n",
    "        for feature_name, category_value in x.items():\n",
    "            # Only attempt to transform features that the encoder has seen\n",
    "            if feature_name in self._feature_mappings:\n",
    "                feature_map = self._feature_mappings[feature_name]\n",
    "                # Check if the category value for this feature has been seen\n",
    "                if category_value in feature_map:\n",
    "                    # Transform the category value using the feature's mapping\n",
    "                    transformed_sample[feature_name] = feature_map[category_value]\n",
    "                else:\n",
    "                    # Handle unseen category values for a known feature\n",
    "                    # By default, this will raise a KeyError as per the docstring.\n",
    "                    # Example: return a placeholder value instead of raising error:\n",
    "                    # transformed_sample[feature_name] = -1 # Or some other indicator\n",
    "                    # print(f\"Warning: Unseen category '{category_value}' for feature '{feature_name}' during transform.\")\n",
    "                    # Or raise the error explicitly:\n",
    "                    raise KeyError(f\"Unseen category '{category_value}' for feature '{feature_name}' during transform.\")\n",
    "            # Features not in self._feature_mappings are ignored in the output.\n",
    "            # If you need to include them (e.g., original numerical features),\n",
    "            # you would copy them over here. This encoder only outputs encoded features.\n",
    "        return transformed_sample\n",
    "    def get_feature_mappings(self) -> Dict[Hashable, Dict[Any, int]]:\n",
    "        \"\"\"Returns the current mappings for all features.\"\"\"\n",
    "        return self._feature_mappings\n",
    "    def get_feature_next_ids(self) -> Dict[Hashable, int]:\n",
    "        \"\"\"Returns the next available IDs for all features.\"\"\"\n",
    "        return self._feature_next_ids\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"String representation of the encoder.\"\"\"\n",
    "        num_features = len(self._feature_mappings)\n",
    "        feature_details = \", \".join([f\"{name}: {len(mapping)} categories\" for name, mapping in self._feature_mappings.items()])\n",
    "        return f\"CustomPicklableOrdinalEncoder(features={num_features} [{feature_details}])\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e15d6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictImputer(base.Transformer):\n",
    "    \"\"\"\n",
    "    Imputes missing values (None or missing keys) for specified features in a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    on\n",
    "        List of feature names to impute.\n",
    "    fill_value\n",
    "        The value to use for imputation.\n",
    "    \"\"\"\n",
    "    def __init__(self, on: list, fill_value):\n",
    "        self.on = on\n",
    "        self.fill_value = fill_value\n",
    "    def transform_one(self, x: dict):\n",
    "        x_transformed = x.copy()\n",
    "        for feature in self.on:\n",
    "            if x_transformed.get(feature) is None:\n",
    "                x_transformed[feature] = self.fill_value\n",
    "        return x_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca72d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_device_info(x):\n",
    "    x_ = x['device_info']\n",
    "    # Parse JSON string if coming from Delta Lake\n",
    "    if isinstance(x_, str):\n",
    "        x_ = orjson.loads(x_)\n",
    "    return {\n",
    "        'os': x_['os'],\n",
    "        'browser': x_['browser'],\n",
    "    }\n",
    "\n",
    "def extract_timestamp_info(x):\n",
    "    x_ = dt.datetime.strptime(\n",
    "        x['timestamp'],\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    return {\n",
    "        'year': x_.year,\n",
    "        'month': x_.month,\n",
    "        'day': x_.day,\n",
    "        'hour': x_.hour,\n",
    "        'minute': x_.minute,\n",
    "        'second': x_.second\n",
    "    }\n",
    "\n",
    "def extract_coordinates(x):\n",
    "    x_ = x['location']\n",
    "    # Parse JSON string if coming from Delta Lake\n",
    "    if isinstance(x_, str):\n",
    "        x_ = orjson.loads(x_)\n",
    "    return {\n",
    "        'lat': x_['lat'],\n",
    "        'lon': x_['lon'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0c397a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(x, encoders, project_name):\n",
    "    \"\"\"Process a single sample for River incremental learning.\"\"\"\n",
    "    if project_name == \"Transaction Fraud Detection\":\n",
    "        pipe1 = compose.Select(\n",
    "            \"amount\",\n",
    "            \"account_age_days\",\n",
    "            \"cvv_provided\",\n",
    "            \"billing_address_match\"\n",
    "        )\n",
    "        pipe1.learn_one(x)\n",
    "        x1 = pipe1.transform_one(x)\n",
    "        pipe2 = compose.Select(\n",
    "            \"currency\",\n",
    "            \"merchant_id\",\n",
    "            \"payment_method\",\n",
    "            \"product_category\",\n",
    "            \"transaction_type\",\n",
    "        )\n",
    "        pipe2.learn_one(x)\n",
    "        x_pipe_2 = pipe2.transform_one(x)\n",
    "        pipe3a = compose.Select(\"device_info\")\n",
    "        pipe3a.learn_one(x)\n",
    "        x_pipe_3 = pipe3a.transform_one(x)\n",
    "        pipe3b = compose.FuncTransformer(extract_device_info)\n",
    "        pipe3b.learn_one(x_pipe_3)\n",
    "        x_pipe_3 = pipe3b.transform_one(x_pipe_3)\n",
    "        pipe4a = compose.Select(\"timestamp\")\n",
    "        pipe4a.learn_one(x)\n",
    "        x_pipe_4 = pipe4a.transform_one(x)\n",
    "        pipe4b = compose.FuncTransformer(extract_timestamp_info)\n",
    "        pipe4b.learn_one(x_pipe_4)\n",
    "        x_pipe_4 = pipe4b.transform_one(x_pipe_4)\n",
    "        x_to_encode = x_pipe_2 | x_pipe_3 | x_pipe_4\n",
    "        encoders[\"ordinal_encoder\"].learn_one(x_to_encode)\n",
    "        x2 = encoders[\"ordinal_encoder\"].transform_one(x_to_encode)\n",
    "        return x1 | x2, {\"ordinal_encoder\": encoders[\"ordinal_encoder\"]}\n",
    "    elif project_name == \"Estimated Time of Arrival\":\n",
    "        pipe1 = compose.Select(\n",
    "            'estimated_distance_km',\n",
    "            'temperature_celsius',\n",
    "            'hour_of_day',\n",
    "            'driver_rating',\n",
    "            'initial_estimated_travel_time_seconds',\n",
    "            'debug_traffic_factor',\n",
    "            'debug_weather_factor',\n",
    "            'debug_incident_delay_seconds',\n",
    "            'debug_driver_factor'\n",
    "        )\n",
    "        pipe1.learn_one(x)\n",
    "        x1 = pipe1.transform_one(x)\n",
    "        pipe2 = compose.Select(\n",
    "            'driver_id',\n",
    "            'vehicle_id',\n",
    "            'weather',\n",
    "            'vehicle_type'\n",
    "        )\n",
    "        pipe2.learn_one(x)\n",
    "        x_pipe_2 = pipe2.transform_one(x)\n",
    "        pipe3a = compose.Select(\n",
    "            \"timestamp\",\n",
    "        )\n",
    "        pipe3a.learn_one(x)\n",
    "        x_pipe_3 = pipe3a.transform_one(x)\n",
    "        pipe3b = compose.FuncTransformer(\n",
    "            extract_timestamp_info,\n",
    "        )\n",
    "        pipe3b.learn_one(x_pipe_3)\n",
    "        x_pipe_3 = pipe3b.transform_one(x_pipe_3)\n",
    "        x_to_encode = x_pipe_2 | x_pipe_3\n",
    "        encoders[\"ordinal_encoder\"].learn_one(x_to_encode)\n",
    "        x2 = encoders[\"ordinal_encoder\"].transform_one(x_to_encode)\n",
    "        return x1 | x2, {\n",
    "            \"ordinal_encoder\": encoders[\"ordinal_encoder\"]\n",
    "        }\n",
    "    elif project_name == \"E-Commerce Customer Interactions\":\n",
    "        pipe1 = compose.Select(\n",
    "            'price',\n",
    "            'quantity',\n",
    "            'session_event_sequence',\n",
    "            'time_on_page_seconds'\n",
    "        )\n",
    "        pipe1.learn_one(x)\n",
    "        x1 = pipe1.transform_one(x)\n",
    "        pipe2 = compose.Select(\n",
    "            'event_type',\n",
    "            'product_category',\n",
    "            'product_id',\n",
    "            'referrer_url',\n",
    "        )\n",
    "        pipe2.learn_one(x)\n",
    "        x_pipe_2 = pipe2.transform_one(x)\n",
    "        pipe3a = compose.Select(\n",
    "            \"device_info\"\n",
    "        )\n",
    "        pipe3a.learn_one(x)\n",
    "        x_pipe_3 = pipe3a.transform_one(x)\n",
    "        pipe3b = compose.FuncTransformer(\n",
    "            extract_device_info,\n",
    "        )\n",
    "        pipe3b.learn_one(x_pipe_3)\n",
    "        x_pipe_3 = pipe3b.transform_one(x_pipe_3)\n",
    "        pipe4a = compose.Select(\n",
    "            \"timestamp\",\n",
    "        )\n",
    "        pipe4a.learn_one(x)\n",
    "        x_pipe_4 = pipe4a.transform_one(x)\n",
    "        pipe4b = compose.FuncTransformer(\n",
    "            extract_timestamp_info,\n",
    "        )\n",
    "        pipe4b.learn_one(x_pipe_4)\n",
    "        x_pipe_4 = pipe4b.transform_one(x_pipe_4)\n",
    "        pipe5a = compose.Select(\n",
    "            \"location\",\n",
    "        )\n",
    "        pipe5a.learn_one(x)\n",
    "        x_pipe_5 = pipe5a.transform_one(x)\n",
    "        pipe5b = compose.FuncTransformer(\n",
    "            extract_coordinates,\n",
    "        )\n",
    "        pipe5b.learn_one(x_pipe_5)\n",
    "        x_pipe_5 = pipe5b.transform_one(x_pipe_5)\n",
    "        x_to_prep = x1 | x_pipe_2 | x_pipe_3 | x_pipe_4 | x_pipe_5\n",
    "        x_to_prep = DictImputer(\n",
    "            fill_value = False, \n",
    "            on = list(x_to_prep.keys())).transform_one(\n",
    "                x_to_prep)\n",
    "        numerical_features = [\n",
    "            'price',\n",
    "            'session_event_sequence',\n",
    "            'time_on_page_seconds',\n",
    "            'quantity'\n",
    "        ]\n",
    "        categorical_features = [\n",
    "            'event_type',\n",
    "            'product_category',\n",
    "            'product_id',\n",
    "            'referrer_url',\n",
    "            'os',\n",
    "            'browser',\n",
    "            'year',\n",
    "            'month',\n",
    "            'day',\n",
    "            'hour',\n",
    "            'minute',\n",
    "            'second'\n",
    "        ]\n",
    "        num_pipe = compose.Select(*numerical_features)\n",
    "        num_pipe.learn_one(x_to_prep)\n",
    "        x_num = num_pipe.transform_one(x_to_prep)\n",
    "        cat_pipe = compose.Select(*categorical_features)\n",
    "        cat_pipe.learn_one(x_to_prep)\n",
    "        x_cat = cat_pipe.transform_one(x_to_prep)\n",
    "        encoders[\"standard_scaler\"].learn_one(x_num)\n",
    "        x_scaled = encoders[\"standard_scaler\"].transform_one(x_num)\n",
    "        encoders[\"feature_hasher\"].learn_one(x_cat)\n",
    "        x_hashed = encoders[\"feature_hasher\"].transform_one(x_cat)\n",
    "        return x_scaled | x_hashed, {\n",
    "            \"standard_scaler\": encoders[\"standard_scaler\"], \n",
    "            \"feature_hasher\": encoders[\"feature_hasher\"]\n",
    "        }\n",
    "    elif project_name == \"Sales Forecasting\":\n",
    "        pipe1 = compose.Select(\n",
    "            'concept_drift_stage',\n",
    "            'day_of_week',\n",
    "            'is_holiday',\n",
    "            'is_promotion_active',\n",
    "            'month',\n",
    "            #'total_sales_amount',\n",
    "            'unit_price'\n",
    "        )\n",
    "        pipe1.learn_one(x)\n",
    "        x1 = pipe1.transform_one(x)\n",
    "        pipe2a = compose.Select(\n",
    "            \"timestamp\",\n",
    "        )\n",
    "        pipe2a.learn_one(x)\n",
    "        x_pipe_2 = pipe2a.transform_one(x)\n",
    "        pipe2b = compose.FuncTransformer(\n",
    "            extract_timestamp_info,\n",
    "        )\n",
    "        pipe2b.learn_one(x_pipe_2)\n",
    "        x2 = pipe2b.transform_one(x_pipe_2)\n",
    "        pipe3a = compose.Select(\n",
    "            'product_id',\n",
    "            'promotion_id',\n",
    "            'store_id'\n",
    "        )\n",
    "        pipe3a.learn_one(x)\n",
    "        x3 = pipe3a.transform_one(x)\n",
    "        x_to_process = x1 | x2 | x3\n",
    "        numerical_features = [\n",
    "            'unit_price',\n",
    "            #'total_sales_amount',\n",
    "        ]\n",
    "        categorical_features = [\n",
    "            'is_promotion_active',\n",
    "            'is_holiday',\n",
    "            'day_of_week',\n",
    "            'concept_drift_stage',\n",
    "            'year',\n",
    "            'month',\n",
    "            'day',\n",
    "            #'hour',\n",
    "            #'minute',\n",
    "            #'second',\n",
    "            'product_id',\n",
    "            'promotion_id',\n",
    "            'store_id',\n",
    "        ]\n",
    "        pipe_num = compose.Select(*numerical_features)\n",
    "        pipe_num.learn_one(x_to_process)\n",
    "        x_num = pipe_num.transform_one(x_to_process)\n",
    "        pipe_cat = compose.Select(*categorical_features)\n",
    "        pipe_cat.learn_one(x_to_process)\n",
    "        x_cat = pipe_cat.transform_one(x_to_process)\n",
    "        encoders[\"standard_scaler\"].learn_one(x_num)\n",
    "        x_num = encoders[\"standard_scaler\"].transform_one(x_num)\n",
    "        encoders[\"one_hot_encoder\"].learn_one(x_cat)\n",
    "        x_cat = encoders[\"one_hot_encoder\"].transform_one(x_cat)\n",
    "        return x_num | x_cat, {\n",
    "            \"one_hot_encoder\": encoders[\"one_hot_encoder\"],\n",
    "            \"standard_scaler\": encoders[\"standard_scaler\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a55a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_default_model(project_name):\n",
    "    \"\"\"Create default model based on project type.\n",
    "\n",
    "    Models are configured based on River ML documentation and best practices.\n",
    "    All parameters are documented with their River ML defaults and rationale.\n",
    "\n",
    "    See: https://riverml.xyz/latest/\n",
    "    \"\"\"\n",
    "    if project_name == \"Transaction Fraud Detection\":\n",
    "        # =================================================================\n",
    "        # ARFClassifier - Adaptive Random Forest Classifier\n",
    "        # For fraud detection with concept drift handling\n",
    "        # =================================================================\n",
    "        # OLD CONFIGURATION:\n",
    "        # return forest.ARFClassifier(\n",
    "        #     n_models = 10,\n",
    "        #     drift_detector = drift.ADWIN(),\n",
    "        #     warning_detector = drift.ADWIN(),\n",
    "        #     metric = metrics.ROCAUC(),\n",
    "        #     max_features = \"sqrt\",\n",
    "        #     lambda_value = 6,\n",
    "        #     seed = 42\n",
    "        # )\n",
    "\n",
    "        # CONFIGURATION based on River ML documentation:\n",
    "        # Reference: https://riverml.xyz/latest/api/forest/ARFClassifier/\n",
    "        # Reference: https://riverml.xyz/latest/examples/imbalanced-learning/\n",
    "        #\n",
    "        # - n_models=10: Default number of trees in ensemble\n",
    "        # - max_features=\"sqrt\": Default, sqrt of features per split\n",
    "        # - lambda_value=6: Default Leveraging Bagging parameter\n",
    "        # - metric=ROCAUC(): RECOMMENDED by River for imbalanced fraud detection\n",
    "        #   (River's imbalanced-learning guide uses ROCAUC for fraud detection)\n",
    "        # - disable_weighted_vote=False: Enable weighted voting for better accuracy\n",
    "        # - drift_detector ADWIN(delta=0.002): Default sensitivity (0.002)\n",
    "        # - warning_detector ADWIN(delta=0.01): Default warning sensitivity\n",
    "        # - grace_period=50: Default observations between split attempts\n",
    "        # - max_depth=None: Default, unlimited tree depth\n",
    "        # - split_criterion=\"info_gain\": Default, information gain criterion\n",
    "        # - delta=0.01: Default allowed error in split decision\n",
    "        # - tau=0.05: Default tie-breaking threshold\n",
    "        # - leaf_prediction=\"nba\": Default, Naive Bayes Adaptive\n",
    "        # - nb_threshold=0: Default, enable NB immediately\n",
    "        # - binary_split=False: Default, allow multi-way splits\n",
    "        # - min_branch_fraction=0.01: Default minimum data per branch\n",
    "        # - max_share_to_split=0.99: Default majority class proportion\n",
    "        # - max_size=100.0: Default max memory in MiB\n",
    "        # - memory_estimate_period=2000000: Default instances between memory checks\n",
    "        # - merit_preprune=True: Default merit-based pre-pruning\n",
    "        return forest.ARFClassifier(\n",
    "            n_models = 10,\n",
    "            max_features = \"sqrt\",\n",
    "            lambda_value = 6,\n",
    "            metric = metrics.ROCAUC(),\n",
    "            disable_weighted_vote = False,\n",
    "            drift_detector = drift.ADWIN(delta = 0.002),\n",
    "            warning_detector = drift.ADWIN(delta = 0.01),\n",
    "            grace_period = 50,\n",
    "            max_depth = None,\n",
    "            split_criterion = \"info_gain\",\n",
    "            delta = 0.01,\n",
    "            tau = 0.05,\n",
    "            leaf_prediction = \"nba\",\n",
    "            nb_threshold = 0,\n",
    "            nominal_attributes = None,\n",
    "            binary_split = False,\n",
    "            min_branch_fraction = 0.01,\n",
    "            max_share_to_split = 0.99,\n",
    "            max_size = 100.0,\n",
    "            memory_estimate_period = 2000000,\n",
    "            stop_mem_management = False,\n",
    "            remove_poor_attrs = False,\n",
    "            merit_preprune = True,\n",
    "            seed = 42,\n",
    "        )\n",
    "    elif project_name == \"Estimated Time of Arrival\":\n",
    "        # =================================================================\n",
    "        # ARFRegressor - Adaptive Random Forest Regressor\n",
    "        # For ETA prediction with continuous drift handling\n",
    "        # =================================================================\n",
    "        # OLD CONFIGURATION:\n",
    "        # return forest.ARFRegressor(\n",
    "        #     n_models = 10,\n",
    "        #     drift_detector = drift.ADWIN(),\n",
    "        #     warning_detector = drift.ADWIN(),\n",
    "        #     metric = metrics.RMSE(),\n",
    "        #     max_features = \"sqrt\",\n",
    "        #     lambda_value = 6,\n",
    "        #     seed = 42\n",
    "        # )\n",
    "\n",
    "        # CONFIGURATION based on River ML documentation:\n",
    "        # Reference: https://riverml.xyz/latest/api/forest/ARFRegressor/\n",
    "        #\n",
    "        # - n_models=10: Default number of trees\n",
    "        # - max_features=\"sqrt\": Default feature selection\n",
    "        # - aggregation_method=\"median\": Default, robust to outliers\n",
    "        # - lambda_value=6: Default Leveraging Bagging parameter\n",
    "        # - metric=MAE(): Using MAE as it's common for ETA prediction\n",
    "        # - disable_weighted_vote=True: Default for regressor\n",
    "        # - drift_detector ADWIN(delta=0.002): Default sensitivity\n",
    "        # - warning_detector ADWIN(delta=0.01): Default warning sensitivity\n",
    "        # - grace_period=50: Default observations between split attempts\n",
    "        # - max_depth=None: Default unlimited depth\n",
    "        # - delta=0.01: Default allowed error\n",
    "        # - tau=0.05: Default tie-breaking threshold\n",
    "        # - leaf_prediction=\"adaptive\": Default, dynamically chooses mean/model\n",
    "        # - model_selector_decay=0.95: Default decay for leaf model selection\n",
    "        # - min_samples_split=5: Default minimum samples for split\n",
    "        # - binary_split=False: Default multi-way splits\n",
    "        # - max_size=500.0: Default max memory in MiB\n",
    "        return forest.ARFRegressor(\n",
    "            n_models=10,\n",
    "            max_features=\"sqrt\",\n",
    "            aggregation_method=\"median\",\n",
    "            lambda_value=6,\n",
    "            metric=metrics.MAE(),\n",
    "            disable_weighted_vote=True,\n",
    "            drift_detector=drift.ADWIN(delta=0.002),\n",
    "            warning_detector=drift.ADWIN(delta=0.01),\n",
    "            grace_period=50,\n",
    "            max_depth=None,\n",
    "            delta=0.01,\n",
    "            tau=0.05,\n",
    "            leaf_prediction=\"adaptive\",\n",
    "            leaf_model=None,\n",
    "            model_selector_decay=0.95,\n",
    "            min_samples_split=5,\n",
    "            binary_split=False,\n",
    "            max_size=500.0,\n",
    "            memory_estimate_period=2000000,\n",
    "            nominal_attributes=None,\n",
    "            seed=42,\n",
    "        )\n",
    "    elif project_name == \"E-Commerce Customer Interactions\":\n",
    "        # =================================================================\n",
    "        # DBSTREAM - Density-Based Stream Clustering\n",
    "        # For customer behavior clustering with arbitrary shapes\n",
    "        # =================================================================\n",
    "        # OLD CONFIGURATION:\n",
    "        # return cluster.DBSTREAM(\n",
    "        #     clustering_threshold = 1.0,\n",
    "        #     fading_factor = 0.01,\n",
    "        #     cleanup_interval = 2,\n",
    "        # )\n",
    "\n",
    "        # CONFIGURATION based on River ML documentation example:\n",
    "        # Reference: https://riverml.xyz/latest/api/cluster/DBSTREAM/\n",
    "        #\n",
    "        # The River documentation provides this exact example configuration:\n",
    "        # - clustering_threshold=1.5: Micro-cluster radius\n",
    "        # - fading_factor=0.05: Historical data importance (must be > 0)\n",
    "        # - cleanup_interval=4: Time between cleanup processes\n",
    "        # - intersection_factor=0.5: Cluster overlap ratio for connectivity\n",
    "        # - minimum_weight=1.0: Threshold for non-noisy cluster classification\n",
    "        return cluster.DBSTREAM(\n",
    "            clustering_threshold=1.5,\n",
    "            fading_factor=0.05,\n",
    "            cleanup_interval=4,\n",
    "            intersection_factor=0.5,\n",
    "            minimum_weight=1.0,\n",
    "        )\n",
    "    elif project_name == \"Sales Forecasting\":\n",
    "        # =================================================================\n",
    "        # SNARIMAX - Seasonal Non-linear Auto-Regressive Integrated\n",
    "        # Moving Average with eXogenous inputs\n",
    "        # For sales forecasting with weekly seasonality\n",
    "        # =================================================================\n",
    "        # OLD CONFIGURATION:\n",
    "        # regressor_snarimax = linear_model.PARegressor(\n",
    "        #     C = 0.01,\n",
    "        #     mode = 1)\n",
    "        # return time_series.SNARIMAX(\n",
    "        #     p = 2,\n",
    "        #     d = 1,\n",
    "        #     q = 1,\n",
    "        #     m = 7,\n",
    "        #     sp = 1,\n",
    "        #     sd = 0,\n",
    "        #     sq = 1,\n",
    "        #     regressor = regressor_snarimax\n",
    "        # )\n",
    "\n",
    "        # CONFIGURATION based on River ML documentation:\n",
    "        # Reference: https://riverml.xyz/latest/api/time-series/SNARIMAX/\n",
    "        # Reference: https://riverml.xyz/latest/api/linear-model/PARegressor/\n",
    "        #\n",
    "        # SNARIMAX parameters for weekly sales data:\n",
    "        # - p=7: Past 7 days of target values (full week)\n",
    "        # - d=1: First-order differencing for trend removal\n",
    "        # - q=2: Past error terms for noise handling\n",
    "        # - m=7: Weekly seasonality period\n",
    "        # - sp=1: Seasonal autoregressive order\n",
    "        # - sd=1: Seasonal differencing (recommended for seasonal data)\n",
    "        # - sq=1: Seasonal moving average order\n",
    "        #\n",
    "        # PARegressor parameters (defaults from River docs):\n",
    "        # - C=1.0: Default regularization strength\n",
    "        # - mode=1: Default algorithm mode\n",
    "        # - eps=0.1: Default tolerance parameter\n",
    "        # - learn_intercept=True: Default bias learning\n",
    "        regressor_snarimax = linear_model.PARegressor(\n",
    "            C=1.0,\n",
    "            mode=1,\n",
    "            eps=0.1,\n",
    "            learn_intercept=True,\n",
    "        )\n",
    "        return time_series.SNARIMAX(\n",
    "            p=7,\n",
    "            d=1,\n",
    "            q=2,\n",
    "            m=7,\n",
    "            sp=1,\n",
    "            sd=1,\n",
    "            sq=1,\n",
    "            regressor=regressor_snarimax,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown project: {project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09fd2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_default_encoders(project_name):\n",
    "    \"\"\"Create default encoders based on project type.\"\"\"\n",
    "    if project_name in [\"Transaction Fraud Detection\", \"Estimated Time of Arrival\"]:\n",
    "        return {\"ordinal_encoder\": CustomOrdinalEncoder()}\n",
    "    elif project_name == \"E-Commerce Customer Interactions\":\n",
    "        return {\n",
    "            \"standard_scaler\": preprocessing.StandardScaler(),\n",
    "            \"feature_hasher\": preprocessing.FeatureHasher()\n",
    "        }\n",
    "    elif project_name == \"Sales Forecasting\":\n",
    "        return {\n",
    "            \"one_hot_encoder\": preprocessing.OneHotEncoder(),\n",
    "            \"standard_scaler\": preprocessing.StandardScaler(),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown project: {project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97nhcpk10fh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REGRESSION METRICS FOR ESTIMATED TIME OF ARRIVAL\n",
      "======================================================================\n",
      "\n",
      "Metric Classes:\n",
      "  MAE       : MAE() - lower is better\n",
      "  RMSE      : RMSE() - lower is better\n",
      "  MAPE      : MAPE() - lower is better\n",
      "  R2        : R2() - higher is better\n",
      "  SMAPE     : SMAPE() - lower is better\n",
      "  MSE       : MSE() - lower is better\n",
      "  RMSLE     : RMSLE() - lower is better\n",
      "\n",
      "Metric Arguments (all empty - no configurable params):\n",
      "  MAE       : {}\n",
      "  RMSE      : {}\n",
      "  MAPE      : {}\n",
      "  R2        : {}\n",
      "  SMAPE     : {}\n",
      "  MSE       : {}\n",
      "  RMSLE     : {}\n",
      "\n",
      "Rolling Metrics:\n",
      "  RollingMAE: Rolling(MAE(), window_size=1000)\n",
      "\n",
      "======================================================================\n",
      "BEST MODEL SELECTION: Minimize MAE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RIVER ML METRICS CONFIGURATION FOR ESTIMATED TIME OF ARRIVAL\n",
    "# =============================================================================\n",
    "# Research-based optimal configuration for real-time ETA training.\n",
    "# Sources:\n",
    "#   - River ML Documentation: https://riverml.xyz/dev/api/metrics/\n",
    "#   - ETA Prediction Best Practices: https://peerj.com/articles/cs-3259/\n",
    "#   - Travel Time Prediction Review: https://pmc.ncbi.nlm.nih.gov/articles/PMC8444094/\n",
    "#\n",
    "# Key insights from literature:\n",
    "#   - MAE + RMSE + MAPE is the most common metric combination (15-23% of studies)\n",
    "#   - MAE is the primary metric (used in 33% of ETA studies)\n",
    "#   - Rolling metrics help detect concept drift (traffic pattern changes)\n",
    "#\n",
    "# IMPORTANT: Unlike classification metrics, River regression metrics have\n",
    "#            NO configurable parameters (no cm, pos_val, beta, n_thresholds, etc.)\n",
    "# =============================================================================\n",
    "\n",
    "from river import metrics, utils\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# REGRESSION METRICS (use predict_one - continuous values)\n",
    "# -----------------------------------------------------------------------------\n",
    "# These metrics compare predicted travel time vs actual travel time (seconds)\n",
    "# All metrics have NO configurable parameters - use default constructors\n",
    "# -----------------------------------------------------------------------------\n",
    "regression_metric_classes = {\n",
    "    # PRIMARY METRICS (most important for ETA - used in 15-23% of studies)\n",
    "    \"MAE\": metrics.MAE,      # Mean Absolute Error - Primary metric (seconds)\n",
    "                             # Formula: (1/n) * Σ|y_true - y_pred|\n",
    "                             # Use case: Most interpretable, same units as target\n",
    "    \n",
    "    \"RMSE\": metrics.RMSE,    # Root Mean Squared Error - Large error penalty\n",
    "                             # Formula: sqrt((1/n) * Σ(y_true - y_pred)²)\n",
    "                             # Use case: Penalizes late arrivals more heavily\n",
    "    \n",
    "    \"MAPE\": metrics.MAPE,    # Mean Absolute Percentage Error - Scale-independent\n",
    "                             # Formula: (100/n) * Σ|y_true - y_pred| / |y_true|\n",
    "                             # Use case: Compare across different trip lengths\n",
    "                             # Warning: Undefined when y_true = 0\n",
    "    \n",
    "    # SECONDARY METRICS (additional insights)\n",
    "    \"R2\": metrics.R2,        # Coefficient of Determination - Goodness of fit\n",
    "                             # Formula: 1 - (SS_res / SS_tot)\n",
    "                             # Use case: Proportion of variance explained\n",
    "                             # Range: Can be negative (worse than baseline)\n",
    "    \n",
    "    \"SMAPE\": metrics.SMAPE,  # Symmetric MAPE - Robust percentage error\n",
    "                             # Formula: (100/n) * Σ|y_true - y_pred| / ((|y_true| + |y_pred|) / 2)\n",
    "                             # Use case: More robust than MAPE (bounded 0-200%)\n",
    "    \n",
    "    \"MSE\": metrics.MSE,      # Mean Squared Error - For optimization\n",
    "                             # Formula: (1/n) * Σ(y_true - y_pred)²\n",
    "                             # Use case: Squared units, used in loss functions\n",
    "    \n",
    "    \"RMSLE\": metrics.RMSLE,  # Root Mean Squared Logarithmic Error - Log-scale\n",
    "                             # Formula: sqrt((1/n) * Σ(log(y_pred+1) - log(y_true+1))²)\n",
    "                             # Use case: Less sensitive to large errors than RMSE\n",
    "}\n",
    "\n",
    "# All regression metrics have NO configurable parameters\n",
    "regression_metric_args = {\n",
    "    \"MAE\": {},      # No args - optimal: lower is better\n",
    "    \"RMSE\": {},     # No args - optimal: lower is better\n",
    "    \"MAPE\": {},     # No args - optimal: lower is better\n",
    "    \"R2\": {},       # No args - optimal: higher is better (only one!)\n",
    "    \"SMAPE\": {},    # No args - optimal: lower is better\n",
    "    \"MSE\": {},      # No args - optimal: lower is better\n",
    "    \"RMSLE\": {},    # No args - optimal: lower is better\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ROLLING METRICS (for concept drift detection)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Rolling metrics use utils.Rolling() wrapper to compute over sliding window\n",
    "# Use case: Detect traffic pattern shifts (rush hour, weather, incidents)\n",
    "# -----------------------------------------------------------------------------\n",
    "rolling_metric_classes = {\n",
    "    \"RollingMAE\": utils.Rolling,\n",
    "}\n",
    "\n",
    "rolling_metric_args = {\n",
    "    # RollingMAE: Windowed MAE for drift detection\n",
    "    # window_size=1000: Number of recent samples to consider\n",
    "    # - Provides stable estimates while detecting recent performance changes\n",
    "    # - For ETA with ~10 samples/second, covers ~100 seconds of data\n",
    "    # - Smaller windows (500) = more sensitive to drift\n",
    "    # - Larger windows (2000) = more stable but slower to detect drift\n",
    "    \"RollingMAE\": {\"obj\": metrics.MAE(), \"window_size\": 1000},\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# INSTANTIATE ALL METRICS\n",
    "# =============================================================================\n",
    "regression_metrics = {\n",
    "    name: regression_metric_classes[name](**regression_metric_args[name])\n",
    "    for name in regression_metric_classes\n",
    "}\n",
    "\n",
    "rolling_metrics = {\n",
    "    name: rolling_metric_classes[name](**rolling_metric_args[name])\n",
    "    for name in rolling_metric_classes\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# BEST MODEL SELECTION CRITERION\n",
    "# =============================================================================\n",
    "# For ETA: Minimize MAE (lower is better)\n",
    "# Rationale: MAE is most interpretable and used in 33% of ETA studies\n",
    "# Alternative: RMSE if large errors (late arrivals) should be penalized more\n",
    "# This should be added to BEST_METRIC_CRITERIA in functions.py:\n",
    "# \"Estimated Time of Arrival\": (\"MAE\", \"minimize\")\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"REGRESSION METRICS FOR ESTIMATED TIME OF ARRIVAL\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nMetric Classes:\")\n",
    "for name in regression_metric_classes:\n",
    "    metric = regression_metrics[name]\n",
    "    optimal = \"higher\" if metric.bigger_is_better else \"lower\"\n",
    "    print(f\"  {name:<10}: {type(metric).__name__}() - {optimal} is better\")\n",
    "\n",
    "print(\"\\nMetric Arguments (all empty - no configurable params):\")\n",
    "for name, args in regression_metric_args.items():\n",
    "    print(f\"  {name:<10}: {args}\")\n",
    "\n",
    "print(\"\\nRolling Metrics:\")\n",
    "for name, args in rolling_metric_args.items():\n",
    "    print(f\"  {name:<10}: Rolling(MAE(), window_size={args['window_size']})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BEST MODEL SELECTION: Minimize MAE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aca362e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 264.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 3209314.4296047348,\n",
       " 'RMSE': 101458798.23315397,\n",
       " 'MAPE': 70854.1680197065,\n",
       " 'R2': -2002101934.0681758,\n",
       " 'SMAPE': 23.803354530158078,\n",
       " 'MSE': 1.0293887738915848e+16,\n",
       " 'RMSLE': 0.5928288151108694,\n",
       " 'RollingMAE': 3209314.4296047348,\n",
       " 'RollingRMSE': 101458798.23315397,\n",
       " 'TimeRollingMAE': 3209314.4296047348}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import metrics, utils\n",
    "import datetime as dt\n",
    "\n",
    "# =============================================================================\n",
    "# INVESTIGATION FINDINGS: dir(metrics)\n",
    "# =============================================================================\n",
    "# Total items: 89 (49 classes, 27 submodules, 0 functions, 0 constants)\n",
    "#\n",
    "# BASE CLASSES (metrics.base):\n",
    "#   RegressionMetric()           - NO parameters\n",
    "#   MeanMetric()                 - NO parameters  \n",
    "#   ClassificationMetric(cm)     - has cm parameter\n",
    "#   BinaryMetric(cm, pos_val)    - has cm, pos_val parameters\n",
    "#   MultiClassMetric(cm)         - has cm parameter\n",
    "#   ClusteringMetric()           - NO parameters\n",
    "#   WrapperMetric()              - abstract base\n",
    "#   Metrics(metrics, str_sep)    - container for multiple metrics\n",
    "#\n",
    "# REGRESSION METRIC HIERARCHY:\n",
    "#   MAE   -> MeanMetric, RegressionMetric\n",
    "#   MAPE  -> MeanMetric, RegressionMetric\n",
    "#   MSE   -> MeanMetric, RegressionMetric\n",
    "#   RMSE  -> MSE\n",
    "#   RMSLE -> RMSE\n",
    "#   SMAPE -> MeanMetric, RegressionMetric\n",
    "#   R2    -> RegressionMetric (only one NOT using MeanMetric)\n",
    "#\n",
    "# ROLLING WRAPPERS (river.utils, NOT river.metrics):\n",
    "#   utils.Rolling(obj, window_size)      - sample-based window\n",
    "#   utils.TimeRolling(obj, period)       - time-based window (requires t=timestamp)\n",
    "#\n",
    "# MULTIOUTPUT METRICS (metrics.multioutput) - for multi-target regression:\n",
    "#   MacroAverage(metric), MicroAverage(metric), PerOutput(metric), SampleAverage(metric)\n",
    "# =============================================================================\n",
    "\n",
    "PROJECT_NAME = \"Estimated Time of Arrival\"\n",
    "\n",
    "model = _create_default_model(PROJECT_NAME)\n",
    "encoders = _create_default_encoders(PROJECT_NAME)\n",
    "\n",
    "regression_metric_classes = {\n",
    "    \"MAE\": metrics.MAE,\n",
    "    \"RMSE\": metrics.RMSE,\n",
    "    \"MAPE\": metrics.MAPE,\n",
    "    \"R2\": metrics.R2,\n",
    "    \"SMAPE\": metrics.SMAPE,\n",
    "    \"MSE\": metrics.MSE,\n",
    "    \"RMSLE\": metrics.RMSLE,\n",
    "}\n",
    "\n",
    "regression_metric_args = {\n",
    "    \"MAE\": {},\n",
    "    \"RMSE\": {},\n",
    "    \"MAPE\": {},\n",
    "    \"R2\": {},\n",
    "    \"SMAPE\": {},\n",
    "    \"MSE\": {},\n",
    "    \"RMSLE\": {},\n",
    "}\n",
    "\n",
    "rolling_metric_classes = {\n",
    "    \"RollingMAE\": utils.Rolling,\n",
    "    \"RollingRMSE\": utils.Rolling,\n",
    "}\n",
    "\n",
    "rolling_metric_args = {\n",
    "    \"RollingMAE\": {\"obj\": metrics.MAE(), \"window_size\": 1000},\n",
    "    \"RollingRMSE\": {\"obj\": metrics.RMSE(), \"window_size\": 1000},\n",
    "}\n",
    "\n",
    "time_rolling_metric_classes = {\n",
    "    \"TimeRollingMAE\": utils.TimeRolling,\n",
    "}\n",
    "\n",
    "time_rolling_metric_args = {\n",
    "    \"TimeRollingMAE\": {\"obj\": metrics.MAE(), \"period\": dt.timedelta(minutes=5)},\n",
    "}\n",
    "\n",
    "regression_metrics = {\n",
    "    name: regression_metric_classes[name](**regression_metric_args[name])\n",
    "    for name in regression_metric_classes\n",
    "}\n",
    "\n",
    "rolling_metrics = {\n",
    "    name: rolling_metric_classes[name](**rolling_metric_args[name])\n",
    "    for name in rolling_metric_classes\n",
    "}\n",
    "\n",
    "time_rolling_metrics = {\n",
    "    name: time_rolling_metric_classes[name](**time_rolling_metric_args[name])\n",
    "    for name in time_rolling_metric_classes\n",
    "}\n",
    "\n",
    "for i, sample in enumerate(tqdm.tqdm(samples)):\n",
    "    x, encoders = process_sample(sample, encoders, PROJECT_NAME)\n",
    "    y = sample['simulated_actual_travel_time_seconds']\n",
    "    timestamp = dt.datetime.strptime(sample['timestamp'], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    \n",
    "    prediction = model.predict_one(x)\n",
    "    model.learn_one(x, y)\n",
    "    \n",
    "    if prediction is not None:\n",
    "        for metric in regression_metrics.values():\n",
    "            try:\n",
    "                metric.update(y, prediction)\n",
    "            except:\n",
    "                pass\n",
    "        for metric in rolling_metrics.values():\n",
    "            try:\n",
    "                metric.update(y, prediction)\n",
    "            except:\n",
    "                pass\n",
    "        for metric in time_rolling_metrics.values():\n",
    "            try:\n",
    "                metric.update(y, prediction, t=timestamp)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "metrics_to_log = {}\n",
    "for name, metric in regression_metrics.items():\n",
    "    metrics_to_log[name] = metric.get()\n",
    "for name, metric in rolling_metrics.items():\n",
    "    metrics_to_log[name] = metric.get()\n",
    "for name, metric in time_rolling_metrics.items():\n",
    "    metrics_to_log[name] = metric.get()\n",
    "\n",
    "metrics_to_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
