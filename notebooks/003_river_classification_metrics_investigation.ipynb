{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "list_all_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All items in metrics module:\n",
      "['Accuracy', 'AdjustedMutualInfo', 'AdjustedRand', 'BalancedAccuracy', 'ClassificationReport', 'CohenKappa', 'Completeness', 'ConfusionMatrix', 'CrossEntropy', 'F1', 'FBeta', 'FowlkesMallows', 'GeometricMean', 'Homogeneity', 'Jaccard', 'LogLoss', 'MAE', 'MAPE', 'MCC', 'MSE', 'MacroF1', 'MacroFBeta', 'MacroJaccard', 'MacroPrecision', 'MacroRecall', 'MicroF1', 'MicroFBeta', 'MicroJaccard', 'MicroPrecision', 'MicroRecall', 'MultiFBeta', 'MutualInfo', 'NormalizedMutualInfo', 'Precision', 'R2', 'RMSE', 'RMSLE', 'ROCAUC', 'Rand', 'Recall', 'RollingROCAUC', 'SMAPE', 'Silhouette', 'VBeta', 'WeightedF1', 'WeightedFBeta', 'WeightedJaccard', 'WeightedPrecision', 'WeightedRecall', 'accuracy', 'annotations', 'balanced_accuracy', 'base', 'confusion', 'cross_entropy', 'efficient_rollingrocauc', 'expected_mutual_info', 'fbeta', 'fowlkes_mallows', 'geometric_mean', 'jaccard', 'kappa', 'log_loss', 'mae', 'mape', 'mcc', 'mse', 'multioutput', 'mutual_info', 'precision', 'r2', 'rand', 'recall', 'report', 'roc_auc', 'rolling_roc_auc', 'silhouette', 'smape', 'vbeta']\n"
     ]
    }
   ],
   "source": [
    "# 1) Get all items from river.metrics\n",
    "all_items = [name for name in dir(metrics) if not name.startswith('_')]\n",
    "print(\"All items in metrics module:\")\n",
    "print(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "filter_classes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total metric classes: 49\n",
      "['Accuracy', 'AdjustedMutualInfo', 'AdjustedRand', 'BalancedAccuracy', 'ClassificationReport', 'CohenKappa', 'Completeness', 'ConfusionMatrix', 'CrossEntropy', 'F1', 'FBeta', 'FowlkesMallows', 'GeometricMean', 'Homogeneity', 'Jaccard', 'LogLoss', 'MAE', 'MAPE', 'MCC', 'MSE', 'MacroF1', 'MacroFBeta', 'MacroJaccard', 'MacroPrecision', 'MacroRecall', 'MicroF1', 'MicroFBeta', 'MicroJaccard', 'MicroPrecision', 'MicroRecall', 'MultiFBeta', 'MutualInfo', 'NormalizedMutualInfo', 'Precision', 'R2', 'RMSE', 'RMSLE', 'ROCAUC', 'Rand', 'Recall', 'RollingROCAUC', 'SMAPE', 'Silhouette', 'VBeta', 'WeightedF1', 'WeightedFBeta', 'WeightedJaccard', 'WeightedPrecision', 'WeightedRecall']\n"
     ]
    }
   ],
   "source": [
    "# Filter only classes (not functions or submodules)\n",
    "metric_classes_all = {\n",
    "    name: getattr(metrics, name) \n",
    "    for name in all_items \n",
    "    if inspect.isclass(getattr(metrics, name))\n",
    "}\n",
    "print(f\"Total metric classes: {len(metric_classes_all)}\")\n",
    "print(list(metric_classes_all.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "classification_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics: 32\n",
      "['Accuracy', 'BalancedAccuracy', 'ClassificationReport', 'CohenKappa', 'ConfusionMatrix', 'CrossEntropy', 'F1', 'FBeta', 'GeometricMean', 'Jaccard', 'LogLoss', 'MCC', 'MacroF1', 'MacroFBeta', 'MacroJaccard', 'MacroPrecision', 'MacroRecall', 'MicroF1', 'MicroFBeta', 'MicroJaccard', 'MicroPrecision', 'MicroRecall', 'MultiFBeta', 'Precision', 'ROCAUC', 'Recall', 'RollingROCAUC', 'WeightedF1', 'WeightedFBeta', 'WeightedJaccard', 'WeightedPrecision', 'WeightedRecall']\n"
     ]
    }
   ],
   "source": [
    "# 2) Filter classification metrics suitable for TFD (binary classification)\n",
    "# Exclude regression metrics (MAE, MSE, RMSE, R2, etc.)\n",
    "# Exclude clustering metrics (Silhouette, Rand, MutualInfo, etc.)\n",
    "\n",
    "regression_metrics = {'MAE', 'MAPE', 'MSE', 'R2', 'RMSE', 'RMSLE', 'SMAPE'}\n",
    "clustering_metrics = {'Silhouette', 'Rand', 'AdjustedRand', 'MutualInfo', \n",
    "                      'AdjustedMutualInfo', 'NormalizedMutualInfo', \n",
    "                      'Homogeneity', 'Completeness', 'VBeta', 'FowlkesMallows'}\n",
    "\n",
    "classification_metrics = {\n",
    "    name: cls for name, cls in metric_classes_all.items()\n",
    "    if name not in regression_metrics and name not in clustering_metrics\n",
    "}\n",
    "\n",
    "print(f\"Classification metrics: {len(classification_metrics)}\")\n",
    "print(list(classification_metrics.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "investigate_accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Accuracy in module river.metrics.accuracy:\n",
      "\n",
      "class Accuracy(river.metrics.base.MultiClassMetric)\n",
      " |  Accuracy(cm=None)\n",
      " |\n",
      " |  Accuracy score, which is the percentage of exact matches.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion\n",
      " |      matrix between multiple metrics. Sharing a confusion matrix reduces the amount of storage\n",
      " |      and computation time.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [True, False, True, True, True]\n",
      " |  >>> y_pred = [True, True, False, True, True]\n",
      " |\n",
      " |  >>> metric = metrics.Accuracy()\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  Accuracy: 60.00%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Accuracy\n",
      " |      river.metrics.base.MultiClassMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MultiClassMetric:\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  __init__(self, cm=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Investigate each classification metric\n",
    "# Starting with Accuracy\n",
    "help(metrics.Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "investigate_balanced_accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BalancedAccuracy in module river.metrics.balanced_accuracy:\n",
      "\n",
      "class BalancedAccuracy(river.metrics.base.MultiClassMetric)\n",
      " |  BalancedAccuracy(cm=None)\n",
      " |\n",
      " |  Balanced accuracy.\n",
      " |\n",
      " |  Balanced accuracy is the average of recall obtained on each class. It is used to\n",
      " |  deal with imbalanced datasets in binary and multi-class classification problems.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion\n",
      " |      matrix between multiple metrics. Sharing a confusion matrix reduces the amount of storage\n",
      " |      and computation time.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |      >>> from river import metrics\n",
      " |      >>> y_true = [True, False, True, True, False, True]\n",
      " |      >>> y_pred = [True, False, True, True, True, False]\n",
      " |\n",
      " |      >>> metric = metrics.BalancedAccuracy()\n",
      " |      >>> for yt, yp in zip(y_true, y_pred):\n",
      " |      ...     metric.update(yt, yp)\n",
      " |\n",
      " |      >>> metric\n",
      " |      BalancedAccuracy: 62.50%\n",
      " |\n",
      " |      >>> y_true = [0, 1, 0, 0, 1, 0]\n",
      " |      >>> y_pred = [0, 1, 0, 0, 0, 1]\n",
      " |      >>> metric = metrics.BalancedAccuracy()\n",
      " |      >>> for yt, yp in zip(y_true, y_pred):\n",
      " |      ...     metric.update(yt, yp)\n",
      " |\n",
      " |      >>> metric\n",
      " |      BalancedAccuracy: 62.50%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      BalancedAccuracy\n",
      " |      river.metrics.base.MultiClassMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MultiClassMetric:\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  __init__(self, cm=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.BalancedAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "investigate_precision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Precision in module river.metrics.precision:\n",
      "\n",
      "class Precision(river.metrics.base.BinaryMetric)\n",
      " |  Precision(cm=None, pos_val=True)\n",
      " |\n",
      " |  Binary precision score.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion matrix between multiple metrics. Sharing\n",
      " |      a confusion matrix reduces the amount of storage and computation time.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [True, False, True, True, True]\n",
      " |  >>> y_pred = [True, True, False, True, True]\n",
      " |\n",
      " |  >>> metric = metrics.Precision()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |  ...     print(metric)\n",
      " |  Precision: 100.00%\n",
      " |  Precision: 50.00%\n",
      " |  Precision: 50.00%\n",
      " |  Precision: 66.67%\n",
      " |  Precision: 75.00%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Precision\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.BinaryMetric:\n",
      " |\n",
      " |  __init__(self, cm=None, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "investigate_recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Recall in module river.metrics.recall:\n",
      "\n",
      "class Recall(river.metrics.base.BinaryMetric)\n",
      " |  Recall(cm=None, pos_val=True)\n",
      " |\n",
      " |  Binary recall score.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion matrix between multiple metrics. Sharing a\n",
      " |      confusion matrix reduces the amount of storage and computation time.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [True, False, True, True, True]\n",
      " |  >>> y_pred = [True, True, False, True, True]\n",
      " |\n",
      " |  >>> metric = metrics.Recall()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |  ...     print(metric)\n",
      " |  Recall: 100.00%\n",
      " |  Recall: 100.00%\n",
      " |  Recall: 50.00%\n",
      " |  Recall: 66.67%\n",
      " |  Recall: 75.00%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Recall\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.BinaryMetric:\n",
      " |\n",
      " |  __init__(self, cm=None, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "investigate_f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class F1 in module river.metrics.fbeta:\n",
      "\n",
      "class F1(FBeta)\n",
      " |  F1(cm=None, pos_val=True)\n",
      " |\n",
      " |  Binary F1 score.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion\n",
      " |      matrix between multiple metrics. Sharing a confusion matrix reduces the amount of storage\n",
      " |      and computation time.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [False, False, False, True, True, True]\n",
      " |  >>> y_pred = [False, False, True, True, False, False]\n",
      " |\n",
      " |  >>> metric = metrics.F1()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  F1: 40.00%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      F1\n",
      " |      FBeta\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, cm=None, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from FBeta:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.BinaryMetric:\n",
      " |\n",
      " |  revert(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "investigate_fbeta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class FBeta in module river.metrics.fbeta:\n",
      "\n",
      "class FBeta(river.metrics.base.BinaryMetric)\n",
      " |  FBeta(beta: 'float', cm=None, pos_val=True)\n",
      " |\n",
      " |  Binary F-Beta score.\n",
      " |\n",
      " |  The FBeta score is a weighted harmonic mean between precision and recall. The higher the\n",
      " |  `beta` value, the higher the recall will be taken into account. When `beta` equals 1,\n",
      " |  precision and recall and equivalently weighted, which results in the F1 score (see\n",
      " |  `metrics.F1`).\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  beta\n",
      " |      Weight of precision in the harmonic mean.\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion\n",
      " |      matrix between multiple metrics. Sharing a confusion matrix reduces the amount of storage\n",
      " |      and computation time.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  precision : metrics.Precision\n",
      " |  recall : metrics.Recall\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [False, False, False, True, True, True]\n",
      " |  >>> y_pred = [False, False, True, True, False, False]\n",
      " |\n",
      " |  >>> metric = metrics.FBeta(beta=2)\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  FBeta: 35.71%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      FBeta\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, beta: 'float', cm=None, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.BinaryMetric:\n",
      " |\n",
      " |  revert(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.FBeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "investigate_rocauc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ROCAUC in module river.metrics.roc_auc:\n",
      "\n",
      "class ROCAUC(river.metrics.base.BinaryMetric)\n",
      " |  ROCAUC(n_thresholds=10, pos_val=True)\n",
      " |\n",
      " |  Receiving Operating Characteristic Area Under the Curve.\n",
      " |\n",
      " |  This metric is an approximation of the true ROC AUC. Computing the true ROC AUC would\n",
      " |  require storing all the predictions and ground truths, which isn't desirable. The approximation\n",
      " |  error is not significant as long as the predicted probabilities are well calibrated. In any\n",
      " |  case, this metric can still be used to reliably compare models between each other.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_thresholds\n",
      " |      The number of thresholds used for discretizing the ROC curve. A higher value will lead to\n",
      " |      more accurate results, but will also cost more time and memory.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [ 0,  0,   1,  1]\n",
      " |  >>> y_pred = [.1, .4, .35, .8]\n",
      " |\n",
      " |  >>> metric = metrics.ROCAUC()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  ROCAUC: 87.50%\n",
      " |\n",
      " |  The true ROC AUC is in fact 0.75. We can improve the accuracy by increasing the amount\n",
      " |  of thresholds. This comes at the cost more computation time and more memory usage.\n",
      " |\n",
      " |  >>> metric = metrics.ROCAUC(n_thresholds=20)\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  ROCAUC: 75.00%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      ROCAUC\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, n_thresholds=10, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0)\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0)\n",
      " |      Update the metric.\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.ROCAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "investigate_rolling_rocauc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RollingROCAUC in module river.metrics.rolling_roc_auc:\n",
      "\n",
      "class RollingROCAUC(river.metrics.base.BinaryMetric)\n",
      " |  RollingROCAUC(window_size=1000, pos_val=True)\n",
      " |\n",
      " |  Rolling version of the Receiving Operating Characteristic Area Under the Curve.\n",
      " |\n",
      " |  The RollingROCAUC calculates the metric using the instances in its window\n",
      " |  of size S. It keeps a queue of the instances, when an instance is added and\n",
      " |  the queue length is equal to S, the last instance is removed. The metric has\n",
      " |  a tree with ordered instances, in order to calculate the AUC efficiently.\n",
      " |  It was implemented based on the algorithm presented in Brzezinski and\n",
      " |  Stefanowski, 2017.\n",
      " |\n",
      " |  The difference between this metric and the standard ROCAUC is that the latter\n",
      " |  calculates an approximation of the real metric considering all data from the\n",
      " |  beginning of the stream, while the RollingROCAUC calculates the exact value\n",
      " |  considering only the last S instances. This approach may be beneficial if\n",
      " |  it's necessary to evaluate the model's performance over time, since\n",
      " |  calculating the metric using the entire stream may hide the current\n",
      " |  performance of the classifier.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  window_size\n",
      " |      The max length of the window.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [ 0,  1,  0,  1,  0,  1,  0,  0,   1,  1]\n",
      " |  >>> y_pred = [.3, .5, .5, .7, .1, .3, .1, .4, .35, .8]\n",
      " |\n",
      " |  >>> metric = metrics.RollingROCAUC(window_size=4)\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  RollingROCAUC: 75.00%\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      RollingROCAUC\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, window_size=1000, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  revert(self, y_true, y_pred)\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true, y_pred)\n",
      " |      Update the metric.\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.RollingROCAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "investigate_mcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MCC in module river.metrics.mcc:\n",
      "\n",
      "class MCC(river.metrics.base.BinaryMetric)\n",
      " |  MCC(cm=None, pos_val=True)\n",
      " |\n",
      " |  Matthews correlation coefficient.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion matrix between multiple metrics. Sharing a\n",
      " |      confusion matrix reduces the amount of storage and computation time.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [True, True, True, False]\n",
      " |  >>> y_pred = [True, False, True, True]\n",
      " |\n",
      " |  >>> mcc = metrics.MCC()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     mcc.update(yt, yp)\n",
      " |\n",
      " |  >>> mcc\n",
      " |  MCC: -0.333333\n",
      " |\n",
      " |  References\n",
      " |  ----------\n",
      " |  [^1]: [Wikipedia article](https://www.wikiwand.com/en/Matthews_correlation_coefficient)\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      MCC\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.BinaryMetric:\n",
      " |\n",
      " |  __init__(self, cm=None, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "investigate_cohen_kappa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CohenKappa in module river.metrics.kappa:\n",
      "\n",
      "class CohenKappa(river.metrics.base.MultiClassMetric)\n",
      " |  CohenKappa(cm=None)\n",
      " |\n",
      " |  Cohen's Kappa score.\n",
      " |\n",
      " |  Cohen's Kappa expresses the level of agreement between two annotators on a classification\n",
      " |  problem. It is defined as\n",
      " |\n",
      " |  $$\n",
      " |  \\kappa = (p_o - p_e) / (1 - p_e)\n",
      " |  $$\n",
      " |\n",
      " |  where $p_o$ is the empirical probability of agreement on the label\n",
      " |  assigned to any sample (prequential accuracy), and $p_e$ is\n",
      " |  the expected agreement when both annotators assign labels randomly.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion\n",
      " |      matrix between multiple metrics. Sharing a confusion matrix reduces the amount of storage\n",
      " |      and computation time.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = ['cat', 'ant', 'cat', 'cat', 'ant', 'bird']\n",
      " |  >>> y_pred = ['ant', 'ant', 'cat', 'cat', 'ant', 'cat']\n",
      " |\n",
      " |  >>> metric = metrics.CohenKappa()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  CohenKappa: 42.86%\n",
      " |\n",
      " |  References\n",
      " |  ----------\n",
      " |  [^1]: J. Cohen (1960). \"A coefficient of agreement for nominal scales\". Educational and Psychological Measurement 20(1):37-46. doi:10.1177/001316446002000104.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      CohenKappa\n",
      " |      river.metrics.base.MultiClassMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MultiClassMetric:\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  __init__(self, cm=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.CohenKappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "investigate_geometric_mean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GeometricMean in module river.metrics.geometric_mean:\n",
      "\n",
      "class GeometricMean(river.metrics.base.MultiClassMetric)\n",
      " |  GeometricMean(cm=None)\n",
      " |\n",
      " |  Geometric mean score.\n",
      " |\n",
      " |  The geometric mean is a good indicator of a classifier's performance in the presence of class\n",
      " |  imbalance because it is independent of the distribution of examples between classes. This\n",
      " |  implementation computes the geometric mean of class-wise sensitivity (recall).\n",
      " |\n",
      " |  $$\n",
      " |  gm = \\sqrt[n]{s_1\\cdot s_2\\cdot s_3\\cdot \\ldots\\cdot s_n}\n",
      " |  $$\n",
      " |\n",
      " |  where $s_i$ is the sensitivity (recall) of class $i$ and $n$ is the\n",
      " |  number of classes.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion matrix between multiple metrics. Sharing a\n",
      " |      confusion matrix reduces the amount of storage and computation time.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = ['cat', 'ant', 'cat', 'cat', 'ant', 'bird', 'bird']\n",
      " |  >>> y_pred = ['ant', 'ant', 'cat', 'cat', 'ant', 'cat', 'bird']\n",
      " |\n",
      " |  >>> metric = metrics.GeometricMean()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |\n",
      " |  >>> metric\n",
      " |  GeometricMean: 69.34%\n",
      " |\n",
      " |  References\n",
      " |  ----------\n",
      " |  [^1]: Barandela, R. et al. Strategies for learning in class imbalance problems, Pattern Recognition, 36(3), (2003), pp 849-851.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      GeometricMean\n",
      " |      river.metrics.base.MultiClassMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MultiClassMetric:\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  __init__(self, cm=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.GeometricMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "investigate_logloss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogLoss in module river.metrics.log_loss:\n",
      "\n",
      "class LogLoss(river.metrics.base.MeanMetric, river.metrics.base.BinaryMetric)\n",
      " |  Binary logarithmic loss.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [True, False, False, True]\n",
      " |  >>> y_pred = [0.9,  0.1,   0.2,   0.65]\n",
      " |\n",
      " |  >>> metric = metrics.LogLoss()\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |  ...     print(metric.get())\n",
      " |  0.105360\n",
      " |  0.105360\n",
      " |  0.144621\n",
      " |  0.216161\n",
      " |\n",
      " |  >>> metric\n",
      " |  LogLoss: 0.216162\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      LogLoss\n",
      " |      river.metrics.base.MeanMetric\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MeanMetric:\n",
      " |\n",
      " |  __init__(self)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  get(self)\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.metrics.base.MeanMetric:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.LogLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "investigate_jaccard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Jaccard in module river.metrics.jaccard:\n",
      "\n",
      "class Jaccard(river.metrics.base.BinaryMetric)\n",
      " |  Jaccard(cm=None, pos_val=True)\n",
      " |\n",
      " |  Jaccard score.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  cm\n",
      " |      This parameter allows sharing the same confusion matrix between multiple metrics. Sharing\n",
      " |      a confusion matrix reduces the amount of storage and computation time.\n",
      " |  pos_val\n",
      " |      Value to treat as \"positive\".\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [False, True, True]\n",
      " |  >>> y_pred = [True, True, True]\n",
      " |\n",
      " |  >>> metric = metrics.Jaccard()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |  ...     print(metric)\n",
      " |  Jaccard: 0.00%\n",
      " |  Jaccard: 50.00%\n",
      " |  Jaccard: 66.67%\n",
      " |\n",
      " |  References\n",
      " |  ----------\n",
      " |  [^1]: [Jaccard index](https://www.wikiwand.com/en/Jaccard_index)\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Jaccard\n",
      " |      river.metrics.base.BinaryMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.BinaryMetric:\n",
      " |\n",
      " |  __init__(self, cm=None, pos_val=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  revert(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  update(self, y_true: 'bool', y_pred: 'bool | float | dict[bool, float]', w=1.0) -> 'None'\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.Jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "investigate_confusion_matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ConfusionMatrix in module river.metrics.confusion:\n",
      "\n",
      "class ConfusionMatrix(river.metrics.base.MultiClassMetric)\n",
      " |  ConfusionMatrix(classes=None)\n",
      " |\n",
      " |  Confusion Matrix for binary and multi-class classification.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  classes\n",
      " |      The initial set of classes. This is optional and serves only for displaying purposes.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = ['cat', 'ant', 'cat', 'cat', 'ant', 'bird']\n",
      " |  >>> y_pred = ['ant', 'ant', 'cat', 'cat', 'ant', 'cat']\n",
      " |\n",
      " |  >>> cm = metrics.ConfusionMatrix()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     cm.update(yt, yp)\n",
      " |\n",
      " |  >>> cm\n",
      " |         ant  bird   cat\n",
      " |   ant     2     0     0\n",
      " |  bird     0     0     1\n",
      " |   cat     1     0     2\n",
      " |\n",
      " |  >>> cm['bird']['cat']\n",
      " |  1.0\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  This confusion matrix is a 2D matrix of shape `(n_classes, n_classes)`, corresponding\n",
      " |  to a single-target (binary and multi-class) classification task.\n",
      " |\n",
      " |  Each row represents `true` (actual) class-labels, while each column corresponds\n",
      " |  to the `predicted` class-labels. For example, an entry in position `[1, 2]` means\n",
      " |  that the true class-label is 1, and the predicted class-label is 2 (incorrect prediction).\n",
      " |\n",
      " |  This structure is used to keep updated statistics about a single-output classifier's\n",
      " |  performance and to compute multiple evaluation metrics.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      ConfusionMatrix\n",
      " |      river.metrics.base.MultiClassMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __getitem__(self, key)\n",
      " |      Syntactic sugar for accessing the counts directly.\n",
      " |\n",
      " |  __init__(self, classes=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  false_negatives(self, label)\n",
      " |\n",
      " |  false_positives(self, label)\n",
      " |\n",
      " |  get(self)\n",
      " |      Return the current value of the metric.\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0)\n",
      " |      Revert the metric.\n",
      " |\n",
      " |  support(self, label)\n",
      " |\n",
      " |  true_negatives(self, label)\n",
      " |\n",
      " |  true_positives(self, label)\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0)\n",
      " |      Update the metric.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  classes\n",
      " |\n",
      " |  total_false_negatives\n",
      " |\n",
      " |  total_false_positives\n",
      " |\n",
      " |  total_true_negatives\n",
      " |\n",
      " |  total_true_positives\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MultiClassMetric:\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.base.base.Base:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.ConfusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "investigate_cross_entropy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CrossEntropy in module river.metrics.cross_entropy:\n",
      "\n",
      "class CrossEntropy(river.metrics.base.MeanMetric, river.metrics.base.MultiClassMetric)\n",
      " |  Multiclass generalization of the logarithmic loss.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from river import metrics\n",
      " |\n",
      " |  >>> y_true = [0, 1, 2, 2]\n",
      " |  >>> y_pred = [\n",
      " |  ...     {0: 0.29450637, 1: 0.34216758, 2: 0.36332605},\n",
      " |  ...     {0: 0.21290077, 1: 0.32728332, 2: 0.45981591},\n",
      " |  ...     {0: 0.42860913, 1: 0.33380113, 2: 0.23758974},\n",
      " |  ...     {0: 0.44941979, 1: 0.32962558, 2: 0.22095463}\n",
      " |  ... ]\n",
      " |\n",
      " |  >>> metric = metrics.CrossEntropy()\n",
      " |\n",
      " |  >>> for yt, yp in zip(y_true, y_pred):\n",
      " |  ...     metric.update(yt, yp)\n",
      " |  ...     print(metric.get())\n",
      " |  1.222454\n",
      " |  1.169691\n",
      " |  1.258864\n",
      " |  1.321597\n",
      " |\n",
      " |  >>> metric\n",
      " |  CrossEntropy: 1.321598\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      CrossEntropy\n",
      " |      river.metrics.base.MeanMetric\n",
      " |      river.metrics.base.MultiClassMetric\n",
      " |      river.metrics.base.ClassificationMetric\n",
      " |      river.metrics.base.Metric\n",
      " |      river.base.base.Base\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  bigger_is_better\n",
      " |      Indicate if a high value is better than a low one or not.\n",
      " |\n",
      " |  requires_labels\n",
      " |      Indicates if labels are required, rather than probabilities.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MeanMetric:\n",
      " |\n",
      " |  __init__(self)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  get(self)\n",
      " |\n",
      " |  revert(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |\n",
      " |  update(self, y_true, y_pred, w=1.0) -> 'None'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from river.metrics.base.MeanMetric:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.MultiClassMetric:\n",
      " |\n",
      " |  works_with(self, model) -> 'bool'\n",
      " |      Indicates whether or not a metric can work with a given model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.ClassificationMetric:\n",
      " |\n",
      " |  __add__(self, other) -> 'Metrics'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return the class name along with the current value of the metric.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  is_better_than(self, other) -> 'bool'\n",
      " |      Indicate if the current metric is better than another one.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from river.metrics.base.Metric:\n",
      " |\n",
      " |  works_with_weights\n",
      " |      Indicate whether the model takes into consideration the effect of sample weights\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from river.base.base.Base:\n",
      " |\n",
      " |  clone(\n",
      " |      self,\n",
      " |      new_params: 'dict[str, typing.Any] | None' = None,\n",
      " |      include_attributes: 'bool' = False\n",
      " |  ) -> 'typing_extensions.Self'\n",
      " |      Return a fresh estimator with the same parameters.\n",
      " |\n",
      " |      The clone has the same parameters but has not been updated with any data.\n",
      " |\n",
      " |      This works by looking at the parameters from the class signature. Each parameter is either\n",
      " |\n",
      " |      - recursively cloned if its a class.\n",
      " |      - deep-copied via `copy.deepcopy` if not.\n",
      " |\n",
      " |      If the calling object is stochastic (i.e. it accepts a seed parameter) and has not been\n",
      " |      seeded, then the clone will not be idempotent. Indeed, this method's purpose if simply to\n",
      " |      return a new instance with the same input parameters.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_params\n",
      " |      include_attributes\n",
      " |          Whether attributes that are not present in the class' signature should also be cloned\n",
      " |          or not.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(lr=0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': optim.SGD(.001)\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'optimizer': optim.SGD(0.03)\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.clone(new_params)\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=0.\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      " |\n",
      " |  mutate(self, new_attrs: 'dict[str, typing.Any]') -> 'None'\n",
      " |      Modify attributes.\n",
      " |\n",
      " |      This changes parameters inplace. Although you can change attributes yourself, this is the\n",
      " |      recommended way to proceed. By default, all attributes are immutable, meaning they\n",
      " |      shouldn't be mutated. Calling `mutate` on an immutable attribute raises a `ValueError`.\n",
      " |      Mutable attributes are specified via the `_mutable_attributes` property, and are thus\n",
      " |      specified on a per-estimator basis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_attrs\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> from river import linear_model\n",
      " |      >>> from river import optim\n",
      " |\n",
      " |      >>> model = linear_model.LinearRegression(\n",
      " |      ...     optimizer=optim.SGD(0.042),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'optimizer': {'lr': optim.schedulers.Constant(0.001)}\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      LinearRegression (\n",
      " |        optimizer=SGD (\n",
      " |          lr=Constant (\n",
      " |            learning_rate=0.001\n",
      " |          )\n",
      " |        )\n",
      " |        loss=Squared ()\n",
      " |        l2=0.\n",
      " |        l1=0.\n",
      " |        intercept_init=0.\n",
      " |        intercept_lr=Constant (\n",
      " |          learning_rate=0.01\n",
      " |        )\n",
      " |        clip_gradient=1e+12\n",
      " |        initializer=Zeros ()\n",
      " |      )\n",
      " |\n",
      " |      The algorithm is recursively called down `Pipeline`s and `TransformerUnion`s.\n",
      " |\n",
      " |      >>> from river import compose\n",
      " |      >>> from river import preprocessing\n",
      " |\n",
      " |      >>> model = compose.Pipeline(\n",
      " |      ...     preprocessing.StandardScaler(),\n",
      " |      ...     linear_model.LinearRegression(\n",
      " |      ...         optimizer=optim.SGD(lr=0.042),\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |\n",
      " |      >>> new_params = {\n",
      " |      ...     'LinearRegression': {\n",
      " |      ...         'l2': 5,\n",
      " |      ...         'optimizer': {'lr': optim.schedulers.Constant(0.03)}\n",
      " |      ...     }\n",
      " |      ... }\n",
      " |\n",
      " |      >>> model.mutate(new_params)\n",
      " |      >>> model\n",
      " |      Pipeline (\n",
      " |        StandardScaler (\n",
      " |          with_std=True\n",
      " |        ),\n",
      " |        LinearRegression (\n",
      " |          optimizer=SGD (\n",
      " |            lr=Constant (\n",
      " |              learning_rate=0.03\n",
      " |            )\n",
      " |          )\n",
      " |          loss=Squared ()\n",
      " |          l2=5\n",
      " |          l1=0.\n",
      " |          intercept_init=0.\n",
      " |          intercept_lr=Constant (\n",
      " |            learning_rate=0.01\n",
      " |          )\n",
      " |          clip_gradient=1e+12\n",
      " |          initializer=Zeros ()\n",
      " |        )\n",
      " |      )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.CrossEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tfd_recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE METRICS CONFIGURATION FOR TRANSACTION FRAUD DETECTION (TFD)\n",
    "# =============================================================================\n",
    "#\n",
    "# TFD Characteristics:\n",
    "# - Binary classification (fraud=1, non-fraud=0)\n",
    "# - Highly imbalanced (~1-5% fraud rate)\n",
    "# - High cost of False Negatives (missed fraud = financial loss)\n",
    "# - Cost of False Positives (blocked legitimate = customer friction)\n",
    "#\n",
    "# =============================================================================\n",
    "# FINAL RECOMMENDED CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Shared confusion matrix for efficiency (multiple metrics share same CM)\n",
    "shared_cm = metrics.ConfusionMatrix()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SCALAR METRICS (support .get() for single value)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "scalar_metric_classes = {\n",
    "    # PRIMARY METRICS - Most important for fraud detection\n",
    "    \"ROCAUC\": metrics.ROCAUC,              # Best overall for imbalanced binary\n",
    "    \"Recall\": metrics.Recall,               # Fraud detection rate (minimize missed fraud)\n",
    "    \"Precision\": metrics.Precision,         # False alarm rate (customer experience)\n",
    "    \"F1\": metrics.F1,                       # Harmonic mean of Precision & Recall\n",
    "    \"FBeta\": metrics.FBeta,                 # Weighted F-score (favor Recall for fraud)\n",
    "    \n",
    "    # SECONDARY METRICS - Good for monitoring\n",
    "    \"BalancedAccuracy\": metrics.BalancedAccuracy,  # Better than Accuracy for imbalanced\n",
    "    \"MCC\": metrics.MCC,                     # Matthews Correlation - robust to imbalance\n",
    "    \"GeometricMean\": metrics.GeometricMean, # sqrt(Recall * Specificity)\n",
    "    \"CohenKappa\": metrics.CohenKappa,       # Agreement beyond chance\n",
    "    \n",
    "    # PROBABILISTIC METRICS - For calibration monitoring\n",
    "    \"LogLoss\": metrics.LogLoss,             # Penalizes confident wrong predictions\n",
    "    \n",
    "    # STREAMING/DRIFT METRICS - For concept drift detection\n",
    "    \"RollingROCAUC\": metrics.RollingROCAUC, # Recent performance window\n",
    "}\n",
    "\n",
    "scalar_metric_args = {\n",
    "    # PRIMARY\n",
    "    \"ROCAUC\": {\"n_thresholds\": 20},         # Higher = more accurate (default 10)\n",
    "    \"Recall\": {\"cm\": shared_cm, \"pos_val\": 1},\n",
    "    \"Precision\": {\"cm\": shared_cm, \"pos_val\": 1},\n",
    "    \"F1\": {\"cm\": shared_cm, \"pos_val\": 1},\n",
    "    \"FBeta\": {\"beta\": 2.0, \"cm\": shared_cm, \"pos_val\": 1},  # beta=2 weights Recall 2x\n",
    "    \n",
    "    # SECONDARY\n",
    "    \"BalancedAccuracy\": {\"cm\": shared_cm},\n",
    "    \"MCC\": {\"cm\": shared_cm, \"pos_val\": 1},\n",
    "    \"GeometricMean\": {\"cm\": shared_cm},\n",
    "    \"CohenKappa\": {\"cm\": shared_cm},\n",
    "    \n",
    "    # PROBABILISTIC\n",
    "    \"LogLoss\": {},\n",
    "    \n",
    "    # STREAMING/DRIFT\n",
    "    \"RollingROCAUC\": {\"window_size\": 1000, \"pos_val\": 1},  # Last 1000 samples\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# MATRIX METRICS (no .get(), need special handling)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "matrix_metric_classes = {\n",
    "    \"ConfusionMatrix\": metrics.ConfusionMatrix,\n",
    "}\n",
    "\n",
    "matrix_metric_args = {\n",
    "    \"ConfusionMatrix\": {},  # Will use separate instance for display\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# KEY INSIGHTS FOR TFD:\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "# 1. pos_val=1 ensures \"fraud\" (is_fraud=1) is treated as positive class\n",
    "#\n",
    "# 2. FBeta with beta=2.0:\n",
    "#    - Weights Recall twice as much as Precision\n",
    "#    - Prioritizes catching fraud over avoiding false alarms\n",
    "#    - Formula: (1 + beta^2) * (P * R) / (beta^2 * P + R)\n",
    "#\n",
    "# 3. Shared ConfusionMatrix (cm parameter):\n",
    "#    - Reduces computation and memory\n",
    "#    - Multiple metrics share same underlying TP/TN/FP/FN counts\n",
    "#\n",
    "# 4. RollingROCAUC for drift detection:\n",
    "#    - Shows performance on recent samples only\n",
    "#    - Helps detect concept drift (fraud patterns changing)\n",
    "#    - window_size=1000 = last 1000 transactions\n",
    "#\n",
    "# 5. ROCAUC n_thresholds=20:\n",
    "#    - More accurate than default (10)\n",
    "#    - Slight memory/compute increase, worth it for accuracy\n",
    "#\n",
    "# 6. Avoid plain Accuracy:\n",
    "#    - With 99% non-fraud, predicting all non-fraud = 99% accuracy\n",
    "#    - Completely misleading for fraud detection\n",
    "#\n",
    "print(\"Configuration ready - copy scalar_metric_classes and scalar_metric_args to notebook 002\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
