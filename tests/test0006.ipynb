{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e38bad0",
   "metadata": {},
   "source": [
    "# Rewriting the processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b13a4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account_age_days': 370,\n",
      " 'amount': 302.69,\n",
      " 'billing_address_match': True,\n",
      " 'currency': 'BRL',\n",
      " 'cvv_provided': True,\n",
      " 'device_info': {'browser': 'Opera', 'os': 'Windows'},\n",
      " 'ip_address': '169.235.63.28',\n",
      " 'is_fraud': 0,\n",
      " 'location': {'lat': -68.4965105, 'lon': -153.515477},\n",
      " 'merchant_id': 'merchant_65',\n",
      " 'payment_method': 'debit_card',\n",
      " 'product_category': 'luxury_items',\n",
      " 'timestamp': '2025-04-17T19:52:06.994066+00:00',\n",
      " 'transaction_id': 'ffd3d366-06e4-4ddb-894e-03876e893079',\n",
      " 'transaction_type': 'deposit',\n",
      " 'user_agent': 'Mozilla/5.0 (Windows; U; Windows NT 11.0) AppleWebKit/532.16.3 '\n",
      "               '(KHTML, like Gecko) Version/4.1 Safari/532.16.3',\n",
      " 'user_id': '61fa227e-d309-4ed0-b513-3cffa5526463'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "x = {\n",
    "    'transaction_id': 'ffd3d366-06e4-4ddb-894e-03876e893079', \n",
    "    'user_id': '61fa227e-d309-4ed0-b513-3cffa5526463', \n",
    "    'timestamp': '2025-04-17T19:52:06.994066+00:00', \n",
    "    'amount': 302.69, \n",
    "    'currency': 'BRL', \n",
    "    'merchant_id': 'merchant_65', \n",
    "    'product_category': 'luxury_items', \n",
    "    'transaction_type': 'deposit', \n",
    "    'payment_method': 'debit_card', \n",
    "    'location': {'lat': -68.4965105, 'lon': -153.515477}, \n",
    "    'ip_address': '169.235.63.28', \n",
    "    'device_info': {'os': 'Windows', 'browser': 'Opera'}, \n",
    "    'user_agent': 'Mozilla/5.0 (Windows; U; Windows NT 11.0) AppleWebKit/532.16.3 (KHTML, like Gecko) Version/4.1 Safari/532.16.3', \n",
    "    'account_age_days': 370, \n",
    "    'cvv_provided': True, \n",
    "    'billing_address_match': True, \n",
    "    'is_fraud': 0}\n",
    "\n",
    "pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "430b5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial encoder state: CustomPicklableOrdinalEncoder(features=0 [])\n",
      "\n",
      "Learning from sample dictionaries:\n",
      "Learning sample: {'color': 'red', 'size': 'M', 'city': 'NY'}\n",
      "Learning sample: {'color': 'blue', 'size': 'L', 'city': 'London'}\n",
      "Learning sample: {'color': 'red', 'size': 'S', 'city': 'NY'}\n",
      "Learning sample: {'color': 'green', 'size': 'M', 'city': 'Paris'}\n",
      "Learning sample: {'color': 'blue', 'size': 'L', 'city': 'NY'}\n",
      "\n",
      "Encoder state after learning: CustomPicklableOrdinalEncoder(features=3 [color: 3 categories, size: 3 categories, city: 3 categories])\n",
      "Learned feature mappings: {'color': {'red': 0, 'blue': 1, 'green': 2}, 'size': {'M': 0, 'L': 1, 'S': 2}, 'city': {'NY': 0, 'London': 1, 'Paris': 2}}\n",
      "Next IDs per feature: {'color': 3, 'size': 3, 'city': 3}\n",
      "\n",
      "Transforming sample dictionaries:\n",
      "Original: {'color': 'red', 'size': 'M', 'city': 'NY'}\n",
      "Transformed: {'color': 0, 'size': 0, 'city': 0}\n",
      "Original: {'color': 'blue', 'size': 'L', 'city': 'London'}\n",
      "Transformed: {'color': 1, 'size': 1, 'city': 1}\n",
      "Original: {'color': 'red', 'size': 'S', 'city': 'NY'}\n",
      "Transformed: {'color': 0, 'size': 2, 'city': 0}\n",
      "Original: {'color': 'green', 'size': 'M', 'city': 'Paris'}\n",
      "Transformed: {'color': 2, 'size': 0, 'city': 2}\n",
      "Original: {'color': 'blue', 'size': 'L', 'city': 'NY'}\n",
      "Transformed: {'color': 1, 'size': 1, 'city': 0}\n",
      "\n",
      "Saving encoder to 'custom_ordinal_encoder.pkl'...\n",
      "Encoder saved successfully.\n",
      "\n",
      "Loading encoder from 'custom_ordinal_encoder.pkl'...\n",
      "Encoder loaded successfully.\n",
      "Loaded encoder state: CustomPicklableOrdinalEncoder(features=3 [color: 3 categories, size: 3 categories, city: 3 categories])\n",
      "Loaded feature mappings: {'color': {'red': 0, 'blue': 1, 'green': 2}, 'size': {'M': 0, 'L': 1, 'S': 2}, 'city': {'NY': 0, 'London': 1, 'Paris': 2}}\n",
      "\n",
      "Transforming data points using loaded encoder:\n",
      "Original: {'color': 'red', 'size': 'M', 'city': 'NY'}\n",
      "Transformed (loaded encoder): {'color': 0, 'size': 0, 'city': 0}\n",
      "Original: {'color': 'blue', 'size': 'L', 'city': 'London'}\n",
      "Transformed (loaded encoder): {'color': 1, 'size': 1, 'city': 1}\n",
      "Original: {'color': 'red', 'size': 'S', 'city': 'NY'}\n",
      "Transformed (loaded encoder): {'color': 0, 'size': 2, 'city': 0}\n",
      "Original: {'color': 'green', 'size': 'M', 'city': 'Paris'}\n",
      "Transformed (loaded encoder): {'color': 2, 'size': 0, 'city': 2}\n",
      "Original: {'color': 'blue', 'size': 'L', 'city': 'NY'}\n",
      "Transformed (loaded encoder): {'color': 1, 'size': 1, 'city': 0}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from typing import Any, Dict, Hashable\n",
    "\n",
    "# Define the path for saving/loading the encoder state\n",
    "ENCODER_FILE = \"custom_ordinal_encoder.pkl\"\n",
    "\n",
    "class CustomPicklableOrdinalEncoder:\n",
    "    \"\"\"\n",
    "    An incremental ordinal encoder that is picklable and processes dictionaries.\n",
    "    Assigns a unique integer ID to each unique category encountered for each feature.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Dictionary to store mappings for each feature.\n",
    "        # Keys are feature names (from input dictionary), values are dictionaries\n",
    "        # mapping category value to integer ID for that feature.\n",
    "        self._feature_mappings: Dict[Hashable, Dict[Any, int]] = {}\n",
    "        # Dictionary to store the next available integer ID for each feature.\n",
    "        # Keys are feature names, values are integers.\n",
    "        self._feature_next_ids: Dict[Hashable, int] = {}\n",
    "    def learn_one(self, x: Dict[Hashable, Any]):\n",
    "        \"\"\"\n",
    "        Learns categories from a single sample dictionary.\n",
    "        Iterates through the dictionary's items and learns each category value\n",
    "        for its corresponding feature.\n",
    "        Args:\n",
    "            x: A dictionary representing a single sample.\n",
    "               Keys are feature names, values are feature values.\n",
    "               Assumes categorical features are present in this dictionary.\n",
    "        \"\"\"\n",
    "        for feature_name, category_value in x.items():\n",
    "            # Ensure the category value is hashable (dictionaries/lists are not)\n",
    "            # You might need more sophisticated type checking or handling\n",
    "            # if your input dictionaries contain complex unhashable types\n",
    "            if not isinstance(category_value, Hashable):\n",
    "                 print(f\"Warning: Skipping unhashable value for feature '{feature_name}': {category_value}\")\n",
    "                 continue # Skip this feature for learning\n",
    "            # If this is the first time we see this feature, initialize its mapping and counter\n",
    "            if feature_name not in self._feature_mappings:\n",
    "                self._feature_mappings[feature_name] = {}\n",
    "                self._feature_next_ids[feature_name] = 0\n",
    "            # Get the mapping and counter for this specific feature\n",
    "            feature_map = self._feature_mappings[feature_name]\n",
    "            feature_next_id = self._feature_next_ids[feature_name]\n",
    "            # Check if the category value is already in the mapping for this feature\n",
    "            if category_value not in feature_map:\n",
    "                # If it's a new category for this feature, assign the next available ID\n",
    "                feature_map[category_value] = feature_next_id\n",
    "                # Increment the counter for the next new category for this feature\n",
    "                self._feature_next_ids[feature_name] += 1\n",
    "    def transform_one(self, x: Dict[Hashable, Any]) -> Dict[Hashable, int]:\n",
    "        \"\"\"\n",
    "        Transforms categorical features in a single sample dictionary into integer IDs.\n",
    "        Args:\n",
    "            x: A dictionary representing a single sample.\n",
    "               Keys are feature names, values are feature values.\n",
    "        Returns:\n",
    "            A new dictionary containing the transformed integer IDs for the\n",
    "            categorical features that the encoder has seen. Features not\n",
    "            seen by the encoder are excluded from the output dictionary.\n",
    "        Raises:\n",
    "            KeyError: If a feature is seen but a specific category value\n",
    "                      within that feature has not been seen during learning.\n",
    "                      You might want to add logic here to handle unseen categories\n",
    "                      (e.g., return a default value like -1 or NaN for that feature).\n",
    "        \"\"\"\n",
    "        transformed_sample: Dict[Hashable, int] = {}\n",
    "        for feature_name, category_value in x.items():\n",
    "            # Only attempt to transform features that the encoder has seen\n",
    "            if feature_name in self._feature_mappings:\n",
    "                feature_map = self._feature_mappings[feature_name]\n",
    "\n",
    "                # Check if the category value for this feature has been seen\n",
    "                if category_value in feature_map:\n",
    "                    # Transform the category value using the feature's mapping\n",
    "                    transformed_sample[feature_name] = feature_map[category_value]\n",
    "                else:\n",
    "                    # Handle unseen category values for a known feature\n",
    "                    # By default, this will raise a KeyError as per the docstring.\n",
    "                    # Example: return a placeholder value instead of raising error:\n",
    "                    # transformed_sample[feature_name] = -1 # Or some other indicator\n",
    "                    # print(f\"Warning: Unseen category '{category_value}' for feature '{feature_name}' during transform.\")\n",
    "                    # Or raise the error explicitly:\n",
    "                    raise KeyError(f\"Unseen category '{category_value}' for feature '{feature_name}' during transform.\")\n",
    "            # Features not in self._feature_mappings are ignored in the output.\n",
    "            # If you need to include them (e.g., original numerical features),\n",
    "            # you would copy them over here. This encoder only outputs encoded features.\n",
    "        return transformed_sample\n",
    "    def get_feature_mappings(self) -> Dict[Hashable, Dict[Any, int]]:\n",
    "        \"\"\"Returns the current mappings for all features.\"\"\"\n",
    "        return self._feature_mappings\n",
    "    def get_feature_next_ids(self) -> Dict[Hashable, int]:\n",
    "        \"\"\"Returns the next available IDs for all features.\"\"\"\n",
    "        return self._feature_next_ids\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"String representation of the encoder.\"\"\"\n",
    "        num_features = len(self._feature_mappings)\n",
    "        feature_details = \", \".join([f\"{name}: {len(mapping)} categories\" for name, mapping in self._feature_mappings.items()])\n",
    "        return f\"CustomPicklableOrdinalEncoder(features={num_features} [{feature_details}])\"\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# 1. Create an instance of the custom encoder\n",
    "custom_encoder = CustomPicklableOrdinalEncoder()\n",
    "print(f\"Initial encoder state: {custom_encoder}\")\n",
    "\n",
    "# 2. Learn from some sample dictionaries\n",
    "sample_data = [\n",
    "    {'color': 'red', 'size': 'M', 'city': 'NY'},\n",
    "    {'color': 'blue', 'size': 'L', 'city': 'London'},\n",
    "    {'color': 'red', 'size': 'S', 'city': 'NY'},\n",
    "    {'color': 'green', 'size': 'M', 'city': 'Paris'},\n",
    "    {'color': 'blue', 'size': 'L', 'city': 'NY'},\n",
    "]\n",
    "\n",
    "print(\"\\nLearning from sample dictionaries:\")\n",
    "for sample in sample_data:\n",
    "    print(f\"Learning sample: {sample}\")\n",
    "    custom_encoder.learn_one(sample)\n",
    "\n",
    "print(f\"\\nEncoder state after learning: {custom_encoder}\")\n",
    "print(f\"Learned feature mappings: {custom_encoder.get_feature_mappings()}\")\n",
    "print(f\"Next IDs per feature: {custom_encoder.get_feature_next_ids()}\")\n",
    "\n",
    "\n",
    "# 3. Transform data points\n",
    "print(\"\\nTransforming sample dictionaries:\")\n",
    "transformed_samples = [custom_encoder.transform_one(sample) for sample in sample_data]\n",
    "for i, sample in enumerate(sample_data):\n",
    "    print(f\"Original: {sample}\")\n",
    "    print(f\"Transformed: {transformed_samples[i]}\")\n",
    "\n",
    "# Example of transforming a sample with an unseen category for a known feature (will raise KeyError)\n",
    "# unseen_sample = {'color': 'yellow', 'size': 'S', 'city': 'NY'}\n",
    "# try:\n",
    "#     print(\"\\nAttempting to transform sample with unseen category 'yellow':\")\n",
    "#     custom_encoder.transform_one(unseen_sample)\n",
    "# except KeyError as e:\n",
    "#     print(f\"Caught expected error: {e}\")\n",
    "\n",
    "# Example of transforming a sample with a new feature (the new feature is ignored)\n",
    "# new_feature_sample = {'color': 'red', 'size': 'M', 'material': 'wood'}\n",
    "# print(\"\\nAttempting to transform sample with new feature 'material':\")\n",
    "# transformed_new_feature = custom_encoder.transform_one(new_feature_sample)\n",
    "# print(f\"Original: {new_feature_sample}\")\n",
    "# print(f\"Transformed: {transformed_new_feature}\") # 'material' is not in the output\n",
    "\n",
    "\n",
    "# 4. Save the encoder using pickle\n",
    "print(f\"\\nSaving encoder to '{ENCODER_FILE}'...\")\n",
    "try:\n",
    "    with open(ENCODER_FILE, \"wb\") as f:\n",
    "        pickle.dump(custom_encoder, f)\n",
    "    print(\"Encoder saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving encoder: {e}\")\n",
    "\n",
    "# 5. Load the encoder using pickle\n",
    "loaded_encoder = None\n",
    "if os.path.exists(ENCODER_FILE):\n",
    "    print(f\"\\nLoading encoder from '{ENCODER_FILE}'...\")\n",
    "    try:\n",
    "        with open(ENCODER_FILE, \"rb\") as f:\n",
    "            loaded_encoder = pickle.load(f)\n",
    "        print(\"Encoder loaded successfully.\")\n",
    "        print(f\"Loaded encoder state: {loaded_encoder}\")\n",
    "        print(f\"Loaded feature mappings: {loaded_encoder.get_feature_mappings()}\")\n",
    "\n",
    "        # Verify the loaded encoder works\n",
    "        print(\"\\nTransforming data points using loaded encoder:\")\n",
    "        transformed_data_loaded = [loaded_encoder.transform_one(sample) for sample in sample_data]\n",
    "        for i, sample in enumerate(sample_data):\n",
    "            print(f\"Original: {sample}\")\n",
    "            print(f\"Transformed (loaded encoder): {transformed_data_loaded[i]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading encoder: {e}\")\n",
    "    # finally:\n",
    "        # Clean up the saved file\n",
    "        # os.remove(ENCODER_FILE)\n",
    "        # print(f\"\\nCleaned up '{ENCODER_FILE}'.\")\n",
    "        # pass # Keep the file for inspection if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d402684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account_age_days': 370,\n",
      " 'amount': 302.69,\n",
      " 'billing_address_match': True,\n",
      " 'cvv_provided': True}\n"
     ]
    }
   ],
   "source": [
    "from river import compose\n",
    "\n",
    "pipe1 = compose.Select(\n",
    "    \"amount\",\n",
    "    \"account_age_days\",\n",
    "    \"cvv_provided\",\n",
    "    \"billing_address_match\"\n",
    ")\n",
    "\n",
    "x_pipe_1 = pipe1.transform_one(x)\n",
    "pprint(x_pipe_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f75fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'currency': 0,\n",
      " 'merchant_id': 0,\n",
      " 'payment_method': 0,\n",
      " 'product_category': 0,\n",
      " 'transaction_type': 0,\n",
      " 'user_agent': 0}\n"
     ]
    }
   ],
   "source": [
    "from river import preprocessing\n",
    "\n",
    "pipe2a = compose.Select(\n",
    "    \"currency\",\n",
    "    \"merchant_id\",\n",
    "    \"payment_method\",\n",
    "    \"product_category\",\n",
    "    \"transaction_type\",\n",
    "    \"user_agent\"\n",
    ")\n",
    "\n",
    "pipe2a.learn_one(x)\n",
    "x_pipe_2 = pipe2a.transform_one(x)\n",
    "\n",
    "#pipe2b = preprocessing.OrdinalEncoder()\n",
    "pipe2b = CustomPicklableOrdinalEncoder()\n",
    "\n",
    "pipe2b.learn_one(x_pipe_2)\n",
    "x_pipe_2 = pipe2b.transform_one(x_pipe_2)\n",
    "\n",
    "pprint(x_pipe_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c067d83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_agent': {'Mozilla/5.0 (Windows; U; Windows NT 11.0) AppleWebKit/532.16.3 (KHTML, like Gecko) Version/4.1 Safari/532.16.3': 0},\n",
       " 'payment_method': {'debit_card': 0},\n",
       " 'merchant_id': {'merchant_65': 0},\n",
       " 'product_category': {'luxury_items': 0},\n",
       " 'transaction_type': {'deposit': 0},\n",
       " 'currency': {'BRL': 0}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2b.get_feature_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7fc11d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'browser': 0, 'os': 0}\n"
     ]
    }
   ],
   "source": [
    "def extract_device_info(x):\n",
    "    x_ = x['device_info']\n",
    "    return {\n",
    "        'os': x_['os'],\n",
    "        'browser': x_['browser'],\n",
    "    }\n",
    "\n",
    "pipe3a = compose.Select(\n",
    "    \"device_info\"\n",
    ")\n",
    "\n",
    "pipe3a.learn_one(x)\n",
    "x_pipe_3 = pipe3a.transform_one(x)\n",
    "\n",
    "pipe3b = compose.FuncTransformer(\n",
    "    extract_device_info,\n",
    ")\n",
    "\n",
    "pipe3b.learn_one(x_pipe_3)\n",
    "x_pipe_3 = pipe3b.transform_one(x_pipe_3)\n",
    "\n",
    "#pipe3c = preprocessing.OrdinalEncoder()\n",
    "pipe3c = CustomPicklableOrdinalEncoder()\n",
    "\n",
    "pipe3c.learn_one(x_pipe_3)\n",
    "x_pipe_3 = pipe3c.transform_one(x_pipe_3)\n",
    "\n",
    "pprint(x_pipe_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5635bd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'os': {'Windows': 0}, 'browser': {'Opera': 0}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3c.get_feature_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5a05ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account_age_days': 370,\n",
      " 'amount': 302.69,\n",
      " 'billing_address_match': True,\n",
      " 'browser': 0,\n",
      " 'currency': 0,\n",
      " 'cvv_provided': True,\n",
      " 'merchant_id': 0,\n",
      " 'os': 0,\n",
      " 'payment_method': 0,\n",
      " 'product_category': 0,\n",
      " 'transaction_type': 0,\n",
      " 'user_agent': 0}\n"
     ]
    }
   ],
   "source": [
    "x = x_pipe_1 | x_pipe_2 | x_pipe_3\n",
    "\n",
    "pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f79e9",
   "metadata": {},
   "source": [
    "## Trying to serialize (pickle) some parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d11d6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"ordinal_encoder_1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipe2b, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1147d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ordinal_encoder_2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipe3c, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d89ba",
   "metadata": {},
   "source": [
    "## Now, let's try to retrieve the saved encoder and check if internal data was saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90fa5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ordinal_encoder_1.pkl\", \"rb\") as f:\n",
    "    pipe2b = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8aaa3e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_agent': {'Mozilla/5.0 (Windows; U; Windows NT 11.0) AppleWebKit/532.16.3 (KHTML, like Gecko) Version/4.1 Safari/532.16.3': 0},\n",
       " 'payment_method': {'debit_card': 0},\n",
       " 'merchant_id': {'merchant_65': 0},\n",
       " 'product_category': {'luxury_items': 0},\n",
       " 'transaction_type': {'deposit': 0},\n",
       " 'currency': {'BRL': 0}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2b.get_feature_mappings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ddbd59",
   "metadata": {},
   "source": [
    "## Create a function to process each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7e79b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(x):\n",
    "    # Pipeline 1\n",
    "    pipe1 = compose.Select(\n",
    "        \"amount\",\n",
    "        \"account_age_days\",\n",
    "        \"cvv_provided\",\n",
    "        \"billing_address_match\"\n",
    "    )\n",
    "    pipe1.learn_one(x)\n",
    "    x_pipe_1 = pipe1.transform_one(x)\n",
    "    # Pipeline 2\n",
    "    pipe2a = compose.Select(\n",
    "        \"currency\",\n",
    "        \"merchant_id\",\n",
    "        \"payment_method\",\n",
    "        \"product_category\",\n",
    "        \"transaction_type\",\n",
    "        \"user_agent\"\n",
    "    )\n",
    "    pipe2a.learn_one(x)\n",
    "    x_pipe_2 = pipe2a.transform_one(x)\n",
    "    pipe2b = CustomPicklableOrdinalEncoder()\n",
    "    pipe2b.learn_one(x_pipe_2)\n",
    "    x_pipe_2 = pipe2b.transform_one(x_pipe_2)\n",
    "    # Pipeline 3\n",
    "    pipe3a = compose.Select(\n",
    "        \"device_info\"\n",
    "    )\n",
    "    pipe3a.learn_one(x)\n",
    "    x_pipe_3 = pipe3a.transform_one(x)\n",
    "    pipe3b = compose.FuncTransformer(\n",
    "        extract_device_info,\n",
    "    )\n",
    "    pipe3b.learn_one(x_pipe_3)\n",
    "    x_pipe_3 = pipe3b.transform_one(x_pipe_3)\n",
    "    pipe3c = CustomPicklableOrdinalEncoder()\n",
    "    pipe3c.learn_one(x_pipe_3)\n",
    "    x_pipe_3 = pipe3c.transform_one(x_pipe_3)\n",
    "    x = x_pipe_1 | x_pipe_2 | x_pipe_3\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7706f900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account_age_days': 370,\n",
      " 'amount': 302.69,\n",
      " 'billing_address_match': True,\n",
      " 'currency': 'BRL',\n",
      " 'cvv_provided': True,\n",
      " 'device_info': {'browser': 'Opera', 'os': 'Windows'},\n",
      " 'ip_address': '169.235.63.28',\n",
      " 'is_fraud': 0,\n",
      " 'location': {'lat': -68.4965105, 'lon': -153.515477},\n",
      " 'merchant_id': 'merchant_65',\n",
      " 'payment_method': 'debit_card',\n",
      " 'product_category': 'luxury_items',\n",
      " 'timestamp': '2025-04-17T19:52:06.994066+00:00',\n",
      " 'transaction_id': 'ffd3d366-06e4-4ddb-894e-03876e893079',\n",
      " 'transaction_type': 'deposit',\n",
      " 'user_agent': 'Mozilla/5.0 (Windows; U; Windows NT 11.0) AppleWebKit/532.16.3 '\n",
      "               '(KHTML, like Gecko) Version/4.1 Safari/532.16.3',\n",
      " 'user_id': '61fa227e-d309-4ed0-b513-3cffa5526463'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "x = {\n",
    "    'transaction_id': 'ffd3d366-06e4-4ddb-894e-03876e893079', \n",
    "    'user_id': '61fa227e-d309-4ed0-b513-3cffa5526463', \n",
    "    'timestamp': '2025-04-17T19:52:06.994066+00:00', \n",
    "    'amount': 302.69, \n",
    "    'currency': 'BRL', \n",
    "    'merchant_id': 'merchant_65', \n",
    "    'product_category': 'luxury_items', \n",
    "    'transaction_type': 'deposit', \n",
    "    'payment_method': 'debit_card', \n",
    "    'location': {'lat': -68.4965105, 'lon': -153.515477}, \n",
    "    'ip_address': '169.235.63.28', \n",
    "    'device_info': {'os': 'Windows', 'browser': 'Opera'}, \n",
    "    'user_agent': 'Mozilla/5.0 (Windows; U; Windows NT 11.0) AppleWebKit/532.16.3 (KHTML, like Gecko) Version/4.1 Safari/532.16.3', \n",
    "    'account_age_days': 370, \n",
    "    'cvv_provided': True, \n",
    "    'billing_address_match': True, \n",
    "    'is_fraud': 0}\n",
    "\n",
    "pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2706d3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'account_age_days': 370,\n",
       " 'cvv_provided': True,\n",
       " 'amount': 302.69,\n",
       " 'billing_address_match': True,\n",
       " 'user_agent': 0,\n",
       " 'payment_method': 0,\n",
       " 'merchant_id': 0,\n",
       " 'product_category': 0,\n",
       " 'transaction_type': 0,\n",
       " 'currency': 0,\n",
       " 'os': 0,\n",
       " 'browser': 0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f671d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ordinal_encoder_1.pkl\", \"rb\") as f:\n",
    "    pipe2b = pickle.load(f)\n",
    "with open(\"ordinal_encoder_2.pkl\", \"rb\") as f:\n",
    "    pipe3c = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41554916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_agent': {'Mozilla/5.0 (Windows; U; Windows NT 11.0) AppleWebKit/532.16.3 (KHTML, like Gecko) Version/4.1 Safari/532.16.3': 0},\n",
       " 'payment_method': {'debit_card': 0},\n",
       " 'merchant_id': {'merchant_65': 0},\n",
       " 'product_category': {'luxury_items': 0},\n",
       " 'transaction_type': {'deposit': 0},\n",
       " 'currency': {'BRL': 0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2b.get_feature_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93addb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'os': {'Windows': 0}, 'browser': {'Opera': 0}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3c.get_feature_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f1837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
