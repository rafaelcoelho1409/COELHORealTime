{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa155b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict, Hashable\n",
    "from river import (\n",
    "    compose, \n",
    "    metrics, \n",
    "    drift,\n",
    "    forest\n",
    ")\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5632e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOrdinalEncoder:\n",
    "    \"\"\"\n",
    "    An incremental ordinal encoder that is picklable and processes dictionaries.\n",
    "    Assigns a unique integer ID to each unique category encountered for each feature.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Dictionary to store mappings for each feature.\n",
    "        # Keys are feature names (from input dictionary), values are dictionaries\n",
    "        # mapping category value to integer ID for that feature.\n",
    "        self._feature_mappings: Dict[Hashable, Dict[Any, int]] = {}\n",
    "        # Dictionary to store the next available integer ID for each feature.\n",
    "        # Keys are feature names, values are integers.\n",
    "        self._feature_next_ids: Dict[Hashable, int] = {}\n",
    "    def learn_one(self, x: Dict[Hashable, Any]):\n",
    "        \"\"\"\n",
    "        Learns categories from a single sample dictionary.\n",
    "        Iterates through the dictionary's items and learns each category value\n",
    "        for its corresponding feature.\n",
    "        Args:\n",
    "            x: A dictionary representing a single sample.\n",
    "               Keys are feature names, values are feature values.\n",
    "               Assumes categorical features are present in this dictionary.\n",
    "        \"\"\"\n",
    "        for feature_name, category_value in x.items():\n",
    "            # Ensure the category value is hashable (dictionaries/lists are not)\n",
    "            # You might need more sophisticated type checking or handling\n",
    "            # if your input dictionaries contain complex unhashable types\n",
    "            if not isinstance(category_value, Hashable):\n",
    "                 print(f\"Warning: Skipping unhashable value for feature '{feature_name}': {category_value}\")\n",
    "                 continue # Skip this feature for learning\n",
    "            # If this is the first time we see this feature, initialize its mapping and counter\n",
    "            if feature_name not in self._feature_mappings:\n",
    "                self._feature_mappings[feature_name] = {}\n",
    "                self._feature_next_ids[feature_name] = 0\n",
    "            # Get the mapping and counter for this specific feature\n",
    "            feature_map = self._feature_mappings[feature_name]\n",
    "            feature_next_id = self._feature_next_ids[feature_name]\n",
    "            # Check if the category value is already in the mapping for this feature\n",
    "            if category_value not in feature_map:\n",
    "                # If it's a new category for this feature, assign the next available ID\n",
    "                feature_map[category_value] = feature_next_id\n",
    "                # Increment the counter for the next new category for this feature\n",
    "                self._feature_next_ids[feature_name] += 1\n",
    "    def transform_one(self, x: Dict[Hashable, Any]) -> Dict[Hashable, int]:\n",
    "        \"\"\"\n",
    "        Transforms categorical features in a single sample dictionary into integer IDs.\n",
    "        Args:\n",
    "            x: A dictionary representing a single sample.\n",
    "               Keys are feature names, values are feature values.\n",
    "        Returns:\n",
    "            A new dictionary containing the transformed integer IDs for the\n",
    "            categorical features that the encoder has seen. Features not\n",
    "            seen by the encoder are excluded from the output dictionary.\n",
    "        Raises:\n",
    "            KeyError: If a feature is seen but a specific category value\n",
    "                      within that feature has not been seen during learning.\n",
    "                      You might want to add logic here to handle unseen categories\n",
    "                      (e.g., return a default value like -1 or NaN for that feature).\n",
    "        \"\"\"\n",
    "        transformed_sample: Dict[Hashable, int] = {}\n",
    "        for feature_name, category_value in x.items():\n",
    "            # Only attempt to transform features that the encoder has seen\n",
    "            if feature_name in self._feature_mappings:\n",
    "                feature_map = self._feature_mappings[feature_name]\n",
    "\n",
    "                # Check if the category value for this feature has been seen\n",
    "                if category_value in feature_map:\n",
    "                    # Transform the category value using the feature's mapping\n",
    "                    transformed_sample[feature_name] = feature_map[category_value]\n",
    "                else:\n",
    "                    # Handle unseen category values for a known feature\n",
    "                    # By default, this will raise a KeyError as per the docstring.\n",
    "                    # Example: return a placeholder value instead of raising error:\n",
    "                    # transformed_sample[feature_name] = -1 # Or some other indicator\n",
    "                    # print(f\"Warning: Unseen category '{category_value}' for feature '{feature_name}' during transform.\")\n",
    "                    # Or raise the error explicitly:\n",
    "                    raise KeyError(f\"Unseen category '{category_value}' for feature '{feature_name}' during transform.\")\n",
    "            # Features not in self._feature_mappings are ignored in the output.\n",
    "            # If you need to include them (e.g., original numerical features),\n",
    "            # you would copy them over here. This encoder only outputs encoded features.\n",
    "        return transformed_sample\n",
    "    def get_feature_mappings(self) -> Dict[Hashable, Dict[Any, int]]:\n",
    "        \"\"\"Returns the current mappings for all features.\"\"\"\n",
    "        return self._feature_mappings\n",
    "    def get_feature_next_ids(self) -> Dict[Hashable, int]:\n",
    "        \"\"\"Returns the next available IDs for all features.\"\"\"\n",
    "        return self._feature_next_ids\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"String representation of the encoder.\"\"\"\n",
    "        num_features = len(self._feature_mappings)\n",
    "        feature_details = \", \".join([f\"{name}: {len(mapping)} categories\" for name, mapping in self._feature_mappings.items()])\n",
    "        return f\"CustomPicklableOrdinalEncoder(features={num_features} [{feature_details}])\"\n",
    "\n",
    "def extract_timestamp_info(x):\n",
    "    x_ = dt.datetime.strptime(\n",
    "        x['timestamp'],\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    return {\n",
    "        'year': x_.year,\n",
    "        'month': x_.month,\n",
    "        'day': x_.day,\n",
    "        'hour': x_.hour,\n",
    "        'minute': x_.minute,\n",
    "        'second': x_.second,\n",
    "        'day_of_week': x_.weekday()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9435053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\n",
    "    'trip_id': 'a1b2c3d4-e5f6-7890-1234-567890abcdef', # Example UUID\n",
    "    'driver_id': 'driver_3456', # Example driver ID\n",
    "    'vehicle_id': 'vehicle_789', # Example vehicle ID\n",
    "    'timestamp': '2025-05-03T01:08:00.000000+00:00', # ISO format timestamp in UTC\n",
    "    'origin': {'lat': -23.551234, 'lon': -46.633456}, # Example coordinates\n",
    "    'destination': {'lat': -23.587654, 'lon': -46.698765}, # Example coordinates\n",
    "    'estimated_distance_km': 8.52, # Calculated Haversine distance\n",
    "    'weather': 'Clouds', # Simulated weather condition\n",
    "    'temperature_celsius': 22.5, # Simulated temperature\n",
    "    'day_of_week': 5, # Day of the week in UTC (0=Monday, 5=Saturday)\n",
    "    'hour_of_day': 1, # Hour of the day in UTC (0-23)\n",
    "    'driver_rating': 4.7, # Simulated driver rating\n",
    "    'vehicle_type': 'Car', # Randomly selected vehicle type\n",
    "    # --- Feature available for prediction ---\n",
    "    'initial_estimated_travel_time_seconds': 805, # Initial estimate based on distance/avg speed + noise\n",
    "    # --- Ground Truth (Simulated) ---\n",
    "    'simulated_actual_travel_time_seconds': 1595, # Simulated ground truth after factors\n",
    "    # --- Debugging Info (Optional) ---\n",
    "    'debug_traffic_factor': 1.08, # Simulated traffic multiplier (weekend example)\n",
    "    'debug_weather_factor': 1.00, # Simulated weather multiplier (no bad weather)\n",
    "    'debug_incident_delay_seconds': 750, # Simulated delay from a random incident\n",
    "    'debug_driver_factor': 0.99 # Simulated factor based on driver rating\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483ee969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(x):\n",
    "    pipe1 = compose.Select(\n",
    "        'estimated_distance_km',\n",
    "        'temperature_celsius',\n",
    "        'hour_of_day',\n",
    "        'driver_rating',\n",
    "        'initial_estimated_travel_time_seconds',\n",
    "        'debug_traffic_factor',\n",
    "        'debug_weather_factor',\n",
    "        'debug_incident_delay_seconds',\n",
    "        'debug_driver_factor'\n",
    "    )\n",
    "    pipe1.learn_one(x)\n",
    "    x1 = pipe1.transform_one(x)\n",
    "    pipe2 = compose.Select(\n",
    "        'driver_id',\n",
    "        'vehicle_id',\n",
    "        'weather',\n",
    "        'vehicle_type'\n",
    "    )\n",
    "    pipe2.learn_one(x)\n",
    "    x_pipe_2 = pipe2.transform_one(x)\n",
    "    pipe3a = compose.Select(\n",
    "        \"timestamp\",\n",
    "    )\n",
    "    pipe3a.learn_one(x)\n",
    "    x_pipe_3 = pipe3a.transform_one(x)\n",
    "    pipe3b = compose.FuncTransformer(\n",
    "        extract_timestamp_info,\n",
    "    )\n",
    "    pipe3b.learn_one(x_pipe_3)\n",
    "    x_pipe_3 = pipe3b.transform_one(x_pipe_3)\n",
    "    return x1 | x_pipe_2 | x_pipe_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de06839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'debug_traffic_factor': 1.08,\n",
       " 'driver_rating': 4.7,\n",
       " 'debug_driver_factor': 0.99,\n",
       " 'initial_estimated_travel_time_seconds': 805,\n",
       " 'debug_incident_delay_seconds': 750,\n",
       " 'temperature_celsius': 22.5,\n",
       " 'hour_of_day': 1,\n",
       " 'debug_weather_factor': 1.0,\n",
       " 'estimated_distance_km': 8.52,\n",
       " 'weather': 'Clouds',\n",
       " 'vehicle_type': 'Car',\n",
       " 'vehicle_id': 'vehicle_789',\n",
       " 'driver_id': 'driver_3456',\n",
       " 'year': 2025,\n",
       " 'month': 5,\n",
       " 'day': 3,\n",
       " 'hour': 1,\n",
       " 'minute': 8,\n",
       " 'second': 0,\n",
       " 'day_of_week': 5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb89cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
